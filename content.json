{"meta":{"title":"Schenk - Blog","subtitle":"","description":"","author":"schenk","url":"http://example.com","root":"/"},"pages":[{"title":"所有分类","date":"2022-06-20T09:27:15.668Z","updated":"2020-11-04T03:12:20.000Z","comments":true,"path":"categories/index.html","permalink":"http://example.com/categories/index.html","excerpt":"","text":""},{"title":"","date":"2022-06-20T09:27:15.667Z","updated":"2020-11-04T03:04:04.000Z","comments":true,"path":"404.html","permalink":"http://example.com/404.html","excerpt":"","text":"404 很抱歉，您访问的页面不存在 可能是输入地址有误或该地址已被删除"},{"title":"友链 - Links","date":"2022-06-20T09:27:15.668Z","updated":"2020-11-04T03:11:20.000Z","comments":true,"path":"friends/index.html","permalink":"http://example.com/friends/index.html","excerpt":"","text":""},{"title":"","date":"2022-06-20T09:27:15.668Z","updated":"2020-11-04T03:12:30.000Z","comments":true,"path":"mylist/index.html","permalink":"http://example.com/mylist/index.html","excerpt":"","text":""},{"title":"所有标签","date":"2022-06-20T09:27:15.668Z","updated":"2020-11-04T03:12:38.000Z","comments":true,"path":"tags/index.html","permalink":"http://example.com/tags/index.html","excerpt":"","text":""},{"title":"About","date":"2022-12-19T04:56:36.262Z","updated":"2022-12-19T04:56:36.262Z","comments":true,"path":"about/index.html","permalink":"http://example.com/about/index.html","excerpt":"","text":"SJTUer Major in Cyber Security Cubing Since 2017 Biiiiiig Fan of Christopher Nolan &amp; One Piece &amp; Hua Chenyu"},{"title":"","date":"2022-12-19T04:56:19.899Z","updated":"2022-12-19T04:56:07.856Z","comments":true,"path":"static/christmas.html","permalink":"http://example.com/static/christmas.html","excerpt":"","text":"Merry Christmas body { background-color: #000; overflow: hidden; display: flex; align-items: center; justify-content: space-around; } body, html { height: 100%; width: 100%; margin: 0; padding: 0; } svg { width: 90%; height: 90%; visibility: hidden; } .sparkle { /* mix-blend-mode:luminosity */ } body { margin: 0; text-align: center; padding: 0; line-height: 2em; font-family: \"Times New Roman\", Times, serif; color: #000000; } #header { /* position: absolute; */ text-align: center; color: #C89568; font-family: Times New Roman; font-size: 35px; min-width: 400px; max-height: 100vh; } .header-item { opacity: 0; transition: all .5s ease-in-out; line-height: 1.5; margin: 0; } .header-item.show { opacity: 1; } #treeStarOutline { opacity: 0; } #mask { position: absolute; background-color: #000; width: 100%; height: 100%; font-size: 15rem; animation: shack 0.4s ease-in-out infinite; display: flex; align-items: center; justify-content: center; cursor: pointer; /* display: none; */ } @keyframes shack { 0% { transform: rotate(0); } 25% { transform: rotate(-10deg); } 50% { transform: rotate(0); } 75% { transform: rotate(10deg); } 100% { transform: rotate(0); } } #stars { position: absolute; width: 100%; height: 100%; z-index: -1; } 🎄 /*! * GSAP 3.11.3 * https://greensock.com * * @license Copyright 2022, GreenSock. All rights reserved. * Subject to the terms at https://greensock.com/standard-license or for Club GreenSock members, the agreement issued with that membership. * @author: Jack Doyle, jack@greensock.com */ !function(t,e){\"object\"==typeof exports&&\"undefined\"!=typeof module?e(exports):\"function\"==typeof define&&define.amd?define([\"exports\"],e):e((t=t||self).window=t.window||{})}(this,function(e){\"use strict\";function _inheritsLoose(t,e){t.prototype=Object.create(e.prototype),(t.prototype.constructor=t).__proto__=e}function _assertThisInitialized(t){if(void 0===t)throw new ReferenceError(\"this hasn't been initialised - super() hasn't been called\");return t}function r(t){return\"string\"==typeof t}function s(t){return\"function\"==typeof t}function t(t){return\"number\"==typeof t}function u(t){return void 0===t}function v(t){return\"object\"==typeof t}function w(t){return!1!==t}function x(){return\"undefined\"!=typeof window}function y(t){return s(t)||r(t)}function P(t){return(i=yt(t,ot))&&Ce}function Q(t,e){return console.warn(\"Invalid property\",t,\"set to\",e,\"Missing plugin? gsap.registerPlugin()\")}function R(t,e){return!e&&console.warn(t)}function S(t,e){return t&&(ot[t]=e)&&i&&(i[t]=e)||ot}function T(){return 0}function ea(t){var e,r,i=t[0];if(v(i)||s(i)||(t=[t]),!(e=(i._gsap||{}).harness)){for(r=gt.length;r--&&!gt[r].targetTest(i););e=gt[r]}for(r=t.length;r--;)t[r]&&(t[r]._gsap||(t[r]._gsap=new jt(t[r],e)))||t.splice(r,1);return t}function fa(t){return t._gsap||ea(Ot(t))[0]._gsap}function ga(t,e,r){return(r=t[e])&&s(r)?t[e]():u(r)&&t.getAttribute&&t.getAttribute(e)||r}function ha(t,e){return(t=t.split(\",\")).forEach(e)||t}function ia(t){return Math.round(1e5*t)/1e5||0}function ja(t){return Math.round(1e7*t)/1e7||0}function ka(t,e){var r=e.charAt(0),i=parseFloat(e.substr(2));return t=parseFloat(t),\"+\"===r?t+i:\"-\"===r?t-i:\"*\"===r?t*i:t/i}function la(t,e){for(var r=e.length,i=0;t.indexOf(e[i])"}],"posts":[{"title":"论文阅读-可搜索加密相关","slug":"paper-reading/searchable-encryption","date":"2022-12-11T16:00:00.000Z","updated":"2022-12-12T09:57:34.819Z","comments":true,"path":"2022/12/12/paper-reading/searchable-encryption/","link":"","permalink":"http://example.com/2022/12/12/paper-reading/searchable-encryption/","excerpt":"论文阅读-可搜索加密相关","text":"","categories":[{"name":"SGX","slug":"SGX","permalink":"http://example.com/categories/SGX/"},{"name":"Paper Reading","slug":"Paper-Reading","permalink":"http://example.com/categories/Paper-Reading/"}],"tags":[{"name":"sgx","slug":"sgx","permalink":"http://example.com/tags/sgx/"},{"name":"db","slug":"db","permalink":"http://example.com/tags/db/"}]},{"title":"SGX Tools","slug":"instruction/sgx-tools","date":"2022-10-30T16:00:00.000Z","updated":"2022-10-31T09:12:02.968Z","comments":true,"path":"2022/10/31/instruction/sgx-tools/","link":"","permalink":"http://example.com/2022/10/31/instruction/sgx-tools/","excerpt":"整理使用过的SGX相关工具","text":"sgx_emmt 测量一个sgx程序运行过程中使用的最大enclave内存，根据 Developer Reference 中的相关章节进行测量，主要使用工具 sgx_gdb 在sdk安装目录的bin目录下 查看当前计算机的EPC大小 1234git clone git@github.com:ayeks/SGX-hardware.gitcd SGX-hardwaregcc test-sgx.c -o test-sgx./test-sgx","categories":[],"tags":[]},{"title":"WSL配置","slug":"instruction/wsl","date":"2022-06-21T16:00:00.000Z","updated":"2022-06-22T04:43:42.843Z","comments":true,"path":"2022/06/22/instruction/wsl/","link":"","permalink":"http://example.com/2022/06/22/instruction/wsl/","excerpt":"Windows11配置Linux子系统","text":"安装WSL 管理员权限打开powershell 1wsl --install 默认安装WSL 2 + Ubuntu 20.04，详见安装 WSL | Microsoft Docs 更新升级apt 1sudo apt update &amp;&amp; sudo apt upgrade 使用Windows文件管理器打开当前Ubuntu目录 1explorer.exe . 使用vscode打开当前当前Ubuntu目录 1code . 基本命令 WSL 的基本命令 | Microsoft Docs ==git等工具及语言的安装同双系统Ubuntu的安装== 配置WSL使用Windows代理 在Windows端Clash中开启 Allow LAN 在Ubuntu的 bashrc 中添加 123export hostip=$(cat /etc/resolv.conf |grep -oP &#x27;(?&lt;=nameserver\\ ).*&#x27;)export https_proxy=&quot;http://$&#123;hostip&#125;:7890&quot;export http_proxy=&quot;http://$&#123;hostip&#125;:7890&quot; 测试 1curl google.com","categories":[{"name":"Instruction","slug":"Instruction","permalink":"http://example.com/categories/Instruction/"},{"name":"Linux","slug":"Linux","permalink":"http://example.com/categories/Linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}]},{"title":"解决 cargo build 过程中无法更新基于git repo的crates","slug":"instruction/rust-cargo-git-block","date":"2022-05-15T16:00:00.000Z","updated":"2022-05-26T08:52:56.000Z","comments":true,"path":"2022/05/16/instruction/rust-cargo-git-block/","link":"","permalink":"http://example.com/2022/05/16/instruction/rust-cargo-git-block/","excerpt":"解决 cargo build 过程中无法更新基于git repo的crates","text":"经过 git clone 检查发现：https经常无法成功下载，而ssh下载稳定 修改 ~/.gitconfig ： 12[url &quot;ssh:&#x2F;&#x2F;git@github.com&#x2F;&quot;] insteadOf &#x3D; https:&#x2F;&#x2F;github.com 修改 ~/.cargo/config 12[net]git-fetch-with-cli &#x3D; true","categories":[{"name":"Instruction","slug":"Instruction","permalink":"http://example.com/categories/Instruction/"},{"name":"Rust","slug":"Rust","permalink":"http://example.com/categories/Rust/"}],"tags":[{"name":"git","slug":"git","permalink":"http://example.com/tags/git/"},{"name":"rust","slug":"rust","permalink":"http://example.com/tags/rust/"}]},{"title":"论文阅读-ORAM相关","slug":"paper-reading/oram","date":"2022-05-06T16:00:00.000Z","updated":"2022-08-18T07:20:30.109Z","comments":true,"path":"2022/05/07/paper-reading/oram/","link":"","permalink":"http://example.com/2022/05/07/paper-reading/oram/","excerpt":"论文阅读-ORAM相关","text":"ORAM基础 使用场景 与不受信任的云存储交互，并在不泄露访问模式的情况下利用云存储 在安全Enclave中实现，从而&quot;ORAM控制器/client&quot;为enclave，而主内存为&quot;server&quot; 在编译器中实现，该编译器将任意代码转换为通过其内存访问模式不泄漏任何内容的代码，但运行速度更慢 constant-time/oblivious定义 对于一个函数，若对任意两个输入，代码和数据的访问模式是： 相同，或 同分布，或 服从计算不可区分的分布 不经意随机访问机研究综述 敌手： 通过用户的访问模式(access pattern)来推断存储数据的重要性 可以通过匹配前后两个连续的访问模式来推断数据查询之间的关联关系，甚至是加密数据的内容 ORAM：隐藏对真实数据块的访问，使得攻击者不能区分每一次访问是真实的还是随机的 ORAM 保证： 任意数据块不会永久驻留在某一个物理地址中，即确保任意两次访问不会产生关联 将每一次读写访问细化成一次读取加一次写回的原子操作 保护： 访问数据块的位置 数据块请求的顺序 对相同数据块的访问频率 具体的读写访问方式 定义：ORAM是客户端与服务器的交互协议 安全性：访问模式计算不可区分 正确性：使用ORAM和不使用的返回结果不同的概率是一个可忽略函数 设计重点： ORAM初始化 ORAM数据访问 特性： 低效性 安全性 用途广 模型： 简单模型 平方根模型 层次模型 分区模型 树状模型 ORAM性能优化 客户端与服务器平均带宽优化 基于布谷鸟哈希的优化策略 基于服务器计算的优化策略 基于映射表的优化策略 基于k 叉树的优化策略 客户端与服务器最坏情况带宽优化 基于de-amortization 的优化策略 基于树状模型的优化策略 基于改进混洗操作的优化策略（优化不经意排序算法） 基于改进驱逐操作的优化策略 客户端存储开销优化 基于迭代构造的优化策略 基于隐私信息检索的优化策略 基于布隆过滤器的优化策略 服务器存储开销优化 通过设计可变大小的数据块集合或者是增加(减少)部分数据块集合大小 客户端与服务器交互轮数优化 基于映射表的优化策略 基于混淆分支函数的设计 Path-ORAM An Introduction to Oblivious RAM (ORAM) – Kudelski Security Research 树的每个节点是一个bucket，其中包含固定个数的block，每个block使用 C 的对称密钥加密 position map初始化为随机值 开始执行data request 整个从根节点到叶子节点的branch返回给 C 每个block包含id和data，id在整棵树中唯一（但是dummy block的id都相同） shuffle： position map保证我们需要的block在这个branch中 若block是空的，不对其操作 非空block与当前branch中距离root最远的空block交换，使得它的leaf path与当前branch有交集 若在操作过程中发现目标block，position map中它的id替换成一个新的随机值 若没有发现空block，则需要shuffle的block会暂时保存在 C 本地的overflow stash，并在branch中替换为空block 所有block操作完成后，将暂存在overflow stash中的block分配到branch中新创建的空block中，然后清空stash 最后，将整个branch重新加密并上传到 S 具体过程如下：C 从root开始扫描 第二个block非空，需要shuffle C 从position map中找到对应的id 找到该block对应的leaf path，此时可以找到该leaf path与当前branch的最深公共节点，该节点一定在当前解密后的branch中，搜索该节点寻找一个空block 第一个block非空 第二个block也非空 第三个block为空 交换两个block，注意到此时空block被换到更接近root的位置 C 继续扫描和交换未被操作过的block 当 C 找到目标block，首先执行request中的op 然后 C 更新position map中对应block的leaf为新生成的随机leaf id 新的随机leaf id对应的branch会与当前branch有部分交集，同样，C 会查找最深公共节点，找寻空block来进行交换 此时，若找不到空block，C 会搜索其父节点，找寻空block来进行交换 在scan的过程中若碰到一个block，无法找到能与它交换的空block，则将其暂存在stash中 同时将该block覆写为空block stash中的block会周期性地写回到branch中空block的位置，并分配合适的leaf id；最后，branch重新加密并上传到 S Enclave-Based Oblivious RAM Using Intel’s SGX Computers &amp; Security 2020 Karolinska Institutet 卡罗林斯卡学院 Carnegie Mellon University in Qatar 卡内基·梅隆大学 Qatar University 卡塔尔大学 利用SGX构造了三种不同的oram：线性ORAM、平方根ORAM和路径ORAM","categories":[{"name":"Paper Reading","slug":"Paper-Reading","permalink":"http://example.com/categories/Paper-Reading/"},{"name":"ORAM","slug":"ORAM","permalink":"http://example.com/categories/ORAM/"}],"tags":[{"name":"oram","slug":"oram","permalink":"http://example.com/tags/oram/"}]},{"title":"在任意位置运行Python脚本","slug":"instruction/python-execute-anywhere","date":"2022-05-02T16:00:00.000Z","updated":"2022-05-16T11:25:42.000Z","comments":true,"path":"2022/05/03/instruction/python-execute-anywhere/","link":"","permalink":"http://example.com/2022/05/03/instruction/python-execute-anywhere/","excerpt":"在任意位置运行Python脚本","text":"在Ubuntu上任意位置运行某一个python脚本的方法： 首先在python文件开头加上： 1#!/usr/bin/env python3 说明该文件是python3脚本 为方便起见，可以将文件的.py后缀删去，并为文件添加可执行权限： 1chmod +x &lt;pythonFile&gt; 最后将python脚本所在的目录添加到 PATH 环境变量中，比如在 ~/.bashrc 中添加： 1export PATH=&lt;pathToPythonFile&gt;:$P","categories":[{"name":"Instruction","slug":"Instruction","permalink":"http://example.com/categories/Instruction/"},{"name":"Python","slug":"Python","permalink":"http://example.com/categories/Python/"},{"name":"Linux","slug":"Linux","permalink":"http://example.com/categories/Linux/"}],"tags":[{"name":"python","slug":"python","permalink":"http://example.com/tags/python/"},{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}]},{"title":"MIT 6.824 Distributed Systems 学习笔记","slug":"learning-notes/mit-6.824","date":"2022-04-27T16:00:00.000Z","updated":"2022-05-06T07:16:52.000Z","comments":true,"path":"2022/04/28/learning-notes/mit-6.824/","link":"","permalink":"http://example.com/2022/04/28/learning-notes/mit-6.824/","excerpt":"MIT6.824学习笔记","text":"Paper Reading MapReduce 一个编程模型，用于大规模并行计算，以及采用re-execution进行容错处理 $Map$：输入键值对，输出一系列中间键值对，并将相同的中间键排在一起传递到 $Reduce$ 函数 $Reduce$：输入中间键 $I$ 以及其对应的一系列中间值，对其进行合并，最后输出 实现 Master数据结构 Master存储： 每个map和reduce任务的状态（idle, in-progress, completed） 各个worker的标识 每个已完成的map任务的R个中间文件的位置和大小 容错 Worker Failure Master Failure Semantics in the Presence of Failures 本地优化 输入文件被划分为64MB的块，每个块会冗余存放在多个机器上 Master会将map任务尽可能分配到一个保存了对应副本的机器或其周围的机器上 任务粒度 M和R应该远大于worker机器的数量 备份任务 为了解决单点效率瓶颈，在MapReduce任务快完成时，master将剩余in-progress机器仍在执行的任务作为备份任务分配给其他机器 改进 Partitioning Function（如何分配R个输出文件） Ordering Guarantees Combiner Function（对重复的中间结果合并） Input and Output Types（自定义类型） Side-effects Skipping Bad Records（用户程序对特定的数据可能有bug） Local Execution（方便Debug） Status Information（日志） Counters Google File System Overview 假设 系统组件经常故障，因此需要持续监控，错误检测，容错处理，自动恢复 存储大量文件，有几百万100MB或以上的文件，多GB的文件很常见，需要高效管理，小文件不需要优化 存在两种读：大规模连续读和小规模随机读 有很多大规模连续写（添加内容），也需要支持小规模随机写但不要求其性能 高效处理多用户同时向同一个文件添加内容，保证原子性并减少开销 高持续带宽比低延迟更重要 架构 单个Master：必须最小化其参与的读和写，防止成为瓶颈 chunk大小：选择较大的64MB 优势： 减少client与master的交互 client更有可能在同一个chunk上进行大量操作，减少网络开销 减少master上存储的metadata 劣势：若很多client访问同一个文件，则这个chunk会成为hot spot Metadata：存放在master的内存中（前两个还会记录在operation log中进行持久化存储） 文件和chunk的命名空间 文件到chunk的映射 各个chunk副本的位置（通过启动时的轮询和之后的心跳消息获取） 一致性模型：保证文件命名空间的改变是原子性的 系统交互 尽可能减少master的参与 Leases 为了保证各副本的一致性改变，master通过将chunk lease给其中一个副本使其成为primary，然后primary选择一个改变的顺序，并同步给其他副本 数据流 原子性record append 快照snapshot Master操作 命名空间管理和读写锁 副本放置 最大化可靠性和可用性 最大化网络带宽利用率 chunk的create、re-replicate、rebalance 垃圾回收机制：周期性扫描 过期副本探测：master维护chunk版本号 容错和诊断 高可用性 快速恢复 Chunk复制 Master复制 数据完整性：chunk分为64KB的块，每个块对应32bit的checksum 诊断工具：诊断log记录重要的事件和所有RPC请求/回复 Fault-tolerant virtual machines 基本FT设计 确定性重播实现 写入log文件 挑战： 正确捕获所有输入和对确定执行必要的非确定因素 正确将输入和非确定因素应用到备份VM上 不造成性能损失 FT协议 **输出要求：**若备份VM接替了故障的主VM，则备份VM将继续与主VM完全一致地向外界输出 **输出规则：**在备份VM收到并确认与生成输出的操作相关的log之前，主VM不能向外部世界输出 检测和响应故障 FT的实际实现 启动和重启FT VM 关键是以相同状态启动备份VM的机制：FT VMotion 管理Logging Channel 其他重要实现 FT VM上的操作 Disk IO的实现 Network IO的实现 Course Notes FT VM 复制状态机 复制状态机基于这个事实：我们想复制的大部分的服务或者计算机软件都有一些确定的内部操作，不确定的部分是外部的输入 如果有两台计算机，如果它们从相同的状态开始，并且它们以相同的顺序，在相同的时间，看到了相同的输入，那么它们会一直互为副本，并且一直保持一致 VMware FT论文讨论的都是复制状态机，并且只涉及了单核CPU 在多核的机器中，两个核交互处理指令的行为是不确定的，所以就算Primary和Backup执行相同的指令，在多核的机器中，它们也不一定产生相同的结果 如果我们要创建一个新的副本，我们别无选择，只能使用状态转移，因为新的副本需要有完整状态的拷贝。所以创建一个新的副本代价会很高 非确定性事件 客户端输入： 当我们说输入的时候，我们实际上是指接收到了一个网络数据包 数据包中的数据 提示数据包送达了的中断 对于Primary和Backup，中断最好要在相同的时间，相同的位置触发，否则执行过程就是不一样的，进而会导致它们的状态产生偏差。所以，我们不仅关心网络数据包的内容，还关心中断的时间 怪异指令： 随机数生成器 获取当前时间的指令，在不同时间调用会得到不同的结果 获取计算机的唯一ID 多CPU并发： 当服务运行在多CPU上时，指令在不同的CPU上会交织在一起运行，进而产生的指令顺序是不可预期的 输出控制 Primary和Backup虚机都会生成回复报文，之后通过模拟的网卡送出，但是只有Primary虚机才会真正的将回复送出，而Backup虚机只是将回复简单的丢弃掉 控制输出规则：直到Backup虚机确认收到了相应的Log条目，Primary虚机不允许生成任何输出 Primary会等到Backup已经有了最新的数据，才会将回复返回给客户端。这几乎是所有的复制方案中对于性能产生伤害的地方，在某个时间点，Primary必须要停下来等待Backup Test-and-Set服务 Primary和Backup都在运行，但是它们之间的网络出现了问题，同时它们各自又能够与一些客户端通信，这样会产生Split Brain问题 Test-and-Set服务会在内存中保留一些标志位，当你向它发送一个Test-and-Set请求，它会设置标志位，并且返回旧的值，Primary和Backup都需要获取Test-and-Set标志位，类似锁 为了能够上线，Primary和Backup或许会同时发送一个Test-and-Set请求给Test-and-Set服务。当第一个请求送达时，Test-and-Set服务会说，这个标志位之前是0，现在是1。第二个请求送达时，Test-and-Set服务会说，标志位已经是1了，你不允许成为Primary Raft Majority Vote 在任何时候为了完成任何操作，你必须凑够过半的服务器来批准相应的操作 如果系统有 $2F+1$ 个服务器，那么系统最多可以接受 $F$ 个服务器出现故障，仍然可以正常工作 Raft初探 Raft会以库（Library）的形式存在于服务中：如果有一个基于Raft的多副本服务，那么每个服务的副本将会由两部分组成：应用程序代码和Raft库 日志 Log是Leader用来对操作排序的一种手段，Log是一些按照数字编号的槽位（类似一个数组），槽位的数字表示了Leader选择的顺序 在一个Follower收到了操作，但是还没有执行操作时，需要将这个操作存放在某处，直到收到了Leader发送的新的commit号才执行，对于Raft的Follower来说，Log是用来存放临时操作的地方 Leader需要在它的Log中记录操作，因为这些操作可能需要重传给Follower，即使对那些已经commit的请求，为了能够向丢失了相应操作的副本重传，也需要存储在Leader的Log中 可以帮助重启的服务器恢复状态，每个Raft节点都需要将Log写入到它的磁盘中，这样它故障重启之后，Log还能保留 **注：**从Log上无法直接观察出某一条日志是否已经commit 应用层接口 在Raft集群中，每一个副本上，这两层之间主要有两个接口 第一个接口是key-value层用来转发客户端请求的接口。如果客户端发送一个请求给key-value层，key-value层会将这个请求转发给Raft层，并说：请将这个请求存放在Log中的某处。这个接口实际上是个函数调用，称之为Start函数。这个函数只接收一个参数，就是客户端请求。key-value层说：我接到了这个请求，请把它存在Log中，并在committed之后告诉我 另一个接口是，随着时间的推移，Raft层会通知key-value层：你刚刚在Start函数中传给我的请求已经commit了。这个向上的接口以go channel中的一条消息的形式存在。Raft层会发出这个消息，key-value层要读取这个消息。所以这里有个叫做applyCh的channel，通过它你可以发送ApplyMsg消息 key-value层需要知道从applyCh中读取的消息，对应之前调用的哪个Start函数，所以Start函数需要返回这个请求将会存放在Log中的位置（index）以及当前的任期号（term number）和一些其它我们现在还不太关心的内容 在ApplyMsg中，将会包含请求（command）和对应的Log位置（index）。所有的副本都会收到这个ApplyMsg消息，它们都知道自己应该执行这个请求，弄清楚这个请求的具体含义，并将它应用在本地的状态中。所有的副本节点还会拿到Log的位置信息（index），但是这个位置信息只在Leader有用，因为Leader需要知道ApplyMsg中的请求究竟对应哪个客户端请求（进而响应客户端请求） Leader选举 Raft生命周期中可能会有不同的Leader，它使用任期号（term number）来区分不同的Leader Followers（非Leader副本节点）不需要知道Leader的ID，它们只需要知道当前的任期号 每个Raft节点都有一个选举定时器（Election Timer），如果在这个定时器时间耗尽之前，当前节点没有收到任何当前Leader的消息，这个节点会认为Leader已经下线，并开始一次选举，当前服务器会增加任期号（term number），因为它想成为一个新的Leader 之后，当前服务器会发出请求投票（RequestVote）RPC，这个消息会发给所有的Raft节点 如果有一场新的选举，有可能之前的Leader仍然在运行，并认为自己还是Leader。我们也需要关心，在不知道有新的选举时，旧的Leader会有什么样的行为？ 确保每个任期最多只有一个Leader：为了能够当选，Raft要求一个候选人从过半服务器中获得认可投票。每个Raft节点，只会在一个任期内投出一个认可选票 如果你赢得了选举，你需要立刻发送一条AppendEntries消息给其他所有的服务器。除非是当前任期的Leader，没人可以发出AppendEntries消息 选举定时器 任何一条AppendEntries消息都会重置所有Raft节点的选举定时器：每一次一个节点重置自己的选举定时器时，都需要重新选择一个随机的超时时间 Raft不能完全避免分割选票（Split Vote），但是可以使得这个场景出现的概率大大降低。Raft通过为选举定时器随机的选择超时时间来达到这一点 选举定时器的超时时间需要至少大于Leader的心跳间隔，实际上由于网络可能丢包，这里你或许希望将下限设置为多个心跳间隔 超时时间的上限： 最大超时时间影响了系统能多快从故障中恢复，这里的上限越大，系统的恢复时间也就越长 不同节点的选举定时器的超时时间差必须要足够长，使得第一个开始选举的节点能够完成一轮选举：至少需要大于发送一条RPC所需要的往返（Round-Trip）时间 日志恢复 Leader使用一种备份机制来探测Followers的Log中，第一个与Leader的Log相同的位置 在获得位置之后，Leader会给Follower发送从这个位置开始的，剩余的全部Log 选举约束 为了保证系统的正确性，并非任意节点都可以成为Leader 在处理别节点发来的RequestVote RPC时，需要做一些检查才能投出赞成票： 候选人最后一条Log条目的任期号大于本地最后一条Log条目的任期号 或者，候选人最后一条Log条目的任期号等于本地最后一条Log条目的任期号，且候选人的Log记录长度大于等于本地Log记录的长度 快速恢复 让Follower返回足够的信息给Leader，这样Leader可以以任期（Term）为单位来回退，而不用每次只回退一条Log条目 XTerm：Follower中与Leader冲突的Log对应的任期号。Leader会在prevLogTerm中带上本地Log记录中，前一条Log的任期号。如果Follower在对应位置的任期号不匹配，它会拒绝Leader的AppendEntries消息，并将自己的任期号放在XTerm中。如果Follower在对应位置没有Log，那么这里会返回 -1 XIndex：Follower中，对应任期号为XTerm的第一条Log条目的槽位号 XLen：如果Follower在对应位置没有Log，那么XTerm会返回-1，XLen表示空白的Log槽位数 case1： 12S1: 4 5 5S2: 4 6 6 6 Follower（S1）会返回XTerm=5，XIndex=2。Leader（S2）发现自己没有任期5的日志，它会将自己本地记录的，S1的nextIndex设置到XIndex，也就是S1中，任期5的第一条Log对应的槽位号。所以，如果Leader完全没有XTerm的任何Log，那么它应该回退到XIndex对应的位置（这样，Leader发出的下一条AppendEntries就可以一次覆盖S1中所有XTerm对应的Log） case2： 12S1: 4 4 4S2: 4 6 6 6 Follower（S1）会返回XTerm=4，XIndex=1。Leader（S2）发现自己其实有任期4的日志，它会将自己本地记录的S1的nextIndex设置到本地在XTerm位置的Log条目后面，也就是槽位2。下一次Leader发出下一条AppendEntries时，就可以一次覆盖S1中槽位2和槽位3对应的Log case3： 12S1: 4S2: 4 6 6 6 Follower（S1）会返回XTerm=-1，XLen=2。这表示S1中日志太短了，以至于在冲突的位置没有Log条目，Leader应该回退到Follower最后一条Log条目的下一条，也就是槽位2，并从这开始发送AppendEntries消息。槽位2可以从XLen中的数值计算得到 持久化 Log需要被持久化存储的原因是，这是唯一记录了应用程序状态的地方 currentTerm和votedFor都是用来确保每个任期只有最多一个Leader 如果一个服务器收到了一个RequestVote请求，并且为服务器1投票了，之后它故障。如果它没有存储它为哪个服务器投过票，当它故障重启之后，收到了来自服务器2的同一个任期的另一个RequestVote请求，那么它还是会投票给服务器2，因为它发现自己的votedFor是空的 存储currentTerm是为了防止任期回退 安全的做法是每次你添加一个Log条目，更新currentTerm或者更新votedFor。可以通过一些批量操作来提升性能。例如，只在服务器回复一个RPC或者发送一个RPC时，服务器才进行持久化存储 如果Leader收到了一个客户端请求，在发送AppendEntries RPC给Followers之前，必须要先持久化存储在本地；在回复AppendEntries 消息之前，Followers也需要持久化存储这些Log条目到本地 服务器重启时，commitIndex、lastApplied、nextIndex、matchIndex可以被丢弃，因为Leader可以通过检查自己的Log和发送给Followers的AppendEntries的结果，来发现哪些内容已经commit了 日志快照 快照背后的思想是，要求应用程序将其状态的拷贝作为一种特殊的Log条目存储下来 对于大多数的应用程序来说，应用程序的状态远小于Log的大小（如KV数据库） 如果Raft要求应用程序做一个快照，Raft会从Log中选取一个与快照对应的点，然后要求应用程序在那个点的位置做一个快照，然后我们可以安全的将那个点之前的Log丢弃；我们还需要为快照标注Log的槽位号 只要Raft持久化存储了快照，快照对应的Log槽位号，以及Log槽位号之后的所有Log，那么快照对应槽位号之前的这部分Log可以被丢弃 重启的时候，必须让Raft有方法知道磁盘中最近的快照和Log的组合，并将快照传递给应用程序。所以应用程序不仅需要有能力能生成一个快照，它还需要能够吸纳一个之前创建的快照，并通过它稳定的重建自己的内存 如果Leader发现有任何一个Follower的Log落后于Leader要做快照的点，Leader可以丢弃Follower需要的Log，但需要某种机制让AppendEntries能处理某些Follower Log的结尾到Leader Log开始之间丢失的这一段Log，即InstallSnapshot RPC 当Leader回退到了自己Log的起点，将不能再回退。这时，Leader会将自己的快照发给Follower，之后立即通过AppendEntries将后面的Log发给Follower 线性一致 一个服务是线性一致的，那么它表现的就像只有一个服务器，并且服务器没有故障，这个服务器每次执行一个客户端请求，并且没什么奇怪的事情发生 如果执行历史整体可以按照一个顺序排列，且排列顺序与客户端请求的实际时间相符合，那么它是线性一致的 一个线性一致的执行历史中的操作是非并发的，也就是时间上不重合的客户端请求与实际执行时间匹配 确定执行顺序： 如果一个操作在另一个操作开始前就结束了，那么这个操作必须在执行历史中出现在另一个操作前面 执行历史中，读操作，必须在相应的key的写操作之后 对于读请求，线性一致系统只能返回最近一次完成的写请求写入的值 Client交互 源自Raft作者博士论文Ch6 寻找Leader Client发送请求到随机节点，节点有两种处理方式： 节点可能通过Leader的AppendEntries RPC知道了LeaderId，从而可以将此信息传递给client； 节点作为代理，将请求转发给Leader。 Raft必须防止过期的Leadership信息 Leader：某个节点处于Leader的状态，但不是当前整个集群的Leader，若client将请求发送给此节点，将永远得不到回复，因为该节点不能得到大部分节点的同意。解决方案： 若Leader没有收到集群中大部分节点的心跳回复，则会自动退位，使得client能请求其他节点 Follower：当Follower开启一轮选举或任期改变时，不能回复client的请求，防止几个节点相互redirect Client：若client与节点失去连接，需要随机请求另一个节点 实现线性一致 Raft中，复制状态机可能会apply一条命令多次，为了实现线性一致，不能允许重复执行 节点保存client操作的结果，当client重发相同请求时，直接回复结果而不执行请求 给与每个client一个唯一标识，client为每条命令分配一个唯一序号 每个节点的状态机为每个client维护一个session，来跟踪client的最新命令序号以及响应的回复 当节点收到同一个client相同序号的命令时，直接回复session中的结果 在并发环境下，节点维护的session应该包含多个序号-回复pair，client在每个请求中包含其还未收到回复的最小的序号，节点根据此来丢弃更小的序号-回复pair 由于存储空间有限，在client session越来越多之后，节点必须丢弃一些client session 所有节点必须对丢弃的session达成共识，因此session丢弃必须是确定性的，可选方案： 设置session数量上限，根据LRU (Least Recently Used) 策略丢弃session 基于时间共识来丢弃session 处理在session过期后仍不断发送请求的client，可选方案： 为该client重新分配一个新的session，但这有命令重复执行的风险（在该client上一个session中可能已经执行过该命令） 节点区分新client和session过期的client：新client发送RegisterClient RPC来请求一个session，若节点收到的命令请求中包含过期的session，则返回error 更高效地执行只读请求 只读请求可以直接进行而不记录log (防止对磁盘的同步写) ，但是需要一些额外处理，否则可能回复过时数据 若Leader还没将自己任期的log条目标记为committed，则等待标记完成。由于Leader刚上任时不知道自己的哪些log已经commit了，所以他需要在自己任期开始时往自己的log中添加一条空的 no-op 条目，当该条目commit之后，Leader的 commitIndex 至少和其他节点一样大； Leader保存一个本地变量 readIndex 来记录当前的 commitIndex ，这将被用作是请求操作的状态的最低版本 Leader需要确保自己没有被更新的Leader取代，为此他发起一轮新的心跳消息，并等待大部分节点的确认，若得到大部分的确认，则Leader知道此时的 readIndex 是所有节点中最大的 commitIndex Leader等待其状态机执行到至少 readIndex ，至此所有操作都是线性一致的 最后，Leader直接查询状态机来获得client只读请求的结果，而不需要记录log 进一步优化：Leader可以积累一定数量的只读请求，然后通过一轮心跳消息来同时执行 进进一步优化：Follower也可以处理只读请求，首先向Leader发送请求来获取 readIndex ，然后Leader执行1-3步并回复Follower，最后Follower执行4-5步 Zookeeper 提高读性能 加入的服务器越多，读性能越高 Zookeeper并不要求返回最新的写入数据，即放弃线性一致性 从而client可以从Follower读取数据 一致保证 写请求线性一致 client请求会根据指定顺序执行，即FIFO client顺序 写请求一定会满足，因为写请求必须满足线性一致 读请求会发送到非Leader的副本，但是需要满足副本根据client读的顺序执行，即使是从不同的副本读也要满足顺序 每个Log条目都会被Leader打上zxid的标签，这些标签就是Log对应的条目号 任何时候一个副本回复一个客户端的读请求，首先这个读请求是在Log的某个特定点执行的，其次回复里面会带上zxid，对应的就是Log中执行点的前一条Log条目号 客户端会记住最高的zxid，当客户端发出一个请求到一个相同或者不同的副本时，它会在它的请求中带上这个最高的zxid 其他的副本就知道，应该至少在Log中这个点或者之后执行这个读请求 写请求和读请求并发时，读请求需要等到Leader执行完写操作后才能执行 如果一个客户端写了一份数据，例如向Leader发送了一个写请求，之后立即读同一份数据，并将读请求发送给了某一个副本，那么客户端需要看到自己刚刚写入的值 同步操作 Zookeeper有一个操作类型是sync，它本质上就是一个写请求 因为读请求必须至少要看到同一个客户端前一个写请求对应的状态 所以，如果我发送了一个sync请求之后，又发送了一个读请求 Zookeeper必须要向我返回至少是我发送的sync请求对应的状态 这是一个代价很高的操作，因为我们现在将一个廉价的读操作转换成了一个耗费Leader时间的sync操作 Ready文件 znode Zookeeper以文件目录的形式管理数据，所以每一个数据点也可以认为是一个file 假设有另外一个分布式系统，这个分布式有一个Master节点，而Master节点在Zookeeper中维护了一个配置，这个配置对应了一些file（也就是znode） Master节点对配置的更新需要是原子性的： 假设Master做了一系列写请求来更新配置，那么我们的分布式系统中的Master会以这种顺序执行写请求 假设有一些Ready file，如果Ready file存在，那么允许读这个配置；如果Ready file不存在，那么说明配置正在更新过程中，我们不应该读取配置 如果Master要更新配置，那么第一件事情是删除Ready file 之后它会更新各个保存了配置的Zookeeper file（也就是znode） 当所有组成配置的file都更新完成之后，Master会再次创建Ready file Worker节点对配置的读取 如果客户端看见了Ready file，那么副本接下来执行的读请求，会在Ready file重新创建的位置之后执行 Zookeeper可以保证这些读请求看到之前对于配置的全部更新 防止客户端读到不同版本的配置文件（Master更新配置，删除Ready file，客户端同时读到了一个Worker没来得及删除的Ready file，并读取了部分znode，然后等Master更新完，Worker重新创建Ready file后，客户端再读完剩下的znode）： 客户端会发送exists请求来查询Ready file是否存在，并建立一个针对这个Ready file的watch 如果Ready file有任何变更，例如被删除了，或者它之前不存在然后被创建了，副本会给客户端发送一个通知 当Ready file有变化时，副本会确保，合适的时机返回对于Ready file变化的通知 如果客户端向某个副本watch了某个Ready file，之后又发送了一些读请求，当这个副本执行了一些会触发watch通知的请求，那么Zookeeper可以确保副本将watch对应的通知，先发给客户端，再处理触发watch通知请求（也就是删除Ready file的请求），在Log中位置之后才执行的读请求 换句话说，客户端在完成读所有的配置之前，如果对配置有了新的更改，Zookeeper可以保证客户端在收到删除Ready file的通知之前，看到的都是配置更新前的数据（即，客户端读取配置读了一半，如果收到了Ready file删除的通知，就可以放弃这次读，再重试读） Zookeeper作用 Zookeeper的数据都存在内存，因此只适合于存储配置信息 它可以是一个VMware FT所需要的Test-and-Set服务的实现 用它来发布其他服务器使用的配置信息。例如，向某些Worker节点发布当前Master的IP地址 选举Master，当一个旧的Master节点故障时，我们需要让所有的节点都认可同一个新的Master节点 用Zookeeper来保存Master的状态，新的Master从Zookeeper读取状态，从而保证其状态是up-to-date的 类似MapReduce的系统： Worker节点可以通过在Zookeeper中创建小文件来注册自己 Master节点通过向Zookeeper写入具体的工作，之后Worker节点从Zookeeper中一个一个的取出工作、执行，完成之后再删除工作 Zookeeper API Zookeeper的API某种程度上来说像是一个文件系统：它有一个层级化的目录结构，有一个根目录（root），之后每个应用程序有自己的子目录。比如说应用程序1将自己的文件保存在APP1目录下，应用程序2将自己的文件保存在APP2目录下，这些目录又可以包含文件和其他的目录 Zookeeper被设计成要被许多可能完全不相关的服务共享使用，所以我们需要一个命名系统来区分不同服务的信息，这样这些信息才不会弄混 这里的文件和目录都被称为znodes，Zookeeper中包含了3种类型的znode Regular znodes：这种znode一旦创建，就永久存在，除非你删除了它 Ephemeral znodes：如果Zookeeper认为创建它的客户端挂了，它会删除这种类型的znodes Ephemeral znodes与客户端会话绑定在一起，所以客户端需要时不时的发送心跳给Zookeeper，告诉Zookeeper自己还活着，这样Zookeeper才不会删除客户端对应的Ephemeral znode Sequential znodes：当你想要以特定的名字创建一个文件，Zookeeper实际上创建的文件名是你指定的文件名再加上一个数字。当有多个客户端同时创建Sequential文件时，Zookeeper会确保这里的数字不重合，同时也会确保这里的数字总是递增的 Zookeeper以RPC的方式暴露以下API： CREATE(PATH，DATA，FLAG)：入参分别是文件的全路径名PATH，数据DATA，和表明znode类型的FLAG 如果我向Zookeeper请求创建一个文件，如果我得到了yes的返回，那么说明这个文件之前不存在，我是第一个创建这个文件的客户端 如果我得到了no或者一个错误的返回，那么说明这个文件之前已经存在了 DELETE(PATH，VERSION)：入参分别是文件的全路径名PATH，和版本号VERSION 每一个znode都有一个表示当前版本号的version，当znode有更新时，version也会随之增加 对于delete和一些其他的update操作，可以增加一个version参数，表明当且仅当znode的当前版本号与传入的version相同，才执行操作 EXIST(PATH，WATCH)：入参分别是文件的全路径名PATH，和一个有趣的额外参数WATCH 通过指定watch，你可以监听对应文件的变化，Zookeeper可以确保如果文件有任何变更，例如创建，删除，修改，都会通知到客户端 判断文件是否存在和watch文件的变化，在Zookeeper内是原子操作 所以，当调用exist并传入watch为true时，不可能在Zookeeper实际判断文件是否存在和建立watch通道之间，插入任何的创建文件的操作，这对于正确性来说非常重要 GETDATA(PATH，WATCH)：入参分别是文件的全路径名PATH，和WATCH标志位 这里的watch监听的是文件的内容的变化 SETDATA(PATH，DATA，VERSION)：入参分别是文件的全路径名PATH，数据DATA，和版本号VERSION Zookeeper当且仅当文件的版本号与传入的version一致时，才会更新文件 LIST(PATH)：入参是目录的路径名，返回的是路径下的所有文件 使用Zookeeper实现计数器 假设我们在Zookeeper中有一个文件，我们想要在那个文件存储一个统计数字，例如，统计客户端的请求次数 需要保证获取计数值和增加计数值的操作的原子性 1234WHILE TRUE: X, V &#x3D; GETDATA(&quot;F&quot;) IF SETDATA(&quot;f&quot;, X + 1, V): BREAK 第3行的意思是，只有当实际真实的版本号等于V的时候，才更新数据 使用Zookeeper实现非扩展锁 获得锁： 1234WHILE TRUE: IF CREATE(&quot;f&quot;, data, ephemeral&#x3D;TRUE): RETURN IF EXIST(&quot;f&quot;, watch&#x3D;TRUE): WAIT 在代码的第2行，是尝试创建锁文件，如果锁文件创建成功了，表明我们获得了锁，直接RETURN 如果锁文件创建失败了，那表明锁已经被别人占住了，所以我们需要等待锁释放。最终锁会以删除文件的形式释放，所以我们这里通过EXIST函数加上watch=TRUE，来监测文件的删除 在代码的第4行，等待文件删除对应的watch通知。收到通知之后，再回到循环的最开始，从代码的第2行开始执行 如果有1000个客户端同时要获得锁文件，为1000个客户端分发锁所需要的时间是 $O(n^2)$ （羊群效应） 因为每一次锁文件的释放，所有剩下的客户端都会收到WATCH的通知，并且回到循环的开始，再次尝试创建锁文件。所以CREATE对应的RPC总数与1000的平方成正比 使用Zookeeper实现可扩展锁 避免羊群效应，使得，即使有1000个客户端在等待锁释放，当锁释放时，另一个客户端获得锁的复杂度是 $O(1)$ 而不是 $O(n)$ 123456CREATE(&quot;f&quot;, data, sequential&#x3D;TRUE, ephemeral&#x3D;TRUE)WHILE TRUE: LIST(&quot;f*&quot;) IF NO LOWER #FILE: RETURN IF EXIST(NEXT LOWER #FILE, watch&#x3D;TRUE): WAIT 第1行调用CREATE，并指定sequential=TRUE，我们创建了一个Sequential文件，如果这是以“f”开头的第27个Sequential文件，这里实际会创建类似以“f27”为名字的文件 通过CREATE获得一个全局唯一序列号 Zookeeper生成的序号必然是递增的 第3行，通过LIST列出了所有以“f”开头的文件，也就是所有的Sequential文件 第4行，如果现存的Sequential文件的序列号都不小于我们在代码第1行得到的序列号，那么表明我们在并发竞争中赢了，我们获得了锁 当存在更低序列号的Sequential文件时，我们要做的是等待拥有更低序列号的客户端释放锁 在这个方案中，释放锁的方式是删除文件。所以接下来，我们需要做的是等待序列号更低的锁文件删除，之后我们才能获得锁 第5行，我们调用EXIST，并设置WATCH，等待比自己序列号更小的下一个锁文件删除 如果等到了，回到LIST开始执行，之所以要重新LIST，是因为比自己低的序号的客户端可能是释放锁才删除文件，也可能是挂了所以删除文件，例如，序号27等待26号释放锁，但如果26号客户端挂了，则需要等待25号释放锁，从而必须重新LIST Zookeeper中的锁不是原子性的，适合用于Soft Lock的场景，如运行MapReduce Job时，你可以用这样的锁来确保一个Task同时只被一个Work节点执行。例如，对于Task 37，执行它的Worker需要先获得相应的锁，再执行Task，并将Task标记成执行完成，之后释放锁。MapReduce本身可以容忍Worker节点崩溃，所以如果一个Worker节点获得了锁，然后执行了一半崩溃了，之后锁会被释放，下一个获得锁的Worker会发现任务并没有完成，并重新执行任务 CRAQ CRAQ是对于一个叫链复制（Chain Replication）的旧方案的改进，它在任意副本上执行读请求的前提下，还可以保证线性一致性 链复制 Chain Replication是这样一种方案，你有多个副本，你想确保它们都看到相同顺序的写请求（这样副本的状态才能保持一致） 在Chain Replication中，有一些服务器按照链排列，第一个服务器称为HEAD，最后一个被称为TAIL 当客户端想要发送一个写请求，写请求总是发送给HEAD HEAD根据写请求更新本地数据，我们假设现在是一个支持PUT/GET的key-value数据库，所有的服务器本地数据都从A开始 当HEAD收到了写请求，将本地数据更新成了B，之后会再将写请求通过链向下一个服务器传递 下一个服务器执行完写请求之后，再将写请求向下一个服务器传递，以此类推，所有的服务器都可以看到写请求 当写请求到达TAIL时，TAIL将回复发送给客户端，表明写请求已经完成了 对于读请求，如果一个客户端想要读数据，它将读请求发往TAIL TAIL直接根据自己的当前状态来回复读请求 故障恢复 如果HEAD出现故障，作为最接近的服务器，下一个节点可以接手成为新的HEAD，并不需要做任何其他的操作。对于还在处理中的请求，可以分为两种情况： 对于任何已经发送到了第二个节点的写请求，不会因为HEAD故障而停止转发，它会持续转发直到commit 如果HEAD在转发这个写请求之前就故障了，那么这个写请求必然没有commit，写请求必然没能送到TAIL，对于这些请求不必做任何事情。或许客户端会重发这个写请求，但是这并不是我们需要担心的问题 如果TAIL出现故障，TAIL的前一个节点可以接手成为新的TAIL。所有TAIL知道的信息，TAIL的前一个节点必然都知道 中间节点出现故障会稍微复杂一点，但是基本上来说，需要做的就是将故障节点从链中移除。或许有一些写请求被故障节点接收了，但是还没有被故障节点之后的节点接收，所以，当我们将其从链中移除时，故障节点的前一个节点或许需要重发最近的一些写请求给它的新后继节点 配置管理器 Chain Replication并不能抵御网络分区，也不能抵御脑裂。因此需要一个外部的权威（External Authority）来决定那些节点是活的，并确保所有参与者都认可由哪些节点组成一条链，这个外部的权威通常称为Configuration Manager Configuration Manager的工作就是监测节点存活性，一旦Configuration Manager认为一个节点挂了，它会生成并送出一个新的配置，在这个新的配置中，描述了链的新的定义，包含了链中所有的节点，HEAD和TAIL，所有节点都会遵从新的配置内容 Configuration Manager通常会基于Raft或者Paxos，在CRAQ的场景下，它会基于Zookeeper 对于一个数据中心，首先有一个基于Raft或者Paxos的Configuration Manager，它是容错的，也不会受脑裂的影响 之后，通过一系列的配置更新通知，Configuration Manager将数据中心内的服务器分成多个链 Configuration Manager通告给所有参与者整个链的信息，所以所有的客户端都知道HEAD在哪，TAIL在哪，所有的服务器也知道自己在链中的前一个节点和后一个节点是什么 Aurora 故障可恢复事务 通常来说，事务是通过对涉及到的每一份数据加锁来实现： 对于一个简单的数据库模型，数据库运行在单个服务器上，并且使用本地硬盘 在硬盘上存储了数据的记录，有一些data page用来存放数据库的数据，其中一个存放了X的记录，另一个存放了Y的记录。每一个data page通常会存储大量的记录，而X和Y的记录是page中的一些bit位 在硬盘中，除了有数据之外，还有一个预写式日志（Write-Ahead Log，简称为WAL） 在服务器内部，有数据库软件，通常数据库会对最近从磁盘读取的page有缓存 当你在执行一个事务内的各个操作时，例如执行 X=X+10 的操作时，数据库会从硬盘中读取持有X的记录，给数据加10 但是在事务提交之前，数据的修改还只在本地的缓存中，并没有写入到硬盘 为了让数据库在故障恢复之后，还能够提供同样的数据，在允许数据库软件修改硬盘中真实的data page之前，数据库软件需要先在WAL中添加Log条目来描述事务 假设，X的初始值是500，Y的初始值是750 在提交并写入硬盘的data page之前，数据库通常需要写入至少3条Log记录： 第一条表明，作为事务的一部分，我要修改X，它的旧数据是500，我要将它改成510 第二条表明，我要修改Y，它的旧数据是750，我要将它改成740 第三条记录是一个Commit日志，表明事务的结束 记录旧数据是为了对于一个非常长的事务，在事务结束之前，数据库可以提前将更新了的page写入硬盘；之后如果在事务提交之前故障了，恢复的软件可以发现，事务并没有完成，然后根据WAL中的日志撤回之前的操作 如果数据库成功的将事务对应的操作和commit日志写入到磁盘中，数据库可以回复给客户端说，事务已经提交了，接下来有两种情况： 如果数据库没有崩溃，那么在它的cache中，X，Y对应的数值分别是510和740。最终数据库会将cache中的数值写入到磁盘对应的位置。所以数据库写磁盘是一个lazy操作，它会对更新进行累积，每一次写磁盘可能包含了很多个更新操作 如果数据库在将cache中的数值写入到磁盘之前就崩溃了，这样磁盘中的page仍然是旧的数值。当数据库重启时，恢复软件会扫描WAL日志，发现对应事务的Log，并发现事务的commit记录，那么恢复软件会将新的数值写入到磁盘中。这被称为redo，它会重新执行事务中的写操作 Aurora 初探 在替代EBS的位置，有6个数据的副本，位于3个AZ，每个AZ有2个副本。所以现在有了超级容错性，并且每个写请求都需要以某种方式发送给这6个副本，这里通过网络传递的数据只有Log条目 这里的存储系统不再是通用（General-Purpose）存储，这是一个可以理解MySQL Log条目的存储系统 Aurora并不需要6个副本都确认了写入才能继续执行操作，只要Quorum形成了，也就是任意4个副本确认写入了，数据库就可以继续执行操作 Aurora存储服务器的容错目标 对于写操作，当只有一个AZ彻底挂了之后，写操作不受影响 对于读操作，当一个AZ和一个其他AZ的服务器挂了之后，读操作不受影响 AZ的下线时间可能很长，比如说数据中心被水淹了。人们可能需要几天甚至几周的时间来修复洪水造成的故障，在AZ下线的这段时间，我们只能依赖其他AZ的服务器。如果其他AZ中的一个服务器挂了，我们不想让整个系统都瘫痪。所以当一个AZ彻底下线了之后，对于读操作，Aurora还能容忍一个额外服务器的故障，并且仍然可以返回正确的数据 Aurora期望能够容忍暂时的慢副本 如果一个服务器看起来永久故障了，我们期望能够尽可能快的根据剩下的副本，生成一个新的副本 Quorum 复制机制 通常来说，Quorum系统就是简单的读写系统，支持Put/Get操作 假设有N个副本。为了能够执行写请求，必须要确保写操作被W个副本确认，W小于N。所以你需要将写请求发送到这W个副本。如果要执行读请求，那么至少需要从R个副本得到所读取的信息。这里的W对应的数字称为Write Quorum，R对应的数字称为Read Quorum。Quorum系统要求，任意你要发送写请求的W个服务器，必须与任意接收读请求的R个服务器有重叠。这意味着，R加上W必须大于N（ 至少满足R + W = N + 1 ），这样任意W个服务器至少与任意R个服务器有一个重合 可以轻易的剔除暂时故障、失联或者慢的服务器 可以调整读写的性能 Aurora读写存储服务器 Aurora中的写请求并不是像一个经典的Quorum系统一样直接更新数据。对于Aurora来说，它的写请求从来不会覆盖任何数据，它的写请求只会在当前Log中追加条目（Append Entries）。所以，Aurora使用Quorum只是在数据库执行事务并发出新的Log记录时，确保Log记录至少出现在4个存储服务器上，之后才能提交事务 但是存储服务器内存最终存储的还是数据库服务器磁盘中的page。在存储服务器的内存中，会有自身磁盘中page的cache，例如page1（P1），page2（P2），这些page其实就是数据库服务器对应磁盘的page 当一个新的写请求到达时，这个写请求只是一个Log条目，Log条目中的内容需要应用到相关的page中。但是我们不必立即执行这个更新，可以等到数据库服务器或者恢复软件想要查看那个page时才执行 对于每一个page，如果它最近被一个Log条目修改过，那么存储服务器会在内存中缓存一个旧版本的page和一系列来自于数据库服务器有关修改这个page的Log条目，所以对于一个新的Log条目，它会立即被追加到影响到的page的Log列表中（这里的Log列表从上次page更新过之后开始） 如果之后数据库服务器将自身缓存的page删除了，过了一会又需要为一个新的事务读取这个page，它会发出一个读请求到存储服务器，并要求存储服务器返回当前最新的page数据。这个时候，存储服务器才会将Log条目中的新数据更新到page，并将page写入到自己的磁盘中，之后再将更新了的page返回给数据库服务器，同时存储服务器在自身cache中会删除page对应的Log列表，并更新cache中的page 数据分片 为了能支持超过10TB数据的大型数据库。Amazon的做法是将数据库的数据，分割存储到多组存储服务器上，每一组都是6个副本，称为一个PG（Protection Group），分割出来的每一份数据是10GB 当Aurora需要发送一个Log条目时，它会查看Log所修改的数据，并找到存储了这个数据的PG，并把Log条目只发送给这个PG对应的6个存储服务器。所以，每个PG只存储了部分data page和所有与这些data page关联的Log条目 如果其中一个存储服务器挂了，我们期望尽可能快的用一个新的副本替代它。而一个存储服务器可能会存储10TB数据，也就是数百个PG，若它挂了，需要恢复整个服务器的数据，通过网络传输10TB消耗的时间太长了，因此需要一个更高效的恢复方案 Aurora实际使用的策略是，对于一个特定的存储服务器，它存储了许多Protection Group对应的10GB的数据块。对于Protection Group A，它的其他副本是5个服务器 或许这个存储服务器还为Protection Group B保存了数据，但是B的其他副本存在于与A没有交集的其他5个服务器中 这种模式下，如果一个存储服务器挂了，假设上面有100个数据块，现在的替换策略是：找到100个不同的存储服务器，其中的每一个会被分配一个数据块，也就是说这100个存储服务器，每一个都会加入到一个新的Protection Group中（相当于每一个存储服务器只需要负责恢复10GB的数据，并且可以并行恢复） Frangipani Frangipani 挑战 假设工作站W1创建了一个文件 /A。最初，这个文件只会在本地缓存中创建。首先，Frangipani需要从Petal获得 / 目录下的内容，之后当创建文件时，工作站只是修改缓存的拷贝，并不会将修改立即返回给Petal。直接的问题是：假设工作站W2上的用户想要获取 / 目录下的文件列表，我们希望这个用户可以看到新创建的文件。这称为缓存一致性问题（Cache Coherence） 因为所有的文件和目录都是共享的，非常容易会有两个工作站在同一个时间修改同一个目录，我们期望看到的是两个工作站的修改都可以生效，且互不干扰。这称为原子性（Atomicity） 假设我的工作站修改了大量的内容，由于Write-Back缓存，可能会在本地的缓存中堆积了大量的修改。如果我的工作站崩溃了，但是这时这些修改只有部分同步到了Petal，还有部分仍然只存在于本地。同时，其他的工作站还在使用文件系统。那么，我的工作站在执行操作的过程中的崩溃，最好不要损坏其他人同样会使用的文件系统。因此我们需要的是单个服务器的故障恢复 锁服务器 Frangipani的缓存一致性核心是由锁保证的，用锁来帮助工作站确定当它们缓存了数据时，它们缓存的是最新的数据 在锁服务器里面，有一个表单，就叫做locks。我们假设每一个锁以文件名来命名，所以对于每一个文件，我们都有一个锁，而这个锁，可能会被某个工作站所持有 在每个工作站，会记录跟踪它所持有的锁，和锁对应的文件内容。所以在每个工作站中，Frangipani模块也会有一个lock表单，表单会记录文件名、对应的锁的状态和文件的缓存内容 当一个Frangipani服务器决定要读取文件，首先它会向一个锁服务器请求文件对应的锁，之后才会向Petal服务器请求文件或者目录的数据 收到数据之后，工作站会记住，本地有一个文件X的拷贝，对应的锁的状态，和相应的文件内容 在工作站完成了一些操作之后，比如创建文件，或者读取文件，它会随着相应的系统调用（例如rename，write，create，read）释放锁（在做操作期间，锁的状态是Busy） 但是从锁服务器的角度来看，工作站仍然持有锁。工作站内部会标明，这是锁时Idle状态，它不再使用这个锁 Frangipani对锁应用了很多的规则： 工作站不允许持有缓存的数据，除非同时也持有了与数据相关的锁 如果你在释放锁之前，修改了锁保护的数据，那你必须将修改了的数据写回到Petal，只有在Petal确认收到了数据，你才可以释放锁 最后才能从工作站的lock表单中删除关文件的锁的记录和缓存的数据 缓存一致性 工作站和锁服务器之间的缓存一致协议协议包含了4种不同的消息： Request消息：从工作站发给锁服务器。Request消息会说：hey锁服务器，我想获取这个锁 Grant消息：一旦工作站Request的锁被释放了，锁服务器会回复一个Grant消息给工作站 Revoke消息：通常来说，当工作站使用完锁之后，不会向锁服务器释放锁。如果锁服务器收到了一个加锁的请求，它查看自己的lock表单可以发现，这个锁现在正被工作站WS1所持有，锁服务器会发送一个Revoke消息给当前持有锁的工作站WS1，并说：现在别人要使用这个文件，请释放锁吧 Release消息：当一个工作站收到了一个Revoke请求，如果锁时在Idle状态，并且缓存的数据脏了，工作站会首先将修改过的缓存写回到Petal存储服务器中，然后发送一条Release消息来释放锁 如果工作站收到Revoke消息时，它还在使用锁，直到它完成了相应的文件系统操作，它都不会放弃锁；完成了操作之后，工作站中的锁的状态才会从Busy变成Idle，之后工作站才能注意到Revoke请求，在向Petal写完数据之后最终释放锁 一个主要的优化是，Frangipani有共享的读锁（Shared Read Lock）和排他的写锁（Exclusive Write Lock） 原子性 为了实现原子性，Frangipani在内部实现了一个数据库风格的事务系统，并且是以锁为核心。同时，这是一个分布式事务系统 Frangipani是这样实现分布式事务的：在我完全完成操作之前，Frangipani确保其他的工作站看不到我的修改 首先我的工作站需要获取所有我需要读写数据的锁，在完成操作之前，我的工作站不会释放任何一个锁 将所有修改了的数据写回到Petal之后，我的工作站才会释放所有的锁 Frangipani Log 需要能正确应对这种场景：一个工作站持有锁，并且在一个复杂操作的过程中崩溃了。比如说一个工作站在创建文件，或者删除文件时，它首先获取了大量了锁，然后会更新大量的数据，在其向Petal回写数据的过程中，一部分数据写入到了Petal，还有一部分还没写入，这时工作站崩溃了，并且锁也没有释放 Frangipani与其他的系统一样，需要通过预写式日志（Write-Ahead Log，WAL）实现故障可恢复的事务（Crash Recoverable Transaction） 当一个工作站需要完成涉及到多个数据的复杂操作时，在工作站向Petal写入任何数据之前，工作站会在Petal中自己的Log列表中追加一个Log条目，这个Log条目会描述整个的需要完成的操作 只有当这个描述了完整操作的Log条目安全的存在于Petal之后，工作站才会开始向Petal发送数据 Frangipani在实现WAL时，有一些不同的地方： 在大部分的事务系统中，只有一个Log，系统中的所有事务都存在于这个Log中；但是Frangipani不是这么保存Log的，它对于每个工作站都保存了一份独立的Log 几乎在所有使用了Log的系统中，Log与运行了事务的计算机紧紧关联在一起，并且几乎总是保存在本地磁盘中；但是Frangipani工作站的Log存储在Petal，而不是本地磁盘中，这样的话如果工作站崩溃了，它的Log可以被其他工作站从Petal中获取到 我们需要大概知道Log条目的内容是什么： 每个Log条目都包含了Log序列号，这个序列号是个自增的数字。因为如果工作站崩溃了，Frangipani需要根据序列号探测工作站Log的结尾 每个Log条目还有一个用来描述一个特定操作中所涉及到的所有数据修改的数组 数组中的每一个元素会有一个Petal中的块号（Block Number），一个版本号和写入的数据 Log只包含了对于元数据的修改，不会包含需要写入文件的数据，所以它并不包含用户的数据 所以写入Petal的完整过程是：当工作站从锁服务器收到了一个Revoke消息，要自己释放某个锁，它需要执行： 首先，工作站需要将内存中还没有写入到Petal的Log条目写入到Petal中 之后，再将被Revoke的Lock所保护的数据写入到Petal 最后，向锁服务器发送Release消息 故障恢复 这里的场景是，当工作站需要重命名文件或者创建一个文件时，首先它会获得所有需要修改数据的锁，之后修改自身的缓存来体现改动。但是后来工作站在向Petal写入数据的过程中故障了。发生故障时可能会有这几种场景： 要么工作站正在向Petal写入Log，所以这个时候工作站必然还没有向Petal写入任何文件或者目录 要么工作站正在向Petal写入修改的文件，所以这个时候工作站必然已经写入了完整的Log 当持有锁的工作站崩溃了之后，发生的第一件事情是锁服务器向工作站发送一个Revoke消息，但是锁服务器得不到任何响应，之后才会触发故障恢复。Frangipani出于一些原因对锁使用了租约，当租约到期了，锁服务器会认定工作站已经崩溃了，之后它会初始化恢复过程 锁服务器会通知另一个还活着的工作站说：看，工作站1看起来崩溃了，请读取它的Log，重新执行它最近的操作并确保这些操作完成了，在你完成之后通知我，在收到这里的通知之后，锁服务器才会释放锁 Frangipani对每一份存储在Petal文件系统数据增加一个版本号，同时将版本号与Log中描述的更新关联起来。当工作站需要修改Petal中的元数据时，它会向从Petal中读取元数据，并查看当前的版本号，之后在创建Log条目来描述更新时，它会在Log条目中对应的版本号填入元数据已有的版本号加1 之后，如果工作站执行到了写数据到Petal的步骤，它也会将新的增加了的版本号写回到Petal。所以，如果一个工作站没有故障，并且成功的将数据写回到了Petal。这样元数据的版本号会大于等于Log条目中的版本号。如果有其他的工作站之后修改了同一份元数据，版本号会更高 分布式事务 分布式事务主要有两部分组成。第一个是并发控制（Concurrency Control）第二个是原子提交（Atomic Commit） 并发控制 在并发控制中，主要有两种策略 悲观并发控制（Pessimistic Concurrency Control）：在悲观系统中，如果有锁冲突，比如其他事务持有了锁，就会造成延时等待。所以这里需要为正确性而牺牲性能 乐观并发控制（Optimistic Concurrency Control）：你不用担心其他的事务是否正在读写你要使用的数据，你直接继续执行你的读写操作，通常来说这些执行会在一些临时区域，只有在事务最后的时候，你再检查是不是有一些其他的事务干扰了你 如果没有这样的其他事务，那么你的事务就完成了，并且你也不需要承受锁带来的性能损耗 如果有一些其他的事务在同一时间修改了你关心的数据，并造成了冲突，那么你必须要Abort当前事务，并重试 讨论悲观并发控制，这里涉及到的基本上就是锁机制。这里的锁是两阶段锁（Two-Phase Locking）： 当事务需要使用一些数据记录时，第一个规则是在使用任何数据之前，在执行任何数据的读写之前，先获取锁 第二个对于事务的规则是，事务必须持有任何已经获得的锁，直到事务提交或者Abort，你不允许在事务的中间过程释放锁 这就是两阶段锁的两个阶段，第一个阶段获取锁，第二个阶段是在事务结束前一直持有锁 缺点是非常容易产生死锁，实际上事务有各种各样的策略，包括了判断循环，超时来判断它们是不是陷入到这样一个场景中。如果是的话，数据库会Abort其中一个事务，撤回它所有的操作，并表现的像这个事务从来没有发生一样 两阶段提交 原子性是指，事务的每一个部分都执行，或者任何一个部分都不执行。两阶段提交（Two-Phase Commit）是一种解决方案 实际上是数据被分割在不同的服务器上，所以相应的任务也被分包在不同的服务器上。假设有一个计算机会用来管理事务，它被称为事务协调者（Transaction Coordinator），事务协调者以某种形式运行事务的代码，例如Put/Get/Add，它向持有了不同数据的其他计算机发送消息，其他计算机再执行事务的不同部分 在一个完整的系统中，或许会有很多不同的并发运行事务，也会有许多个事务协调者在执行它们各自的事务。在这个架构里的各个组成部分，都需要知道消息对应的是哪个事务，所以对于事务，需要有事务ID（Transaction ID），简称为TID 除了TC之外，其他的服务器执行部分的事务，这些服务器被称为参与者（Participants） 我们将Two-Phase Commit简称为2PC。参与者有：事务协调者（TC），我们假设只有两个参与者（A，B），两个参与者就是持有数据的两个不同的服务器 在事务的最开始，TC会向参与者A发送Get请求并得到回复，之后再向参与者B发送一个Put请求并得到回复 之后，当TC到达了事务的结束并想要提交事务，这样才能： 释放所有的锁 使得事务的结果对于外部是可见的 再向客户端回复 在开始执行事务时，TC需要确保，所有的事务参与者能够完成它们在事务中的那部分工作，TC为了确保这一点，会向所有的参与者发送Prepare消息 当A或者B收到了Prepare消息，它们就知道事务要执行但是还没执行的内容，它们会查看自身的状态并决定它们实际上能不能完成事务，并回复Yes/No TC会等待来自于每一个参与者的这些Yes/No投票。如果所有的参与者都回复Yes，那么事务可以提交，不会发生错误；之后TC会发出一个Commit消息，给每一个事务的参与者；之后，事务参与者通常会回复ACK说，我们知道了要commit 如果任何一个参与者回复了No，表明自己不能完成这个事务，那么事务协调者不会发送commit消息，它会发送一轮Abort消息给所有的参与者说，请撤回这个事务 在事务Commit之后，会发生两件事情 事务协调者会向客户端发送代表了事务输出的内容，表明事务结束了，事务没有被Abort并且被持久化保存起来了 为了遵守两阶段锁规则，事务参与者会释放锁（这里不论Commit还是Abort都会释放锁） 每个事务参与者在参与事务时，会对任何涉及到的数据加锁 故障恢复 事务参与者故障 参与者B可能在回复事务协调者的Prepare消息之前的崩溃了：如果B发现自己不可能发送Yes，比如说在发送Yes之前自己就故障了，那么B被授权可以单方面的Abort事务 B也可能在回复了Yes给事务协调者的Prepare消息之后崩溃的：在B故障的时候，不知道事务是否能Commit，因为它还没有收到Commit消息。但是B还是需要做好Commit的准备。这意味着，在故障重启的时候，B不能丢失对于事务的状态记录 在B回复Prepare之前，它必须确保记住当前事务的中间状态，记住所有要做的修改，记住事务持有的所有的锁，这些信息必须在磁盘上持久化存储 之后如果B在发送完Yes之后崩溃了，当它重启恢复时，通过查看自己的Log，它可以发现自己正在一个事务的中间，并且对一个事务的Prepare消息回复了Yes B可能在收到Commit之后崩溃了：但是这样的话，B就完成了修改，并将数据持久化存储在磁盘上了。这样的话，故障重启就不需要做任何事情，因为事务已经完成 因为没有收到ACK，事务协调者会再次发送Commit消息。当B重启之后，收到了Commit消息时，它可能已经将Log中的修改写入到自己的持久化存储中、释放了锁、并删除了有关事务的Log。因此对于一个它不知道事务的Commit消息，B会简单的ACK这条消息 事务协调者故障 如果事务的任何一个参与者可能已经提交了，或者事务协调者可能已经回复给客户端了，那么我们不能忽略事务。例如如果事务协调者已经向A发送了Commit消息，但是还没来得及向B发送Commit消息就崩溃了，那么事务协调者必须在重启的时候准备好向B重发Commit消息，以确保两个参与者都知道事务已经提交了 如果事务协调者在发送Commit消息之前就崩溃了，那就无所谓了，因为没有一个参与者会Commit事务，它可以直接Abort事务 如果事务协调者在发送完一个或者多个Commit消息之后崩溃，那么就不允许它忘记相关的事务 在崩溃的时间点，也就是事务协调者决定要Commit而不是Abort事务，并且在发送任何Commit消息之前，它必须先将事务的信息写入到自己的Log，并存放在例如磁盘的持久化存储中 事务协调者在收到所有对于Prepare消息的Yes/No投票后，会将结果和事务ID写入存在磁盘中的Log，之后才会开始发送Commit消息 作为恢复流程的一部分，对于执行了一半的事务，事务协调者会向所有的参与者重发Commit消息或者Abort消息，以防在崩溃前没有向参与者发送这些消息 在事务协调者没有收到Yes/No回复一段时间之后，它可以单方面的Abort事务。因为它知道它没有得到完整的Yes/No消息，当然它也不可能发送Commit消息 类似的，如果参与者等待Prepare消息超时了，那意味着它必然还没有回复Yes消息，进而意味着事务协调者必然还没有发送Commit消息。所以如果一个参与者在这个位置因为等待Prepare消息而超时，那么它也可以决定Abort事务 假设B收到了Prepare消息，并回复了Yes，这个时候参与者没有收到Commit消息，它接下来怎么也等不到Commit消息。这段时间里，B一直持有事务涉及到数据的锁，这意味着，其他事务可能也在等待这些锁的释放。但是这时候我们不能单方面Abort事务或Commit事务，并释放锁，必须等待事务协调者上线 因为B对Prepare消息回复了Yes，这意味着事务协调者可能收到了来自于所有参与者的Yes，并且可能已经向部分参与者发送Commit消息 这意味着A可能已经看到了Commit消息，Commit事务，持久化存储事务的结果并释放锁","categories":[{"name":"Notes","slug":"Notes","permalink":"http://example.com/categories/Notes/"},{"name":"Paper Reading","slug":"Paper-Reading","permalink":"http://example.com/categories/Paper-Reading/"}],"tags":[{"name":"distributed system","slug":"distributed-system","permalink":"http://example.com/tags/distributed-system/"}]},{"title":"论文阅读-Oblivious Database相关","slug":"paper-reading/oblivious-db","date":"2022-04-12T16:00:00.000Z","updated":"2022-12-02T06:33:24.788Z","comments":true,"path":"2022/04/13/paper-reading/oblivious-db/","link":"","permalink":"http://example.com/2022/04/13/paper-reading/oblivious-db/","excerpt":"论文阅读-Oblivious Database相关","text":"不经意数据库相关研究 抵抗inference attack 关键是隐藏访问模式：隐藏访问内容+访问时间/访问次数/访问顺序等 ObliDB:star2: Proceedings of the VLDB Endowment，Volume 13，Issue 2，October 2019 Stanford University 威胁模型： 读取并篡改不可信内存 暂停和恢复Enclave执行 观察到对不可信内存的访问模式 监听网络通信 了解存储的数据的辅助信息 无法突破SGX远程认证 假设：不经意内存有限 安全保证： 探测到任何篡改数据的恶意行为 只泄露查询选择率（select行的比例），表的大小（包括输出表和中间表）和查询方案 可选的padding模式，可以隐藏表的大小和查询选择率 在enclave外的数据经过加密和MAC计算，仅泄露大小 数据库中表的数量 &amp; 查询了哪张表不作隐藏 Overview： 不经意数据库引擎支持小规模查询和分析查询（需要遍历整张表） 表加密存储在不可信内存但是访问模式被隐藏 两种存储方案：线性表、不经意索引（用于单点查询） Enclave用于存储密钥、元数据，不经意算子在Enclave中执行 存储方案 扁平化存储 数据存储在相邻的块中，每次读/写都需要访问所有块（整张表），用于存储： 小的表 操作后返回表的大部分区域的表 涉及读取全部或大部分表的分析 数据的插入、更新、删除需遍历整张表，对未受影响的块进行虚拟写（重新写一遍所有数据并重新加密） 索引存储 对B+树的插入/删除操作会泄露树的结构信息 =&gt; 使用虚拟ORAM访问，填充所有插入/删除操作，使其访问次数与最坏情况匹配 优化： 懒写回：只在必要的时候写入ORAM，否则将节点保留在enclave中 移除指向父节点的指针 Opaque 14th USENIX Symposium on Networked Systems Design and Implementation (NSDI 17) UC Berkeley Opaque relies on oblivious sorts over the entire dataset. These systems are not efficient for more general workloads that may also include point queries.【ObliDB】(单点查询效率低) 仅达到了Level 1的不经意性，因为使用不经意内存池进行优化【O-Join】 不经意分布式数据分析平台： 引入一系列新的分布式关系运算符 新的查询规划技术，rule-based和cost-based 三种运行模式：加密模式、不经意模式、不经意填充模式 威胁模型 观察和修改网络通信 获取操作系统的root权限 观察enclave对不可信内存的访问模式 可以进行回滚攻击，将密封的数据恢复到之前的状态 不能破坏可信硬件 对Opaque源码的访问是不经意的 安全保证 加密模式 数据加密和身份认证 self-verifying integrity 不经意模式 隐藏访问模式，但不隐藏访问的数据大小，以及Catalyst选择的查询方案 不经意填充模式 在不经意模式的基础上，进一步隐藏数据大小和查询方案 Overview 不经意执行 不经意排序（单机 &amp; 分布式） 不经意过滤（filter） 不经意聚合（group） 不经意连接（join） 查询规划 成本模型：主要考虑不经意排序的次数 查询优化 混合敏感性：使用second path analysis来推断敏感表 OCQ Proceedings of the Fifteenth European Conference on Computer Systems 2020 UC Berkeley OCQ[33]是一个不经意的协同竞争分析的通用框架，它建立在Opaque[87]的基础上，以分散的方式执行协同竞争查询。【Practical O-Join】 多方不经意竞争分析的解决方案，而不是设计一个数据库 主要贡献： 不经意查询算法 schema-aware填充机制：防止两种数据泄露——enclave中的数据泄露和enclave外网络通信中的模式泄露 不经意规划器：决定在哪执行操作以及如何执行 不经意算法： Single-machine oblivious sorting can be done using sorting networks that perform a fixed sequence of compare-exchange operations. Asymptotically more compare-exchange operations are needed for oblivious sorting than for traditional sorting. An oblivious compare-exchange can be implemented via a comparison followed by a conditional swap of two equal-length buffers depending on the result of the comparison. For data partitioned across multiple machines, oblivious sorting can be accomplished using a two-level sorting algorithm in which each partition is individually sorted using a sorting network, and records are sorted across partitions using an algorithm called column sort. Column sort consists of a fixed sequence of data exchange and intra-machine sorting that uses only 4 shuffles, compared to O(nlog2n) shuffles for a sorting-network-based distributed sort. Overview Oblivious join:star2: Proceedings of the VLDB Endowment 2020 University of Waterloo 滑铁卢大学 提出时间复杂度为 $O(nlog^2n+mlogm)$ 的不经意equi-join算法，其中 $n$ 是输入表大小之和， $m$ 是输出表大小 equi-join是指根据相等的条件来join两张表 该算法只依赖于能够在加密数据上支持sorting network的计算模型 不隐藏输出大小和运行时间 在加密数据上进行计算 Outsourced External Memory Secure Cryptographic Coprocessors TEE Secure Multiparty Computation Fully Homomorphic Encryption 不经意性划分 Level 1：对公共内存的访问是不经意的，但需要非常数量的本地内存来执行non-oblivious计算 Level 2：对公共内存的访问是不经意的，且需要的本地内存大小是一个常数 访问程序的数据是不经意的，但是基于控制流访问的字节码没有隐藏。例如分支语句，条件本身是不经意的，但是跳转到的分支的字节码位置没有隐藏 Level 3：程序的控制流，甚至处理器执行的指令，都与输入无关 将Level 2的程序转变为Level 3的程序需另外满足3条限制： 循环次数必须是常数（因为若根据变量来定循环次数，会很难隐藏执行循环的时间） 任何变量执行的最大分支数是一个常数 若一个程序暴露输出长度 $m$ ，则这一定在分配了 $m_0\\in\\Omega(m)$ 的内存之后 Overview 输入两张未排序的表 $T_1$ 和 $T_2$ ，分别包含 $n_1$ 和 $n_2$ 对 $(j,d)$ ，其中 $j$ 表示参与join条件判断的属性， $d$ 是其他属性。输出记为 $T_1\\bowtie T_2={(d_1,d_2)|(j,d_1)\\in T_1, (j,d_2)\\in T_2}$ 使用固定大小的本地内存来实现Level 2的不经意性 算法 ProDB Information Systems 2021 The Hong Kong Polytechnic University 香港理工大学 使用enclave+ORAM的方案来优化硬件资源不足的问题 提出SaP ORAM协议，用来实现enclave到不可信区的通信 不支持并发控制，回滚机制，数据库日志 Overview 安全模型：Memory-secure DBMS two-tier设计： core（部署在TEE中） SQL Decryptor：在TEE中解密SQL query Secure Query Processor (SQP)：与传统处理query的组件相同，除了I/O access ORAM Analyzer (OA)：利用SQL query历史信息的meta-data来规划最优的分配数据块到ORAM树path的方案 ORAM Clients：每个client对应一个server，SQP通过client获取不可信内存中的数据 shield（部署在不可信内存） DBMS Main Process：主程序 ORAM Servers：树形结构，以ORAM-to-Disk机制将数据安全地写入磁盘 work-flow SaP ORAM probabilistic lazy persistence Tagged position map：tag-address-path映射 Update list：存储被SQL query更新的块（而不是被ORAM重加密更新的），不能被敌手知道哪些块在Update list中 probabilistic dirty-block-generation procedure SQL-aware path sharing 目的：减少查询内和查询间的ORAM轮数 核心思想：在一轮ORAM中从树的path中获取多个块（ORAM Analyzer跟踪那些经常一起访问的块，并尽可能多地将它们放在同一ORAM树路径中） 具体方案：没细看 Obladi Proceedings of the 13th USENIX Symposium on Operating Systems Design and Implementation (OSDI’18) Cornell University Obladi [28] considers concurrent ACID transactions but does not support indexes and only processes operations in batches over discrete time epochs.【ObliDB】 Obladi[32]是第一个在隐藏访问模式的同时提供ACID事务的系统。它批量处理操作，但不支持索引【Practical O-Join】 【主要是事务和并发的实现】 第一个提供ACID事务的kv数据库 容错机制 并发控制 Practical Oblivious Join SIGMOD '22: Proceedings of the 2022 International Conference on Management of Data 西安电子科技大学，阿里巴巴 :star2:【参考文献整理】 对以往的不经意Join算法进行整理比较 提出了两种用于一般二元equi-join的不经意算法 oblivious sort-merge join oblivious index nested-loop join 通过扩展index nested-loop join来支持一些band join（如&quot;&lt;“和”&gt;&quot;） 使用index nested-loop join来支持多个表上的非循环equi-join Oblivious Query Processing Microsoft Research Contributions 对安全查询处理的形式化定义 设计占用较小TM（Trusted Module）的不经意算法 定理1（Informal）：$O(log,n)$ TM空间占用的不经意算法的存在性 定理2（Informal）：I/O复杂度 实现时间复杂度 $O(nlog,n)$ ，TM空间占用 $O(log,n)$ 的不经意算法 ORAM-based算法时间复杂度的下界为 $\\Omega(nlog^2n)$ 除了不经意排序，所有算法都基于磁盘扫描；不经意排序基于磁盘搜索， 搜索次数 $O(log_{M/B}(n/B))\\cdot o(n/B)$ 【M为TM内存，B为block大小】 ORAM-based算法磁盘搜索次数 $\\Omega(\\frac{n}{BlogM}log^2{\\frac{n}{B}})$ 对比 数据库类型 支持 特点 实现 ObliDB 关系型 索引 TEE+ORAM Opaque Spark SQL 分布式 TEE OCQ Opaque 分布式 TEE ProDB DBMS(关系型) SaP ORAM协议 TEE+ORAM Obladi kv数据库 事务 并发ORAM ORAM CODBS 关系型(PostgresSQL) 索引 形式化证明:star2: TEE+ORAM O-Join 关系型 二元equi-join TEE Practical O-Join 关系型 综合Join ORAM O-Query 关系型 形式化证明:star2: 算法 不经意可搜索加密 CODBS 40th International Symposium on Reliable Distributed Systems (SRDS) 2021 University of Porto 葡萄牙波尔图大学 提出一种新的不经意搜索方案CODBS来存储数据库索引，将搜索树拆分为L个较小的ORAM实例，而不是一个较大的ORAM 提出了Forest ORAM，这是一种用于存储数据库表的优化ORAM结构 提出了一种优化的不经意数据库体系结构，并在PostgreSQL之上实现了一个完整的解决方案 形式化证明 POSUP Proceedings on Privacy Enhancing Technologies; Journal Volume: 2019 Oregon State University 俄勒冈州立大学 POSUP [41] and Oblix [50] explore oblivious indexes over encrypted data using specialized ORAM constructions as building blocks, but do not support general queries.【ObliDB】 使用Intel SGX开发不经意数据结构，在大数据集上提供实用的不经意搜索/更新操作 Oblix 2018 IEEE Symposium on Security and Privacy (SP) UC Berkeley POSUP [41] and Oblix [50] explore oblivious indexes over encrypted data using specialized ORAM constructions as building blocks, but do not support general queries.【ObliDB】 不泄露访问模式，并且能够隐藏搜索结果的大小；支持更新（插入和删除），以及多个（可能是恶意的）用户 Preserving Access Pattern Privacy in SGX-Assisted Encrypted Search 27th International Conference on Computer Communication and Networks (ICCCN) 2018 The University of Auckland 奥克兰大学 提出了一种SGX辅助的对加密数据进行搜索的方案 保护访问模式免受侧通道攻击，同时确保搜索效率（使用了B+树结构来保证搜索效率） 处理大型数据库，而不需要在SGX上长期存储（分批加载和处理树索引） 与基于oram的解决方案(如obildb)相比，我们的方案要快11倍以上 不经意性证明/分析 Memory trace oblivious program execution KV数据库TEE EdgelessDB 开源项目，无相关论文，兼容MySQL Authenticated key-value stores with hardware enclaves【相关性不大】 Syracuse University 雪城大学 支持查询认证的kv数据库，从而保护数据完整性 实现认证LSM树：eLSM（with small query proofs at selective tree levels），将内存数据存放在enclave外部 提出基于LSM树的新摘要结构：eLSM摘要，以append方式更新摘要 基于Google LevelDB和Facebook RocksDB实现eLSM LSM树 适用于写密集型workload 基本增删改查：深入浅出分析LSM树（日志结构合并树） - 知乎 (zhihu.com) LSM树详解 - 知乎 (zhihu.com) 安全定义 Query integrity：读出的数据是否是之前合法的写请求写入的 Query completeness：读出的数据是否完整 Query freshness：读出的数据的时间戳是否最大 Aria 2021 IEEE 37th International Conference on Data Engineering (ICDE) 清华 现实世界的工作负载通常表现出高度倾斜的访问模式：一小部分hot KV pair收到的请求比其他多得多 引入基于软件的EPC空间管理器 Secure Cache ，为KV存储提供安全保障和高性能 深入研究了命中和未命中惩罚，从而优化了缓存策略 基于 Secure Cache 实现Aria，一个不依赖特定index structure的kv数据库 KV存储 index structure：通过key找到一个KV pair hash-based：简单而快速的点查询 tree-based：支持范围查询（有序存放key） storage manager：保存KV pair 通常的设计是：将KV存储直接放在不受信任的内存中，并在EPC中构建安全元数据，以保护KV pair的完整性和机密性。这样的设计基于这样的事实：对不受信任内存中的KV pair或MAC的任何攻击都会导致从其相应计数器计算的MAC与存储在不受信任内存中的MAC之间的KV pair不匹配 Secure Cache Secure Cache 用于缓存最经常访问的MT节点，从而在访问这些节点时可以直接从 Secure Cache 里验证，消除了MT验证的开销（叶节点若是要验证，只需要沿着到根节点的路径，找到第一个在缓存中的节点即可） 语义优化： 消除metadata从enclave内部到外部的加密 避免clean缓存项的写回 缓存命中优化： 将深层的节点固定在 Secure Cache 中（因为验证时用到的概率高） 采用FIFO策略来驱逐 Secure Cache 中的节点 若命中率小于一个阈值，停止swap 实现 连续Merkle树 用户空间堆分配器 解耦合设计 计数器管理 Put和Get实例 每次get需要解密多个kv pair才能得到想要的结果，是否有优化空间？ SPEICHER 17th USENIX Conference on File and Storage Technologies (FAST 19) 2019 The University of Edinburgh 爱丁堡大学 基于LSM树的三个设计更改：【Tweezer】 必须调整MemTable以减少EPC的使用。Speicher重新设计了MemTable，使它的大部分(叶上的值)显式地存储在EPC外部，并具有加密保护 I/O调用必须由另一个线程在用户级别上处理，以避免在每次调用时都离开enclave上下文。Speicher使用基于Intel SPDK[1]的直接I/O库运行，这减少了额外上下文切换的成本 KVS应该有适当的时间戳，以击败回滚和分叉攻击。Speicher使用自己的异步单调计数器包装同步SGX单调计数器 用于屏蔽执行的I/O库：I/O库在不退出enclave的情况下执行I/O操作 SPEICHER基于屏蔽执行框架SCONE实现 异步可信单调计数器：确保数据新鲜度，利用KV存储中同步操作的延迟来异步更新计数器 安全LSM数据结构：部署在enclave外部，并保证完整性，机密性和新鲜性 算法：设计和实现持久化KV数据库的操作：get, put, range queries, iterators, compaction, restore 威胁模型 敌手可以控制整个系统软件堆栈，包括操作系统或虚拟机监控程序，并能够发起物理攻击，例如执行内存探测 防止回滚攻击和分叉攻击 无法抵御侧信道攻击 设计挑战 有限EPC大小：EPC分页切换开销大，因此需要将MemTable放在enclave外部，同时保证安全 不可信的存储介质：存储引擎持久化三种文件：SSTable，WAL，Manifest，需要保证这三种文件的安全（SGX本身不提供对有状态计算的安全保证），因此重新设计LSM数据结构 昂贵的I/O系统调用：SCONE提供异步系统调用接口，但不适合需要支持频繁I/O系统调用的存储系统，因此设计了一种新的I/O机制 可信计数器：用于保护存储在不可信存储介质中的数据的新鲜性，SGX可信计数器十分慢，因此设计了异步可信单调计数器 Overview SPEICHER controller：基于SCONE实现，提供可信执行环境、远程认证、enclave内部用户级多线程和内存管理的运行时支持 屏蔽I/O库：从enclave内部直接访问磁盘，而不需要昂贵的exit操作，通过SPDK实现 可信计数器：防止回滚攻击，设计异步单调计数器AMC MemTable：key存放在enclave中的跳表里，value加密存放在不可信内存【存在线性增长导致EPC页切换的问题】 SSTable：KV按序排列并经过加密，每个block的hash存放在footer，footer的hash记录在enclave中的Manifest中从而确保新鲜性 Log文件：append-only - WAL：存放插入的KV pair直到top-level compaction，用于restore WAL - Manifest：跟踪实时文件 算法 Put：将KV pair添加到WAL，然后写到MemTable Get：需要生成存在证明或不存在证明 Range queries：根据start key构建Iterator进行遍历，对于每个key，找到最顶层的value Iterators Restore：收集所有属于KV存储的文件（通过读取Manifest），然后重放所有变化到MemTable Compaction EnclaveCache Proceedings of the 20th International Middleware Conference 2019 SJTU 对多租户云环境的KV数据库进行用户隔离等保护【不相关】 ShieldStore:star2: Proceedings of the Fourteenth EuroSys Conference 2019 School of Computing, KAIST 韩国科学技术院 随着密钥空间的增长，ShieldStore由于bucket变长而承受着巨大的验证开销【Aria】 Baseline kv存储 【不是直接用业界成熟的kv数据库，而是自己实现一个简单版本的内存kv存储】 基于哈希的索引结构：高效点查询，范围查询困难 为相同的哈希值创建链表，来抗碰撞 server-side加密和计算数据 Overview 只将主要的密钥和meta-data存放在enclave中，主哈希表经过加密后存放在非可信区 设计 key-value加密 通过对hash索引使用keyed-hash函数，可以将hashed键分布中的信息泄漏降至最低【进一步优化？】 通过key hint来在一个bucket中快速找到对应的value 若一个key更新，IV/counter会增加；若创建新的kv pair，会插入到bucket的头部 完整性校验 对每个bucket set维护一个Merkle root，而不是对所有kv pair维护一个Merkle tree【时间、空间复杂度分析？】 持久化 周期性snapshot parent进程密封enclave内的meta-data，child进程直接存储不可信内存中的哈希表 在snapshot的同时处理新的请求，使用临时表 使用SGX提供的单调计时器防止回滚攻击【使用效率更高的安全计时器?】 优化 额外的堆分配器：在enclave内运行，分配外部不可信内存（为了减少OCALL） MAC bucket：每个hash bucket维护一个，用来存放每个条目的MAC，从而快速计算merkle proof 而不用遍历整个chain 多线程：不同的线程处理不同的hash key，从而避免同步，但线程数量只能固定，不能动态变化【使用Occlum改进？】 搜索加密的key：使用1字节明文key的hash作为hint，从而减少需要解密的次数（只对匹配hint的key进行解密来判断是否是target key） ZeroTrace:star2: NDSS 2018 University of Waterloo 滑铁卢大学 ZeroTrace[66]在set/dictionary/list接口上提供了一个新的不经意的get/put/insert操作库【Practical O-Join】 设计和实现了一个不经意内存管理器 设计和实现 ZeroTrace，一个用来不经意处理数据结构的库 安全威胁 enclave内对外部内存的访问是完全暴露于server的 enclave内部的执行不能保证不经意性 server可以随时终止enclave从而造成某些攻击 不抵抗硬件攻击、硬件制造的漏洞、拒绝服务攻击 定义 enclave执行的不经意性（计算不可区分） SGX的安全挑战 软件侧信道 不能对超出EPC范围的存储提供隐私/完整性保护 没有直接的IO/系统调用 SGX的性能挑战 EPC大小限制 可信区和不可信区切换 ORAM正确性和安全性定义（可忽略函数/计算不可区分） ZeroTrace内存控制器 client接口：read(addr) 和 write(addr, data) server处理： FetchPath(leaf) 和 StorePath(tpath, leaf) 内存管理器enclave程序: 初始化：将程序加载到enclave中 构筑块： 不经意函数：根据汇编级别的函数库构建ORAM控制器 加密和哈希：使用AES-NI和SHA-256 ORAM控制器：处理client请求 (op, id, data*) 不经意leaf-label检索 不经意block检索 不经意path重建 Fetch/Store path优化 使用多个磁盘扩展带宽 缓存ORAM树的顶层 安全性分析（informal） 持久化的完整性 定义fault tolerance的enclave协议 functionality和security 抵抗mix-and-match攻击 抵抗重放攻击 Precursor Proceedings of the 22nd International Middleware Conference 2021 TU Braunschweig 布伦瑞克工业大学 德国 利用TEE来提供保密性和完整性，同时依赖于RDMA进行低延迟和高带宽通信 将加密操作放在客户端，以防止服务器端CPU瓶颈 尽可能避免昂贵的TEE上下文切换，即安全区和非安全区的切换 TEE-KV Proceedings of the ACM Symposium on Cloud Computing 2018 Tokyo University of Agriculture and Technology 东京农工大 &amp; 蚂蚁 &amp; Microsoft Research Asia 微软亚洲研究院 【只有一个Abstract，这是个啥？】 Oblivious key-value stores and amplification for private set intersection Annual International Cryptology Conference 2021 Oregon State University 俄勒冈州立大学 【形式化证明，没有用到SGX】 引入了无关键值存储(OKVS)的抽象，确定并形式化了允许OKVS接入不同协议的重要属性 描述了放大技术，可以用来将较弱的OKVS引导为强OKVS Tweezer 20th USENIX Conference on File and Storage Technologies (fast22) UNIST 韩国蔚山科学技术学院 在Speicher基础上修改 根据Speicher论文自己实现了一个Speicher版本 TWEEZER比Speicher性能高出1.94 ~ 6.23×，使得由于机密计算导致的性能开销从16 ~ 30×减少到4 ~ 9× 不同于Speicher的三个关键设计 无需构建横跨SSTable的Merkle树来确保LSM树的新鲜度，而是对不同的SSTable采用不同的key进行身份认证，使得攻击者无法在当前SSTable以外的任何地方找到其他数据块来执行重放攻击 Tweezer为每个SSTable创建并关联一个唯一的MAC key，基于LSM树的三个属性：每个SSTable的不可变性、每个Level的键的唯一性和每个数据块中的排序键 每个数据块中键的顺序都是唯一且不变的，这使得Tweezer可以检测到任何对新鲜度的攻击，而无需为每个SSTable生成Merkle树 将MAC与每个键值对相关联，而不是与SSTable中的每个数据块相关联。Tweezer通过分别对每个键值对进行加密和身份验证，减少了EPC使用中的读放大。 使用哈希链来对日志文件（WAL和Manifest）进行身份认证，而不使用计数器，Tweezer要求用户放置一个心跳事务来作为时间戳记录KVS版本，并在以后使用它来验证Tweezer的快照是否是最新的","categories":[{"name":"SGX","slug":"SGX","permalink":"http://example.com/categories/SGX/"},{"name":"Paper Reading","slug":"Paper-Reading","permalink":"http://example.com/categories/Paper-Reading/"}],"tags":[{"name":"sgx","slug":"sgx","permalink":"http://example.com/tags/sgx/"},{"name":"db","slug":"db","permalink":"http://example.com/tags/db/"}]},{"title":"Introduction To Modern Cryptography笔记","slug":"learning-notes/cryptography","date":"2022-03-19T16:00:00.000Z","updated":"2022-04-28T07:28:14.000Z","comments":true,"path":"2022/03/20/learning-notes/cryptography/","link":"","permalink":"http://example.com/2022/03/20/learning-notes/cryptography/","excerpt":"正式的密码学证明","text":"Chapter 1: Introduction 1.2 对称加密Setting Kerckhoffs’ principle：要求加密算法的安全性只依赖于密钥的安全性，而加解密算法都应当可以公开 1.3 古典加密算法 恺撒加密、移位加密、单字母替换、多字母移位 密钥空间充分性原则：任何安全的加密方案必须拥有一个能够抵御穷举搜索的密钥空间 1.4 现代密码学原则 原则1 Formal Defination 安全性定义包含： security guarantee regardless of any information an attacker already has, a ciphertext should leak no additional information about the underlying plaintext threat model 敌手的目标是要解密密文，得到明文 Ciphertext-only attack 唯密文攻击：敌手只能得到密文【被动攻击】 Known-plaintext attack 已知明文攻击：敌手能获得一个或多个明文-密文对【被动攻击】 Chosen-plaintext attack 选择明文攻击：敌手可以选择明文，并获得加密后的密文【主动攻击】 Chosen-ciphertext attack 选择密文攻击：敌手可以选择密文，并获得解密后的明文【主动攻击】 原则2 Precise Assumption 原则3 Proofs of Security Chapter 2: Perfectly Secret Encryption 2.1 符号定义 加密方案的元素： $\\mathcal{M}$ ——有限消息空间，$|\\mathcal{M}|&gt;1$ 令 $M$ 是一个随机的消息 ，对于任意 $m\\in\\mathcal{M}$ ，$Pr[M=m]$ 表示 $M$ 与 $m$ 一致的概率 $\\mathcal{K}$ ——有限密钥空间 令 $K$ 是 $\\mathsf{Gen}$ 随机生成的密钥，对于任意 $k\\in\\mathcal{K}$ ，$Pr[K=k]$ 表示 $\\mathsf{Gen}$ 生成的密钥为 $k$ 的概率 注：$K$ 和 $M$ 是独立的 $\\mathcal{C}$ ——密文空间 令 $C$ 是一个随机变量，对于任意 $c\\in\\mathcal{C}$ ，$Pr[C=c]$ 表示 $\\mathsf{Enc}$ 加密得到的密文为 $c$ 的概率 给定 $\\mathsf{Enc}$ ，$\\mathcal{C}$ 的分布完全取决于 $\\mathcal{M}$ 和 $\\mathcal{K}$ 的分布 加密方案包含三个算法： $\\mathsf{Gen}$ ——密钥生成 密钥生成算法从 $\\mathcal{K}$ 中均匀地选择一个密钥 $k$ $\\mathsf{Enc}$ ——加密 输入 $k\\in\\mathcal{K}, m\\in\\mathcal{M}$ ，输出密文 $c\\in\\mathcal{C}$ 对于概率性加密算法，记作 $c\\leftarrow \\mathsf{Enc}_{k}(m)$ 对于确定性加密算法，记作 $c:=\\mathsf{Enc}_{k}(m)$ $\\mathsf{Dec}$ ——解密 输入 $k\\in\\mathcal{K},c\\in\\mathcal{C}$ ，输出消息 $m\\in\\mathcal{M}$ 一般假设解密算法是确定性的，记作 $m:=\\mathsf{Dec}_{k}©$ Perfect Secrecy 定义2.3：加密方案 $\\Pi=(\\mathsf{Gen}, \\mathsf{Enc}, \\mathsf{Dec})$ 是perfectly secret，如果对 $\\mathcal{M}$ 上任意概率分布，任意明文 $m\\in\\mathcal{M}$ ，任意密文 $c\\in\\mathcal{C}$ 且 $Pr[C=c]&gt;0$ 有：$Pr[M=m|C=c]=Pr[M=m]$ 等价定义：$Pr[C=c|M=m]=Pr[C=c]$ 引理2.4：加密方案 $\\Pi=(\\mathsf{Gen}, \\mathsf{Enc}, \\mathsf{Dec})$ 是perfectly secret，当且仅当对所有 $m, m’\\in\\mathcal{M}$ 和所有 $c\\in\\mathcal{C}$ 有：$Pr[\\mathsf{Enc}{k}(m)=c]=Pr[\\mathsf{Enc}{k}(m’)=c]$ 说明密文不包含任何关于明文的信息，且不可能区分加密后的 $m$ 和 $m’$ Perfect (adversarial) indistinguishability 定义敌手不可区分实验 $\\mathsf{PrivK}^{eav}_{\\mathcal{A},\\Pi}$ (其中 $\\Pi=(\\mathsf{Gen}, \\mathsf{Enc}, \\mathsf{Dec})$ )： 敌手 $\\mathcal{A}$ 输出一对消息 $m_0,m_1\\in\\mathcal{M}$ 选择一个比特 $b\\in{0,1}$ ，计算 $c\\leftarrow \\mathsf{Enc}_k(m_b)$ 并发送给 $\\mathcal{A}$ 。称 $c$ 为挑战密文 $\\mathcal{A}$ 输出一个比特 $b’$ 若 $b=b’$ 则实验输出1，记作 $\\mathsf{PrivK}^{eav}_{\\mathcal{A},\\Pi}=1$ ，此时 $\\mathcal{A}$ 获胜；反之输出0 定义2.5：加密方案 $\\Pi=(\\mathsf{Gen}, \\mathsf{Enc}, \\mathsf{Dec})$ 是perfectly indistinguishable，如果对所有 $\\mathcal{A}$ 有： $Pr[\\mathsf{PrivK}^{eav}_{\\mathcal{A},\\Pi}=1]=\\frac{1}{2}$ 引理2.6：加密方案 $\\Pi=(\\mathsf{Gen}, \\mathsf{Enc}, \\mathsf{Dec})$ 是perfectly secret，当且仅当它是perfectly indistinguishable 2.2 一次一密 定义：取定整数 $l&gt;0$ ， $\\mathcal{M},\\mathcal{C},\\mathcal{K}$ 都是长度为 $l$ 的二进制串，即 ${0,1}^l$ $\\mathsf{Gen}$ ：根据均匀分布从 $\\mathcal{K}={0,1}^l$ 中选择一个密钥 $\\mathsf{Enc}$ ：给定密钥 $k\\in{0,1}^l$ 和消息 $m\\in{0,1}^l$ ，输出密文 $c:=k\\oplus m$ $\\mathsf{Dec}$ ：给定密钥 $k\\in{0,1}^l$ 和密文 $c\\in{0,1}^l$ ，输出消息 $m:=k\\oplus c$ 定理2.9：一次一密方案是perfectly secret 局限性： 密钥必须和消息等长 只有每次加密使用不同的密钥才安全 2.3 Perfect Secrecy的局限性 定理2.10： $(\\mathsf{Gen}, \\mathsf{Enc}, \\mathsf{Dec})$ 是perfectly secret加密方案，则 $|\\mathcal{K}|&gt;|\\mathcal{M}|$ 【反证】 Perfectly secret的加密方案中密钥空间必须大于消息空间 2.4 香农定理 定理2.11(香农定理)：对于 $|\\mathcal{M}|=|\\mathcal{K}|=|\\mathcal{C}|$ 的加密方案 $\\Pi=(\\mathsf{Gen}, \\mathsf{Enc}, \\mathsf{Dec})$ 是perfectly secret，当且仅当： 每个密钥 $k\\in\\mathcal{K}$ 被 $\\mathsf{Gen}$ 选择的概率为 $1/|\\mathcal{K}|$ 对每个 $m\\in\\mathcal{M}$ 和 $c\\in\\mathcal{C}$ ，存在唯一的密钥 $k\\in\\mathcal{K}$ 使得 $\\mathsf{Enc}_k(m)$ 输出 $c$ Chapter 3: Private-Key Encryption 3.1 计算安全 放松perfect secrecy的限制： 仅对可行时间内的敌手保证安全（敌手可能在足够多的时间内可以破解） 敌手有很小的概率破解 形式化定义 具体定义 一个方案是 $(t,\\varepsilon)$-安全 的，如果任何敌手在时间 $t$ 内破解该方案的概率最大为 $\\varepsilon$ 渐进定义 诚实各方使用一个共享的安全参数 $n$ (或记为 $1^n$ ) 来初始化加密方案，从而敌手的攻击时间和攻击成功的概率都是 $n$ 的函数： 敌手攻击时间：多项式时间，即存在多项式 $p$ ，对所有输入 $x\\in{0,1}^*$ ，算法最多执行 $p(|x|)$ 步 敌手的攻击成功概率可忽略 定义3.4：从自然数映射到非负实数的函数 $f$ 是可忽略(negligible)的，如果对所有正多项式 $p$ ，存在 $N$ ，使得对所有 $n&gt;N$ ，有 $f(n)&lt;\\frac{1}{p(n)}$ 【将任意可忽略函数记作 $\\mathsf{negl}$】 命题3.6：令 $\\mathsf{negl_1}$ 和 $\\mathsf{negl_2}$ 为可忽略函数，则 $\\mathsf{negl_3}(n)=\\mathsf{negl_1}(n)+\\mathsf{negl_2}(n)$ 是可忽略的 对任意正多项式 $p$ ，$\\mathsf{negl_4}(n)=p(n)\\cdot \\mathsf{negl_1}(n)$ 是可忽略的 一个方案是安全的，如果任何PPT (probabilistic polynomial-time概率多项式时间) 敌手破解该方案的概率可忽略 3.2 定义计算安全的加密 定义3.7：一个对称加密方案是一个PPT算法元组 $(\\mathsf{Gen}, \\mathsf{Enc}, \\mathsf{Dec})$ ，满足： $\\mathsf{Gen}$ 的输入为 $1^n$ ，输出密钥 $k$ ，记作 $k\\leftarrow \\mathsf{Gen}(1^n)$ ，并假设任何 $k$ 满足 $|k|&gt;n$ $\\mathsf{Enc}$ 的输入为 $k$ 和 $m\\in{0,1}^*$ ，输出密文 $c$ ，记作 $c\\leftarrow \\mathsf{Enc}_k(m)$ $\\mathsf{Dec}$ 的输入为 $k$ 和 $c$ ，输出消息 $m$ 或错误 $\\bot$ (当输入为无效密文)，记作 $m:=\\mathsf{Dec}_k©$ 算法满足 $\\mathsf{Dec}_k(\\mathsf{Enc}_k(m))=m$ 安全的基本定义 关于敌手能力的假设： 仅窃听信道（唯密文攻击） 多项式时间 定义敌手不可区分实验 $\\mathsf{PrivK}^\\mathsf{eav}_{\\mathcal{A},\\Pi}(n)$ (其中 $\\Pi=(\\mathsf{Gen}, \\mathsf{Enc}, \\mathsf{Dec})$ )： 敌手 $\\mathcal{A}$ 根据输入 $1^n$ 输出一对消息 $m_0,m_1$ ，且 $|m_0|=|m_1|$ 计算 $k\\leftarrow \\mathsf{Gen}(1^n)$ ，选择一个比特 $b\\in{0,1}$ ，计算 $c\\leftarrow \\mathsf{Enc}_k(m_b)$ 并发送给 $\\mathcal{A}$ 。称 $c$ 为挑战密文 $\\mathcal{A}$ 输出一个比特 $b’$ 若 $b=b’$ 则实验输出1，记作 $\\mathsf{PrivK}^\\mathsf{eav}_{\\mathcal{A},\\Pi}(n)=1$ ，此时 $\\mathcal{A}$ 获胜；反之输出0 定义3.8(3.9)：对称加密方案 $\\Pi=(\\mathsf{Gen}, \\mathsf{Enc}, \\mathsf{Dec})$ 是EAV-安全的（对窃听敌手不可区分），如果对所有PPT敌手 $\\mathcal{A}$ 有一个可忽略函数 $\\mathsf{negl}$ ，使得对所有n： $Pr[\\mathsf{PrivK}^\\mathsf{eav}_{\\mathcal{A},\\Pi}(n)=1]\\leq \\frac{1}{2}+\\mathsf{negl}(n)$ 该式说明 $\\mathcal{A}$ 正确判断加密的消息是 $m_0$ 还是 $m_1$ 的概率小于等于 $\\frac{1}{2}+\\mathsf{negl}(n)$ $Pr[out_{\\mathcal{A}}(\\mathsf{PrivK}\\mathsf{eav}_{\\mathcal{A},\\Pi}(n,0))=1]-Pr[out_{\\mathcal{A}}(\\mathsf{PrivK}\\mathsf{eav}_{\\mathcal{A},\\Pi}(n,1))=1]\\leq \\mathsf{negl}(n)$ 其中 $\\mathsf{PrivK}^\\mathsf{eav}{\\mathcal{A},\\Pi}(n,b)$ 表示实验选择了 $m_b$ 进行加密； $out{\\mathcal{A}}(\\mathsf{PrivK}^\\mathsf{eav}_{\\mathcal{A},\\Pi}(n,b))$ 表示 $\\mathcal{A}$ 在实验中的输出，即 $b’$ 该式说明 $\\mathcal{A}$ 不能判断进行的实验是 $\\mathsf{PrivK}^\\mathsf{eav}{\\mathcal{A},\\Pi}(n,0)$ 还是 $\\mathsf{PrivK}^\\mathsf{eav}{\\mathcal{A},\\Pi}(n,1)$ 语义安全 不可区分意味着密文不会泄露任何一比特的明文 定理3.10： $\\Pi=(\\mathsf{Enc},\\mathsf{Dec})$ 是一个对长度为 $l$ 的消息的对称加密方案，并且是EAV-安全的。则对所有PPT敌手 $\\mathcal{A}$ 和任何 $i\\in{1,…,l}$ ，存在一个可忽略函数 $\\mathsf{negl}$ 使得：【其中 $m^i$ 表示消息的第 $i$ 比特；$\\mathcal{A}(1^n,\\mathsf{Enc}_k(m))$ 表示 $\\mathcal{A}$ 收到挑战密文后的输出 $b’$ 】 $$Pr[\\mathcal{A}(1n,\\mathsf{Enc}_k(m))=mi]\\leq\\frac{1}{2}+\\mathsf{negl}(n)$$ 不可区分意味着没有敌手能从密文中学习到任何明文的函数 定理3.11：$\\Pi=(\\mathsf{Enc},\\mathsf{Dec})$ 是一个对长度为 $l$ 的消息的对称加密方案，并且是EAV-安全的。则对所有PPT敌手 $\\mathcal{A}$ 存在一个PPT算法 $\\mathcal{A’}$ ，使得对任何 $S\\subseteq {0,1}^l$ 和任何函数 $f: {0,1}^l\\rightarrow{0,1}$ ，存在一个可忽略函数 $negl$ 使得： $$ |Pr[\\mathcal{A}(1n,\\mathsf{Enc}_k(m))=f(m)]-Pr[\\mathcal{A’}(1n)=f(m)]|\\leq \\mathsf{negl}(n) $$ 3.3 构建安全加密方案 伪随机生成器 伪随机生成器 $G$ 是一个高效、确定性的算法，用于将一个短的、均匀的字符串 (seed) 转变为一个长的、伪随机的字符串 定义3.14：令 $l$ 为一个多项式，$G$ 为一个确定性多项式时间算法，使得对任何 $n$ 和输入 $s\\in{0,1}^n$ ，输出 $G(s)$ 是一个长度为 $l(n)$ 的字符串。称 $G$ 是一个伪随机生成器，如果满足： 扩展性：对任意 $n$ 满足 $l(n)&gt;n$ 伪随机性：对任意PPT算法 $D$ ，存在一个可忽略函数使得：【其中 $r\\in {0,1}^{l(n)}$】 $$ |Pr[D(G(s))=1]-Pr[D®=1]|\\leq \\mathsf{negl}(n) $$ 称 $l$ 为 $G$ 的扩展系数 之所以生成的字符串是伪随机而不是均匀的，举例说明：$l(n)=2n$ 时，长度为 $2n$ 的字符串空间为 $2^{2n}$ ，选择任意一个 $r\\in {0,1}^{2n}$ 的概率为 $1/2^{2n}$ ，是均匀的；但是由于 $s$ 的长度为 $n$ ，所以 $G(s)$ 的字符串空间为 $2^n$ ，选择到的概率为 $1/2^n$ ，不是均匀的 流密码 流密码是一对确定性算法 $(\\mathsf{Init}, \\mathsf{GetBits})$ $\\mathsf{Init}$ 输入seed $s$ 和可选的初始化向量 $IV$ ，输出初始状态 $st_0$ $\\mathsf{GetBits}$ 输入状态信息 $st_i$ ，输出一个比特 $y$ 并更新状态到 $st_{i+1}$ 算法3.16： 规约证明 将证明一个敌手 $\\mathcal{A}$ 成功破解一个方案 转换为 证明一个算法 $\\mathcal{A’}$ 解决一个难题，具体步骤如下： 选定一个敌手 $\\mathcal{A}$ 攻击 $\\Pi$ ，攻击成功的概率为 $\\varepsilon(n)$ ； 构建一个算法 $\\mathcal{A’}$ ，它使用敌手 $\\mathcal{A}$ 作为子程序来尝试解决问题 $X$ 。注意： $\\mathcal{A’}$ 不知道 $\\mathcal{A}$ 是如何工作的，它只知道 $\\mathcal{A}$ 要攻击 $\\Pi$ 。当输入一个问题 $X$ 的实例 $x$ 时， $\\mathcal{A’}$ 为 $\\mathcal{A}$ 模拟一个 $\\Pi$ 的实例，使得： $\\mathcal{A}$ 无法区分自己是作为 $\\mathcal{A’}$ 的子程序在运行还是其本身在攻击 $\\Pi$ ； 如果 $\\mathcal{A}$ 成功破解 $\\mathcal{A’}$ 模拟的 $\\Pi$ ，则 $\\mathcal{A’}$ 能解决问题 $x$ ，其概率至少为 $1/p(n)$ ； 根据上一点， $\\mathcal{A’}$ 解决 $X$ 的概率为 $\\varepsilon(n)/p(n)$ 。若 $\\varepsilon(n)$ 不是可忽略的，则 $\\varepsilon(n)/p(n)$ 也不是可忽略的，从而得到一个算法 $\\mathcal{A’}$ 以不可忽略的概率解决 $X$ ，与假设（ $X$ 是一个计算难题，无法在多项式时间内解决）矛盾； 综上，如果 $X$ 确实是计算难题，则没有 $\\mathcal{A}$ 能以不可忽略的概率破解 $\\Pi$ 。换言之， $\\Pi$ 是计算安全的。 安全的定长加密方案 用生成器对密钥进行扩充，以达到一次一密的效果 具体构造3.17如下： 定理3.18：如果 $G$ 是伪随机生成器，则上述构造的加密方案是EAV-安全的 规约证明3.18： 使用 $\\mathcal{A}$ 来构造一个判别器 $D$ ，将 $\\mathcal{A}$ 正确选择 $\\Pi$ 加密的消息的能力规约到 $D$ 分辨 $G$ 的输出和均匀字符串的能力，从而由 $G$ 的安全性能推导出 $\\Pi$ 的安全性。 $D$ 的构造如下，$D$ 的目标是分辨输入 $w$ 是随机串还是由伪随机生成器生成的： 定义 $\\widetilde{\\Pi}=(\\widetilde{\\mathsf{Gen}},\\widetilde{\\mathsf{Enc}},\\widetilde{\\mathsf{Dec}})$ 为一次一密方案： $\\widetilde{\\mathsf{Gen}}(1^n)$ 输出长度为 $l(n)$ 的密钥 $k$ ； $\\widetilde{\\mathsf{Enc}}$ 使用 $k$ 加密长度为 $l(n)$ 的消息：$c:=k\\oplus m$ ； 根据一次一密的perfect secrecy： $$ Pr[\\mathsf{PrivK}^{eav}_{\\mathcal{A},\\widetilde{\\Pi}}(n)=1]=\\frac{1}{2} \\tag{3.3} $$ 对 $D$ 进行分析： 若 $w$ 是从 ${0,1}^{l(n)}$ 中均匀选出的，则 $\\mathcal{A}$ 作为 $D$ 的子程序运行的视图和在实验 $\\mathsf{PrivK}^{eav}{\\mathcal{A},\\widetilde{\\Pi}}(n)$ 中的视图完全一致，即： $$ Pr{w\\leftarrow {0,1}{l(n)}}[D(w)=1]=Pr[\\mathsf{PrivK}{eav}_{\\mathcal{A},\\widetilde{\\Pi}}(n)=1]=\\frac{1}{2} \\tag{3.4} $$ 若 $w$ 是通过 $w=G(k),,k\\in {0,1}^n$ 生成的，则 $\\mathcal{A}$ 作为 $D$ 的子程序运行的视图和在实验 $\\mathsf{PrivK}^{eav}{\\mathcal{A},\\Pi}(n)$ 中的视图完全一致，即 $$ Pr{k\\leftarrow {0,1}n}[D(G(k))=1]=Pr[\\mathsf{PrivK}{eav}_{\\mathcal{A},\\Pi}(n)=1] \\tag{3.5} $$ 由于 $G$ 是伪随机生成器，所以存在一个可忽略函数 $\\mathsf{negl}$ 使得： $$ |Pr_{w\\leftarrow {0,1}^{l(n)}}[D(w)=1]-Pr_{k\\leftarrow {0,1}^n}[D(G(k))=1]|\\leq \\mathsf{negl}(n) $$ 根据公式 $(3.4),,(3.5)$ 得： $$ |\\frac{1}{2}-Pr[\\mathsf{PrivK}^{eav}_{\\mathcal{A},\\Pi}(n)=1]|\\leq \\mathsf{negl}(n) $$ 即 $Pr[\\mathsf{PrivK}^{eav}_{\\mathcal{A},\\Pi}(n)=1]\\leq \\frac{1}{2}+\\mathsf{negl}(n)$ ，从而方案 $\\Pi$ 是EAV-安全的。 3.4 更强的安全概念 多消息加密——修改安全目标 多消息窃听实验 $\\mathsf{PrivK}^\\mathsf{mult}_{\\mathcal{A},\\Pi}(n)$ ： 敌手 $\\mathcal{A}$ 得到输入 $1^n$ ，并输出一对相同长度的消息列表： $\\vec{M_0}=(m_{0,1},…,m_{0,t})$ 和 $\\vec{M_1}=(m_{1,1},…,m_{1,t})$ ，其中 $|m_{0,i}|=|m_{1,i}|$ ； $k\\leftarrow \\mathsf{Gen(1^n)}$ ，并随机选择 $b\\in{0,1}$ 。对所有 $i$ ，计算 $c_i\\leftarrow \\mathsf{Enc}k(m{b,i})$ ，将 $\\vec{C}=(c_1,…,c_t)$ 发送给 $\\mathcal{A}$ ； $\\mathcal{A}$ 输出一比特 $b’$ ； 若 $b=b’$ 则实验输出1，$\\mathcal{A}$ 获胜，反之输出0。 定义3.19：一个对称加密方案 $\\Pi=(\\mathsf{Gen,Enc,Dec})$ 是多消息EAV-安全的，如果对所有PPT敌手 $\\mathcal{A}$ 存在一个可忽略函数 $\\mathsf{negl}$ 使得： $$ Pr[\\mathsf{PrivK}^\\mathsf{mult}_{\\mathcal{A},\\Pi}(n)=1]\\leq\\frac{1}{2}+\\mathsf{negl}(n) $$ 命题3.20：存在一个对称加密算法是EAV-安全的，但不是多消息EAV-安全的。【eg. 一次一密】 定理3.21：如果 $\\Pi$ 是一个无状态的加密方案且 $\\mathsf{Enc}$ 是确定性算法，则 $\\Pi$ 不可能是多消息EAV-安全的。 CPA-安全（选择明文攻击）——增强威胁模型 CPA不可区分实验 $\\mathsf{PrivK}^\\mathsf{cpa}_{\\mathcal{A},\\Pi}(n)$ ： $k\\leftarrow \\mathsf{Gen(1^n)}$ ； 敌手 $\\mathcal{A}$ 得到输入 $1^n$ 并能够使用oracle $\\mathsf{Enc}_k(\\cdot)$，输出一对相同长度的消息 $m_0$ 和 $m_1$ ； 随机选择 $b\\in{0,1}$ ，计算 $c\\leftarrow \\mathsf{Enc}k(m{b})$ ，并发送给 $\\mathcal{A}$ ； $\\mathcal{A}$ 输出一比特 $b’$ ； 若 $b=b’$ 则实验输出1，$\\mathcal{A}$ 获胜，反之输出0。 定义3.22：对称加密方案 $\\Pi=(\\mathsf{Gen}, \\mathsf{Enc}, \\mathsf{Dec})$ 是CPA-安全的（对选择明文攻击不可区分），如果对所有PPT敌手 $\\mathcal{A}$ 有一个可忽略函数 $\\mathsf{negl}$ ，使得对所有n： $$Pr[\\mathsf{PrivK}^\\mathsf{cpa}_{\\mathcal{A},\\Pi}(n)=1]\\leq \\frac{1}{2}+\\mathsf{negl}(n)$$ 多消息加密的CPA-安全 定义oracle $\\mathsf{LR}_{k,b}(\\cdot,\\cdot)$ ：输入两个等长的消息 $m_0$ ，$m_1$ ，若 $b=0$ 输出 $c\\leftarrow \\mathsf{Enc}_k(m_0)$ ；若 $b=1$ 输出 $c\\leftarrow \\mathsf{Enc}_k(m_1)$ LR-oracle实验 $\\mathsf{PrivK}^\\mathsf{LR-cpa}_{\\mathcal{A},\\Pi}(n)$ ： $k\\leftarrow \\mathsf{Gen(1^n)}$ ； 随机选择 $b\\in{0,1}$ ； 敌手 $\\mathcal{A}$ 得到输入 $1^n$ 并能够使用oracle $\\mathsf{LR}{k,b}(\\cdot,\\cdot)$ 【 $\\mathcal{A}$ 能通过请求 $\\mathsf{LR}{k,b}(m_{0,1},m_{1,1})$,…,$\\mathsf{LR}{k,b}(m{0,t},m_{1,t})$ 来获取消息列表的加密结果，同时也可以通过请求 $\\mathsf{LR}_{k,b}(m,m)$ 来获得 $\\mathsf{Enc}_k(m)$ 】，输出一对相同长度的消息 $m_0$ 和 $m_1$ ； 计算 $c\\leftarrow \\mathsf{Enc}k(m{b})$ ，并发送给 $\\mathcal{A}$ ； $\\mathcal{A}$ 输出一比特 $b’$ ； 若 $b=b’$ 则实验输出1，$\\mathcal{A}$ 获胜，反之输出0。 定义3.23：对称加密方案 $\\Pi=(\\mathsf{Gen}, \\mathsf{Enc}, \\mathsf{Dec})$ 是多消息CPA-安全的，如果对所有PPT敌手 $\\mathcal{A}$ 有一个可忽略函数 $\\mathsf{negl}$ ，使得对所有n： $$Pr[\\mathsf{PrivK}^\\mathsf{LR-cpa}_{\\mathcal{A},\\Pi}(n)=1]\\leq \\frac{1}{2}+\\mathsf{negl}(n)$$ 定理3.24：任何CPA-安全的对称加密方案都是多消息CPA-安全的 3.5 构造CPA-安全的加密方案 伪随机函数 定义keyed函数 $F(k,x):{0,1}^\\times {0,1}^\\rightarrow {0,1}^$ ，一般而言可以固定密钥 $k$ ，记作 $F_k(x)=F(k,x)$ ，而 $F_k(x):{0,1}^\\rightarrow {0,1}^*$ 。安全参数 $n$ 规定了密钥、输入、输出的长度，从而 $F_k(x)$ 是条件 $k\\in{0,1}^n$ 下的一个将长度为 $n$ 的输入映射到长度为 $n$ 的输出的函数。 称函数 $F$ 是伪随机的，如果 $F_k(x)$ 与 $f:{0,1}^n\\rightarrow {0,1}^n$ 不可区分【所有 $f$ 的集合记作 $\\mathsf{Func}_n$】 可以将 $f$ 看作一个表，根据长度 $n$ 的输入查表得到长度 $n$ 的输出，输入可以固定顺序为 $0^n$ 到 $1^n$ ，则该表有 $2^n$ 行，每个输入对应的输出长度为 $n$ ，即每行长度为 $n$ ，因此函数 $f$ 可以看作一个长度为 $2^n\\cdot n$ 的序列，从而 $f$ 的取值空间大小为 $2{2n\\cdot n}$ 【$F_k$ 的取值空间为 $2^n$】 定义3.25：令 $F:{0,1}^\\times {0,1}^\\rightarrow {0,1}^*$ 为一个keyed函数。$F$ 是一个伪随机函数，如果对所有PPT判别器 $D$ 存在一个可忽略函数 $\\mathsf{negl}$ 使得： $$ |Pr[D{F_k(\\cdot)}(1n)=1]-Pr[D{f(\\cdot)}(1n)=1]|\\leq\\mathsf{negl}(n) $$ 注：$D$ 并不知道具体的 $k$ 伪随机排列 令 $\\mathsf{Perm}_n$ 是 ${0,1}^n$ 的全排列，大小为 $(2^n)!$ 若函数 $f\\in\\mathsf{Perm}_n$ ，说明不同输入映射到的输出是不同的 $F$ 是一个keyed排列，如果 $F_k$ 的值是全排列； $F$ 是efficient的，如果可以在多项式时间内计算 $F_k(x)$ 和 $F_k^{-1}(y)$ $F$ 是伪随机排列，如果 $F_k(x)$ 与 $f\\in\\mathsf{Perm}_n$ 不可区分 命题3.27：如果 $F$ 是一个伪随机排列且 $l_{in}(n)\\geq n$ ，则 $F$ 也是一个伪随机函数 定义3.28：令 $F:{0,1}^\\times {0,1}^\\rightarrow {0,1}^*$ 为一个keyed排列。$F$ 是一个强伪随机排列，如果对所有PPT判别器 $D$ 存在一个可忽略函数 $\\mathsf{negl}$ 使得： $$ |Pr[D{F_k(\\cdot),F_k{-1}(\\cdot)}(1n)=1]-Pr[D{f(\\cdot),f{-1}(\\cdot)}(1n)=1]|\\leq\\mathsf{negl}(n) $$ 伪随机函数与伪随机生成器的关系 伪随机生成器 $G$ 可以由伪随机函数 $F$ 得到：$G(s)=F_s(1)||F_s(2)||…||F_s(l)$ 根据伪随机函数构造流密码3.29： 伪随机函数构造的CPA-安全加密 证明基于伪随机函数的构造的安全性：首先假设构造中的伪随机函数被以一个随机函数替换，再通过规约证明来说明这个改变不会影响敌手成功的概率，最后再证明修改后的构造是安全的 构造3.30： 缺点在于生成的密文长度是明文的两倍 定理3.31：如果 $F$ 是一个伪随机函数，则上述构造是CPA-安全的【证明on P83】 3.6 工作模式 流密码的工作模式 同步模式：有状态，需要通信双方同步，基于算法3.16和构造3.17 令发送方为A，接收方为B，双方计算 $\\mathsf{st}_0:=\\mathsf{Init}(k)$ 发送第一条长度为 $l_1$ 的消息 $m_1$ ，A根据 $\\mathsf{st}0$ 运行 $l_1$ 次 $\\mathsf{GetBits}$ ，得到 $\\mathsf{pad}1\\overset{def}{=}y_1,…,y{l_1}$ 并更新状态到 $\\mathsf{st}{l_1}$ ，然后发送 $c_1:=\\mathsf{pad}_1 \\oplus m_1$ ；而B解密通过 $m_1:=\\mathsf{pad}_1 \\oplus c_1$ 发送第二条长度为 $l_2$ 的消息 $m_2$ ，A根据 $\\mathsf{st}{l_1}$ 运行 $l_2$ 次 $\\mathsf{GetBits}$ ，得到 $\\mathsf{pad}2\\overset{def}{=}y{l_1+1},…,y{l_1+l_2}$ 并更新状态到 $\\mathsf{st}_{l_1+l_2}$ ，然后发送 $c_2:=\\mathsf{pad}_2 \\oplus m_2$ ；而B解密通过 $m_2:=\\mathsf{pad}_2 \\oplus c_2$ ，以此类推 自同步模式：无状态CPA-安全，基于构造3.30，其中的 $F_k(IV)\\overset{def}{=}G_\\infty(k,IV,1^l)$ 分组密码的工作模式 使用分组密码构造CPA-安全的加密方案，改进构造3.30，使得密文长度减小。令 $F$ 为分组长度为 $n$ 的分组密码，需要加密的消息记为 $m=m_1,m_2,…,m_l$ 且 $m_i\\in{0,1}^n$ ECB模式（Electronic Code Book）：$c:=\\langle F_k(m_1),…,F_k(m_l)\\rangle$ ，它是确定性算法，因此不是CPA-安全的，同时它也不是EAV-安全的，因为每一个分组的block都相同 CBC模式（Cipher Block Chaining）：概率性算法，若 $F$ 是一个伪随机排列，则CBC-模式加密是CPA-安全的 缺点：加解密只能串行，不能并行，因为后面的block依赖于前面block的输出 链式CBC：对一种选择明文攻击不安全，构造攻击如下： 假设敌手知道 $m_1\\in{m_10,m_11}$ ，并且得到了密文 $IV,c_1,c_2,c_3$ ，接着构造 $m_4=IV\\oplus m_1^0\\oplus c_3$ ，得到输出 $c_4$ 。从而可以得出 $m_1=m_1^0$ 当且仅当 $c_4=c_1$ ，因此敌手可以从 ${m_10,m_11}$ 中选出正确的 $m_1$ OFB模式（Output Feedback）：可以看作是自同步流密码，$F$ 不需要是一个伪随机排列，消息长度不需要进行填充，且每一步的状态都是保密的。若 $F$ 是一个伪随机函数，则OFB模式是CPA-安全的。虽然加解密都只能串行执行，但是加解密用的伪随机串可以提前计算 CTR模式（Counter）：也可以看作自同步流密码，具体构造如下： 选择一个随机值 $\\mathsf{ctr}\\in{0,1}^n$ ，计算伪随机串 $y_i:=F_k(\\mathsf{ctr}+i)$ 【其中 $\\mathsf{ctr}+i$ 是整数模 $2^n$ 相加】，从而第 $i$ 个密文块为 $c_i:=y_i\\oplus m_i$ $F$ 不需要是一个伪随机排列，消息长度不需要进行填充，且每一步的状态都是保密的，加解密可以并行执行，且伪随机串可以提前计算 定理3.32：若 $F$ 是一个伪随机函数，则CRT模式是CPA-安全的。【证明on P93】 3.7 选择密文攻击 CCA-安全 CCA不可区分实验 $\\mathsf{PrivK}^\\mathsf{cca}_{\\mathcal{A},\\Pi}(n)$ ： $k\\leftarrow \\mathsf{Gen(1^n)}$ ； 敌手 $\\mathcal{A}$ 得到输入 $1^n$ 并能够使用oracle $\\mathsf{Enc}_k(\\cdot)$ 和 $\\mathsf{Dec}_k(\\cdot)$ ，输出一对相同长度的消息 $m_0$ 和 $m_1$ ； 随机选择 $b\\in{0,1}$ ，计算 $c\\leftarrow \\mathsf{Enc}k(m{b})$ ，并发送给 $\\mathcal{A}$ ； $\\mathcal{A}$ 可以继续使用 $\\mathsf{Enc}_k(\\cdot)$ 和 $\\mathsf{Dec}_k(\\cdot)$ ，但不能对挑战密文使用 $\\mathsf{Dec}_k(\\cdot)$。最终 $\\mathcal{A}$ 输出一比特 $b’$ ； 若 $b=b’$ 则实验输出1，$\\mathcal{A}$ 获胜，反之输出0。 定义3.33：对称加密方案 $\\Pi=(\\mathsf{Gen}, \\mathsf{Enc}, \\mathsf{Dec})$ 是CCA-安全的（对选择密文攻击不可区分），如果对所有PPT敌手 $\\mathcal{A}$ 有一个可忽略函数 $\\mathsf{negl}$ ，使得对所有n： $$Pr[\\mathsf{PrivK}^\\mathsf{cca}_{\\mathcal{A},\\Pi}(n)=1]\\leq \\frac{1}{2}+\\mathsf{negl}(n)$$ 注：任何CCA-安全的对称加密方案都是多消息CCA-安全的 之前所讨论的所有加密方案都不是CCA安全的，例如对于构造3.30：敌手选择 $m_0=0n,,m_1=1n$ ，在收到密文 $c=\\langle r,s\\rangle$ 之后，敌手反转 $s$ 的第一位，并将新的密文 $c’=\\langle r,s’\\rangle$ 发送到 $\\mathsf{Dec}_k(\\cdot)$ 进行解密，若结果是 $10^{n-1}$ 说明 $b=0$ ，若结果是 $01^{n-1}$ 说明 $b=1$ CCA-安全的一个重要性质是non-malleability，即对于一个密文，若对其做一些修改，则解密要么无效要么结果与原本的结果毫无关系 Padding-Oracle Attacks 攻击者只需要知道修改后的密文是否能够有效解密，具体攻击方法见P98 Chapter 4: Message Authentication Codes 4.2 MAC（消息认证码）定义 定义4.1：一个MAC包含三个PPT算法 $(\\mathsf{Gen},\\mathsf{Mac},\\mathsf{Vrfy})$ ：满足 $\\mathsf{Vrfy}_k(m,\\mathsf{Mac}_k(m))=1$ $\\mathsf{Gen}$ 根据输入安全参数 $1^n$ ，输出密钥 $k,,|k|\\geq n$ $\\mathsf{Mac}$ 根据输入密钥 $k$ 和消息 $m\\in{0,1}^*$ ，输出一个标签 $t$ ，即 $t\\leftarrow \\mathsf{Mac}_k(m)$ $\\mathsf{Vrfy}$ 是确定性算法，根据输入密钥 $k$ 、消息 $m$ 和标签 $t$ ，输出一比特 $b$ ，即 $b:=\\mathsf{Vrfy}_k(m,t)$ 。若 $b=1$ 说明验证通过 消息认证实验 $\\mathsf{Mac{-}forge}_{\\mathcal{A},\\Pi}(n)$ ： $k\\leftarrow \\mathsf{Gen}(1^n)$ 敌手 $\\mathcal{A}$ 得到输入 $1^n$ 并能够使用oracle $\\mathsf{Mac}_k(\\cdot)$ 。敌手最终输出 $(m,t)$ 。令 $\\mathcal{Q}$ 表示 $\\mathcal{A}$ 对oracle的所有请求集合 $\\mathcal{A}$ 成功当且仅当(1). $\\mathsf{Vrfy}_k(m,t)=1$ 和(2). $m\\notin \\mathcal{Q}$ ，此时实验输出1 定义4.2：MAC算法 $\\Pi=(\\mathsf{Gen},\\mathsf{Mac},\\mathsf{Vrfy})$ 是安全的，若对所有PPT敌手 $\\mathcal{A}$ 存在一个可忽略函数 $\\mathsf{negl}$ 使得： $$ Pr[\\mathsf{Mac{-}forge}_{\\mathcal{A},\\Pi}(n)=1]\\leq \\mathsf{negl}(n) $$ 以上定义的安全的MAC算法不能抵抗重放攻击，因为它不对消息的状态进行验证，只要 $(m,t)$ 是有效的就可以通过验证 消息认证增强实验 $\\mathsf{Mac{-}sforge}_{\\mathcal{A},\\Pi}(n)$ ： $k\\leftarrow \\mathsf{Gen}(1^n)$ 敌手 $\\mathcal{A}$ 得到输入 $1^n$ 并能够使用oracle $\\mathsf{Mac}_k(\\cdot)$ 。敌手最终输出 $(m,t)$ 。令 $\\mathcal{Q}$ 表示所有的请求过的 $(m,t)$ 集合 $\\mathcal{A}$ 成功当且仅当(1). $\\mathsf{Vrfy}_k(m,t)=1$ 和(2). $(m,t)\\notin \\mathcal{Q}$ ，此时实验输出1 定义4.3：MAC算法 $\\Pi=(\\mathsf{Gen},\\mathsf{Mac},\\mathsf{Vrfy})$ 是强安全的，若对所有PPT敌手 $\\mathcal{A}$ 存在一个可忽略函数 $\\mathsf{negl}$ 使得： $$ Pr[\\mathsf{Mac{-}sforge}_{\\mathcal{A},\\Pi}(n)=1]\\leq \\mathsf{negl}(n) $$ 命题4.4：令 $\\Pi=(\\mathsf{Gen},\\mathsf{Mac},\\mathsf{Vrfy})$ 是一个安全的MAC算法，则它也是强安全的 4.3 构造安全MAC 固定长度MAC 构造4.5： 定理4.6：若 $F$ 是一个伪随机函数，则构造4.5对于长度为 $n$ 的消息是安全的MAC【证明on P117】 任意长度MAC 构造4.7： 定理4.8：如果 $\\Pi’$ 是安全的定长MAC，则构造4.7也是安全MAC【证明on P120】 4.4 CBC-MAC 基本构造4.11（定长CBC-MAC）： 定理4.12：令 $\\ell$ 为多项式，若 $F$ 是伪随机函数，则构造4.11是对长度为 $\\ell(n)\\cdot n$ 的消息的安全MAC 构造任意长度的CBC-MAC *安全性证明on P125，包括： 定理4.13 断言4.14 断言4.15 4.5 认证加密 定义 不可伪造加密实验 $\\mathsf{Enc{-}Forge}_{\\mathcal{A},\\Pi}(n)$ ： $k\\leftarrow \\mathsf{Gen}(1^n)$ 敌手 $\\mathcal{A}$ 得到输入 $1^n$ 并能够使用加密oracle $\\mathsf{Enc}_k(\\cdot)$ 。敌手最终输出密文 $c$ 令 $m:=\\mathsf{Dec}_k©$ ，令 $\\mathcal{Q}$ 表示 $\\mathcal{A}$ 对加密oracle的所有请求集合。实验输出1当且仅当(1) $m\\neq\\perp$ 和(2) $m\\notin \\mathcal{Q}$ 若敌手可以伪造一个密文，使其能够成功解密，则敌手获胜 定义4.16：一个对称加密方案 $\\Pi$ 是不可伪造的，如果对所有PPT敌手 $\\mathcal{A}$ 存在一个可忽略函数 $\\mathsf{negl}$ 使得： $$ Pr[\\mathsf{Enc{-}Forge}_{\\mathcal{A},\\Pi}(n)=1]\\leq\\mathsf{negl}(n) $$ 定义4.17：一个对称加密方案是一个认证加密方案，如果它既是CCA-安全的又是不可伪造的 一般构造 Encrypt-and-authenticate： $$ c\\leftarrow\\mathsf{Enc}{k_E}(m),,and,,t\\leftarrow\\mathsf{Mac}{k_E}(m) $$ 不能保证基本的安全性，因为MAC并没有机密性要求，从而可能泄露关于 $m$ 的信息 Authenticate-then-encrypt： $$ t\\leftarrow\\mathsf{Mac}{k_E}(m),,and,,c\\leftarrow\\mathsf{Enc}{k_E}(m||t) $$ 不能保证一定是认证加密方案，例如对于CBC模式加密，将 $t$ 看作是对消息 $m$ 的填充，则对于解密失败存在两种情况：填充错误或MAC验证失败，但只要攻击者能分辨两种错误，就可以正确解密，如3.7节最后的Padding-Oracle Attacks所示 Encrypt-then-authenticate： $$ c\\leftarrow\\mathsf{Enc}{k_E}(m),,and,,t\\leftarrow\\mathsf{Mac}{k_E}© $$ 正式构造4.18如下： 定理4.19：令 $\\Pi_E$ 是CPA-安全的对称加密方案， $\\Pi_M$ 是强安全的MAC，则构造4.18是认证加密方案【证明on P136】 Chapter 5: Hash Functions and Applications 5.1 定义 抗碰撞 定义5.1：哈希函数是一对PPT算法 $(\\mathsf{Gen},H)$ ，满足： $\\mathsf{Gen}$ 是一个概率算法，输入安全参数 $1^n$ ，输出密钥 $s$ 。假设 $1^n$ 隐含在 $s$ 中 $H$ 根据输入密钥 $s$ 和字符串 $x\\in{0,1}^*$ ，输出字符串 $Hs(x)\\in{0,1}{\\ell(n)}$ collision-finding实验 $\\mathsf{Hash{-}coll}_{\\mathcal{A},\\Pi}(n)$ ： $s\\leftarrow\\mathsf{Gen}(1^n)$ 敌手 $\\mathcal{A}$ 根据输入 $s$ 输出 $x,x’$ 实验输出1当且仅当 $x\\neq x’$ 且 $Hs(x)=Hs(x’)$ ，此时称 $\\mathcal{A}$ 找到了碰撞 定义5.2：哈希函数 $\\Pi=(\\mathsf{Gen},H)$ 是抗碰撞的，如果对所有PPT敌手 $\\mathcal{A}$ 存在一个可忽略函数 $\\mathsf{negl}$ 使得： $$ Pr[\\mathsf{Hash{-}coll}_{\\mathcal{A},\\Pi}(n)=1]\\leq \\mathsf{negl}(n) $$ 在实际应用中，哈希函数通常是unkeyed的，即 $H: {0,1}*\\rightarrow{0,1}\\ell$ ，从理论的角度这是不安全的，因为所有哈希函数在生成的时候就硬编码了碰撞对 $(x,x’)$ ，但是实践中找到这样的碰撞对是困难的，因此unkeyed哈希函数还是计算安全的 较弱的安全概念 弱抗碰撞性（抗第一原像）：给定 $s,x$ ，PPT敌手找到 $x’\\neq x$ 使得 $Hs(x’)=Hs(x)$ 是不可行的 单向性（抗第二原像）：给定 $s,y$ ，PPT敌手找到 $x$ 使得 $H^s(x)=y$ 是不可行的 抗碰撞 =&gt; 弱抗碰撞 =&gt; 单向 5.2 域扩张：Merkle-Damgard变换 用于将压缩函数扩展为完整的哈希函数，同时保持前者的抗碰撞性 将定长输入的哈希函数通过Merkle-Damgard变换转换为任意长度输入的哈希函数，构造5.3： 定理5.4：如果 $(\\mathsf{Gen},h)$ 是抗碰撞的，则 $(\\mathsf{Gen},H)$ 也是抗碰撞的【证明on P157】【形式化证明on 练习5.4】 5.3 使用哈希函数实现消息认证 Hash-and-MAC 构造5.5： 定理5.6：若 $\\Pi$ 是对长 $\\ell$ 的消息安全的MAC，且 $\\Pi_H$ 是抗碰撞的，则构造5.5是对任意长消息安全的MAC【证明on P160】 HMAC 构造5.7： 5.5 Random-Oracle模型 向oracle查询 $x$ 并得到输出 $y$ ，$x$ 是保密的，甚至查询oracle这个事件本身也是保密的 一致性：若对特定的输入 $x$ ，oracle输出 $y$ ，则之后再输入相同的 $x$ ，oracle仍然输出 $y$ 一些性质： 若 $x$ 没有发送到 $H$ 进行查询，则 $H(x)$ 的值是均匀随机的 即使 $x$ 不是随机的，甚至 $x$ 是已知的， $H(x)$ 的值也是均匀随机的 若 $\\mathcal{A}$ 向 $H$ 请求 $x$ ，则规约过程可以看到这个请求，也能知道 $x$ 规约过程可以设置 $H(x)$ 的值，只要这个值是均匀随机分布的 Random-Oracle实例 假设Random-Oracle将 $\\ell_{in}$ 比特输入映射为 $\\ell_{out}$ 比特输出，且 $\\ell_{in},\\ell_{out}&gt;n$ Random-Oracle作伪随机生成器（$\\ell_{in}&lt;\\ell_{out}$） $|Pr[\\mathcal{A}{H(\\cdot)}(y)=1]-Pr[\\mathcal{A}{H(\\cdot)}(H(x))=1]|\\leq \\mathsf{negl}(n)$ ，其中 $x\\in{0,1}{\\ell_{in}(n)},,y\\in{0,1}{\\ell{out}(n)}$ Random-Oracle作抗碰撞哈希函数（$\\ell_{in}&gt;\\ell_{out}$） 任何PPT敌手 $\\mathcal{A}$ 成功进行如下实验的概率可忽略： 选择随机函数 $F$ $\\mathcal{A}$ 获胜，当他输出不同的 $x,x’$ 使得 $H(x)=H(x’)$ Chapter 7: Theoretical Constructions of Symmetric-Key Primitives 7.1 单向函数 定义 逆转实验 $\\mathsf{Invert}_{\\mathcal{A},f}(n)$ ： 随机均匀选择 $x\\in{0,1}^n$ ，计算 $y:=f(x)$ $\\mathcal{A}$ 根据输入 $1^n$ 和 $y$ ，得到输出 $x’$ 当 $f(x’)=y$ 时，实验的输出为1，否则输出0 定义7.1：函数 $f:{0,1}*\\rightarrow{0,1}*$ 是单向函数，若满足： （计算简单）存在一个多项式时间算法 $M_f$ 来计算 $f$ ，即对所有 $x$ 有 $M_f(x)=f(x)$ （求逆困难）对所有PPT算法 $\\mathcal{A}$ 存在一个可忽略函数使得： $$ Pr[\\mathsf{Invert}_{\\mathcal{A},f}(n)=1]\\leq\\mathsf{negl}(n) $$ 对于2，可以将其简记为： $$ \\underset{x\\leftarrow{0,1}n}{Pr}[\\mathcal{A}(1n,f(x))\\in f^{-1}(f(x))]\\leq\\mathsf{negl}(n) $$ 定义7.2：PPT算法组成的元组 $\\Pi=(\\mathsf{Gen},\\mathsf{Samp},f)$ 是一个函数族，若满足： 参数生成算法 $\\mathsf{Gen}$ 根据输入 $1^n$ ，输出参数 $I,,|I|\\geq n$ 。$I$ 中的每一个值定义了函数 $f_I$ 的定义域 $\\mathcal{D}_I$ 和值域 $\\mathcal{R}_I$ 采样算法 $\\mathsf{Samp}$ 根据输入 $1^n$ ，输出 $\\mathcal{D}_I$ 的一个均匀分布的元素 评估算法（确定性）$f$ 根据输入 $I$ 和 $x\\in\\mathcal{D}_I$ ，输出 $y\\in\\mathcal{R}_I$ ，记作 $y:=f_I(x)$ $\\Pi$ 是一个排列族，若对所有 $\\mathsf{Gen}(1^n)$ 输出的 $I$ 的值，满足 $\\mathcal{D}_I=\\mathcal{R}_I$ 且函数 $f_I:\\mathcal{D}_I\\rightarrow\\mathcal{D}_I$ 是双射（单射且满射） 对函数族定义逆转实验 $\\mathsf{Invert}_{\\mathcal{A},\\Pi}(n)$ ： 运行 $\\mathsf{Gen}(1^n)$ 来获取 $I$ ，运行 $\\mathsf{Samp}(I)$ 来获取随机均匀 $x\\in\\mathcal{D}_I$ ，最后计算 $y:=f_I(x)$ $\\mathcal{A}$ 根据输入 $I,,y$，输出 $x’$ 当 $f(x’)=y$ 时，实验的输出为1，否则输出0 定义7.3：函数族/排列族 $\\Pi=(\\mathsf{Gen},\\mathsf{Samp},f)$ 是单向的，若对所有PPT敌手 $\\mathcal{A}$ 存在一个可忽略函数 $\\mathsf{negl}$ 使得： $$ Pr[\\mathsf{Invert}_{\\mathcal{A},\\Pi}(n)=1]\\leq\\mathsf{negl}(n) $$ 硬核谓词 定义7.4：函数 $\\mathsf{hc}:{0,1}^*\\rightarrow{0,1}$ 是函数 $f$ 的硬核谓词，若 $\\mathsf{hc}$ 可以在多项式时间内计算，并且对所有PPT敌手 $\\mathcal{A}$ 存在一个可忽略函数 $\\mathsf{negl}$ 使得： $$ \\underset{x\\leftarrow{0,1}n}{Pr}[\\mathcal{A}(1n,f(x))=\\mathsf{hc}(x)]\\leq\\frac{1}{2}+\\mathsf{negl}(n) $$ $\\mathsf{hc}(x)$ 可以根据 $x$ 很容易算出，但很难根据 $f(x)$ 算出 7.2 单向函数构造伪随机 Step1：说明任何单向函数都存在硬核谓词 定理7.5（Goldreich–Levin定理）：假设单向函数存在，则存在一个单向函数 $g$ 和一个 $g$ 硬核谓词 $\\mathsf{hc}$ 具体来说，令 $f$ 是一个单向函数，可以构造 $g(x,r)\\overset{def}{=}(f(x),r),,|x|=|r|$ ，并定义： $$ \\mathsf{hc}(x,r)\\overset{def}{=}\\oplus^n_{i=1}x_i\\cdot r_i $$ Step2：说明单向排列的硬核谓词可以构造伪随机生成器 定理7.6：令 $f$ 是一个单向排列，$\\mathcal{hc}$ 是 $f$ 的硬核谓词，则 $G(s)\\overset{def}{=}f(s)||\\mathsf{hc}(s)$ 是扩张因子 $\\ell(n)=n+1$ 的伪随机生成器 定理7.7：如果存在一个扩张因子 $\\ell(n)=n+1$ 的伪随机生成器，则对任何多项式 $\\mathsf{poly}$ 存在一个扩张因子为 $\\mathsf{poly}(n)$ 伪随机生成器 Step3：根据伪随机生成器构造伪随机函数 定理7.8：如果存在一个扩张因子 $\\ell(n)=2n$ 的伪随机生成器，则存在一个伪随机函数 定理7.9：如果存在一个伪随机函数，则存在一个强伪随机排列 推论7.10：假设存在单向函数，则存在任何扩张因子的伪随机生成器，伪随机函数，强伪随机排列 推论7.11：如果存在单向函数，则存在CCA-安全的对称加密方案以及安全的MAC 7.8 计算不可区分性 定义7.30：两个概率集合 $\\mathcal{X}={X_n}{n\\in\\mathbb{N}}$ 和 $\\mathcal{Y}={Y_n}{n\\in\\mathbb{N}}$ 是计算不可区分的，记作 $\\mathcal{X}\\overset{c}{\\equiv}\\mathcal{Y}$ ，若对所有PPT判别器 $D$ 存在一个可忽略函数 $\\mathsf{negl}$ 使得： $$ |\\underset{x\\leftarrow X_n}{Pr}[D(1^n,x)=1]-\\underset{y\\leftarrow Y_n}{Pr}[D(1^n,y)=1]|\\leq\\mathsf{negl}(n) $$ 概率集合是无穷多概率分布的序列 通常也会把 $\\underset{x\\leftarrow X_n}{Pr}[D(1^n,x)=1]$ 记作 $Pr[D(1^n,X_n)=1]$ 计算不可区分具有传递性，即：若 $\\mathcal{X}\\overset{c}{\\equiv}\\mathcal{Y},,\\mathcal{Y}\\overset{c}{\\equiv}\\mathcal{Z}$ ，则 $\\mathcal{X}\\overset{c}{\\equiv}\\mathcal{Z}$ 使用计算不可区分定义伪随机生成器——定义7.31：令 $\\ell(\\cdot)$ 是一个多项式，令 $G$ 是一个确定性多项式时间算法，且对所有 $s$ 满足 $|G(s)|=\\ell(|s|)$ 。$G$ 是伪随机生成器若满足： （扩张）对所有 $n$ 满足 $\\ell(n)&gt;n$ （伪随机）集合 ${G(U_n)}{n\\in\\mathbb{N}}$ 与 ${U{\\ell(n)}}_{n\\in\\mathbb{N}}$ 在计算上不可区分 其中 $U_n$ 代表在 ${0,1}^n$ 上的均匀分布 令 $\\mathcal{X}$ 和 $\\mathcal{Y}$ 是计算不可区分的可采样概率集合，则对所有多项式 $p$ ，集合 $\\overline{\\mathcal{X}}={(X_n{(1)},…,X_n{p(n)})}{n\\in\\mathbb{N}}$ 和 $\\overline{\\mathcal{Y}}={(Y_n{(1)},…,Y_n{p(n)})}{n\\in\\mathbb{N}}$ 计算不可区分 Chapter 10: Key Management and the Public-Key Revolution 10.3 密钥交换和Diffie-Hellman协议 密钥交换实验 $\\mathsf{KE}_{\\mathcal{A},\\Pi}^{\\mathsf{eav}}(n)$ ： 两个参与方使用 $1^n$ 来执行协议 $\\Pi$ 。协议执行完会产生一个记录 $\\mathsf{trans}$ ，包含双方交流的所有信息以及双方最终输出的密钥 $k$ 随机均匀选择 $b\\in{0,1}$ 。若 $b=0$ 则令 $\\hat{k}:=k$ ，否则随机均匀选择 $\\hat{k}\\in{0,1}^n$ $\\mathcal{A}$ 根据收到的 $\\mathsf{trans}$ 和 $\\hat{k}$ ，输出一比特 $b’$ 若 $b=b’$ 则实验输出1，否则输出0 定义10.1：密钥交换协议 $\\Pi$ 对窃听者安全，若对所有PPT敌手存在一个可忽略函数 $\\mathsf{negl}$ 使得： $$ Pr[\\mathsf{KE}_{\\mathcal{A},\\Pi}^{\\mathsf{eav}}(n)=1]\\leq\\frac{1}{2}+\\mathsf{negl}(n) $$ 构造10.2：（Diffie-Hellman协议） 其中 $\\mathbb{G}$ 是一个循环群，$q$ 是 $\\mathbb{G}$ 的阶，$g$ 是 $\\mathbb{G}$ 的生成元 定理10.3：若 $\\mathcal{G}$ 的决策Diffie-Hellman问题是困难的，则Diffie-Hellman协议对于窃听者是安全的【证明on P368】 其中决策Diffie-Hellman问题指：任何敌手给定 $g,gx,gy$ 都不能将共享密钥 $g^{xy}$ 与随机均匀的值区分 Chapter 11: Public-Key Encryption 11.2 定义 定义11.1：公钥加密方案是一个PPT算法的三元组 $(\\mathsf{Gen},\\mathsf{Enc},\\mathsf{Dec})$ ： $\\mathsf{Gen}$ 根据输入的安全参数 $1^n$ ，输出一对密钥 $(pk,sk)$ $\\mathsf{Enc}$ 根据输入的公钥 $pk$ 和消息 $m$ ，输出密文 $c$ ，记作 $c\\leftarrow\\mathsf{Enc}_{pk}(m)$ $\\mathsf{Dec}$ 根据输入的私钥 $sk$ 和密文 $c$ ，输出消息 $m$ 或者失败 $\\bot$ ，记作 $m:=\\mathsf{Dec}_{sk}©$ 抵抗选择明文攻击 窃听不可区分实验 $\\mathsf{PubK}^{\\mathsf{eav}}_{\\mathcal{A},\\Pi}(n)$ ： $(pk,sk)\\leftarrow\\mathsf{Gen}(1^n)$ 敌手 $\\mathcal{A}$ 获得公钥 $pk$ ，并输出一对等长的消息 $m_0,,m_1$ 随机均匀选择 $b\\in{0,1}$ ，计算 $c\\leftarrow\\mathsf{Enc}_{pk}(m_b)$ ，然后将挑战密文 $c$ 发送给 $\\mathcal{A}$ $\\mathcal{A}$ 输出 $b’$ ，若 $b=b’$ 则实验输出1（敌手成功），否则输出0 定义11.2：一个公钥加密方案 $\\Pi=(\\mathsf{Gen},\\mathsf{Enc},\\mathsf{Dec})$ 对窃听攻击者不可区分，若对所有PPT敌手 $\\mathcal{A}$ 存在一个可忽略函数 $\\mathsf{negl}$ 使得： $$ Pr[\\mathsf{PubK}_{\\mathcal{A},\\Pi}^{\\mathsf{eav}}(n)=1]\\leq\\frac{1}{2}+\\mathsf{negl}(n) $$ 命题11.3：若一个公钥加密方案对窃听攻击者不可区分，则它也是CPA-安全的 对于公钥加密而言，任何窃听敌手都可以获得公钥来加密明文 定理11.4：确定性公钥加密方案都不是CPA安全的 多消息加密 LR-oracle实验 $\\mathsf{PubK}^{\\mathsf{LR-cpa}}_{\\mathcal{A},\\Pi}(n)$ ： $(pk,sk)\\leftarrow\\mathsf{Gen}(1^n)$ 随机均匀选择 $b\\in{0,1}$ 敌手 $\\mathcal{A}$ 获得输入 $pk$ ，并且可以访问oracle $\\mathsf{LR}_{pk,b}(\\cdot,\\cdot)$ 敌手 $\\mathcal{A}$ 输出一比特 $b’$ 若 $b=b’$ 则实验输出1（敌手成功），否则输出0 其中oracle $\\mathsf{LR}{pk,b}(\\cdot,\\cdot)$ ：输入两个等长的消息 $m_0$ ，$m_1$ ，若 $b=0$ 输出 $c\\leftarrow \\mathsf{Enc}{pk}(m_0)$ ；若 $b=1$ 输出 $c\\leftarrow \\mathsf{Enc}_{pk}(m_1)$ 定义11.5：一个公钥加密方案 $\\Pi=(\\mathsf{Gen},\\mathsf{Enc},\\mathsf{Dec})$ 对窃听攻击者是多消息不可区分的，若对所有PPT敌手 $\\mathcal{A}$ 存在一个可忽略函数 $\\mathsf{negl}$ 使得： $$ Pr[\\mathsf{PubK}_{\\mathcal{A},\\Pi}^{\\mathsf{LR-cpa}}(n)=1]\\leq\\frac{1}{2}+\\mathsf{negl}(n) $$ 定理11.6：若一个公钥加密方案是CPA-安全的，则它也是多消息不可区分的【*证明on P383】 断言11.7：$\\Pi=(\\mathsf{Gen},\\mathsf{Enc},\\mathsf{Dec})$ 是对一比特消息进行加密的公钥加密方案，$\\Pi’=(\\mathsf{Gen’},\\mathsf{Enc’},\\mathsf{Dec’})$ 是对任意长消息进行加密的公钥加密方案，构造如下：$\\mathsf{Enc’}{pk}(m)=\\mathsf{Enc}{pk}(m_1),…,\\mathsf{Enc}{pk}(m{\\ell})$ ，其中 $m=m_1\\cdot\\cdot\\cdot m_{\\ell}$ 。则如果 $\\Pi$ 是CPA-安全的，$\\Pi’$ 也是 抵抗选择密文攻击 CCA不可区分实验 $\\mathsf{PubK}^{\\mathsf{cca}}_{\\mathcal{A},\\Pi}(n)$ ： $(pk,sk)\\leftarrow\\mathsf{Gen}(1^n)$ 敌手 $\\mathcal{A}$ 获得 $pk$ ，并且可以访问解密oracle $\\mathsf{Dec}_{sk}(\\cdot)$ 。$\\mathcal{A}$ 输出一对等长消息 $m_0,m_1$ 随机均匀选择 $b\\in{0,1}$ ，计算 $c\\leftarrow\\mathsf{Enc}_{pk}(m_b)$ 并发送给 $\\mathcal{A}$ $\\mathcal{A}$ 可以继续与解密oracle交互，但不能解密 $c$ 。最终 $\\mathcal{A}$ 输出一比特 $b’$ 若 $b=b’$ 则实验输出1（敌手成功），否则输出0 定义11.8：一个公钥加密方案 $\\Pi=(\\mathsf{Gen},\\mathsf{Enc},\\mathsf{Dec})$ 是CCA-安全的，若对所有PPT敌手 $\\mathcal{A}$ 存在一个可忽略函数 $\\mathsf{negl}$ 使得： $$ Pr[\\mathsf{PubK}_{\\mathcal{A},\\Pi}^{\\mathsf{cca}}(n)=1]\\leq\\frac{1}{2}+\\mathsf{negl}(n) $$ 若一个公钥加密方案是CCA-安全的，则它也是多消息CCA-安全的 11.3 混合加密和KEM/DEM范式 定义11.9：一个密钥封装机制（KEM）是PPT算法的三元组 $(\\mathsf{Gen},\\mathsf{Encaps},\\mathsf{Decaps})$ 使得： 密钥生成算法 $\\mathsf{Gen}$ 根据输入的安全参数 $1^n$ ，输出公私钥对 $(pk,sk)$ 密封算法 $\\mathsf{Encaps}$ 根据输入的安全参数 $1^n$ 和公钥 $pk$ ，输出密文 $c$ 和密钥 $k\\in{0,1}^{\\ell(n)}$ ，其中 $\\ell$ 是密钥长度。记作 $(c,k)\\leftarrow\\mathsf{Encaps}_{pk}(1^n)$ 确定性的解封算法 $\\mathsf{Decaps}$ 根据输入的私钥 $sk$ 和密文 $c$ ，输出密钥 $k$ 或者一个特殊符号 $\\bot$ 来表示解封失败。记作 $k:=\\mathsf{Decaps}_{sk}©$ 构造11.10： CPA-安全 令 $\\Pi=(\\mathsf{Gen},\\mathsf{Encaps},\\mathsf{Decaps})$ 是KEM，定义CPA不可区分实验 $\\mathsf{KEM}^{\\mathsf{cpa}}_{\\mathcal{A},\\Pi}(n)$ ： $(pk,sk)\\leftarrow\\mathsf{Gen}(1^n)$ ，然后 $(c,k)\\leftarrow\\mathsf{Encaps}_{pk}(1^n)$ ，其中 $k\\in{0,1}^n$ 随机均匀选择 $b\\in{0,1}$ 。若 $b=0$ 则令 $\\hat{k}:=k$ ，若 $b=1$ ，则随机均匀选择 $\\hat{k}\\in{0,1}^n$ $\\mathcal{A}$ 获得 $(pk,c,\\hat{k})$ ，并输出 $b’$ 。若 $b=b’$ 则实验输出1（敌手成功），否则输出0 定义11.11：一个KEM $\\Pi$ 是CPA-安全的，若对所有PPT敌手 $\\mathcal{A}$ 存在一个可忽略函数 $\\mathsf{negl}$ 使得： $$ Pr[\\mathsf{KEM}_{\\mathcal{A},\\Pi}^{\\mathsf{cpa}}(n)=1]\\leq\\frac{1}{2}+\\mathsf{negl}(n) $$ 定理11.12：若 $\\Pi$ 是一个CPA-安全的KEM，$\\Pi’$ 是一个对窃听攻击不可区分的对称加密方案，则构造11.10中的 $\\Pi^{\\mathsf{hy}}$ 是CPA-安全的公钥加密方案【证明on P394】 CCA-安全 令 $\\Pi=(\\mathsf{Gen},\\mathsf{Encaps},\\mathsf{Decaps})$ 是KEM，定义CCA不可区分实验 $\\mathsf{KEM}^{\\mathsf{cca}}_{\\mathcal{A},\\Pi}(n)$ ： $(pk,sk)\\leftarrow\\mathsf{Gen}(1^n)$ ，然后 $(c,k)\\leftarrow\\mathsf{Encaps}_{pk}(1^n)$ ，其中 $k\\in{0,1}^n$ 随机均匀选择 $b\\in{0,1}$ 。若 $b=0$ 则令 $\\hat{k}:=k$ ，若 $b=1$ ，则随机均匀选择 $\\hat{k}\\in{0,1}^n$ $\\mathcal{A}$ 获得 $(pk,c,\\hat{k})$ 以及可以访问oracle $\\mathsf{Decaps}_{sk}(\\cdot)$ ，但不能请求解封挑战密文 $c$ $\\mathcal{A}$ 输出 $b’$ 。若 $b=b’$ 则实验输出1（敌手成功），否则输出0 定义11.13：一个KEM $\\Pi$ 是CCA-安全的，若对所有PPT敌手 $\\mathcal{A}$ 存在一个可忽略函数 $\\mathsf{negl}$ 使得： $$ Pr[\\mathsf{KEM}_{\\mathcal{A},\\Pi}^{\\mathsf{cca}}(n)=1]\\leq\\frac{1}{2}+\\mathsf{negl}(n) $$ 定理11.14：若 $\\Pi$ 是一个CCA-安全的KEM，$\\Pi’$ 是一个CCA-安全的对称加密方案，则构造11.10中的 $\\Pi^{\\mathsf{hy}}$ 是CCA-安全的公钥加密方案","categories":[{"name":"Notes","slug":"Notes","permalink":"http://example.com/categories/Notes/"}],"tags":[{"name":"cryptography","slug":"cryptography","permalink":"http://example.com/tags/cryptography/"}]},{"title":"Markdown数学符号补充","slug":"lookup/markdown-math","date":"2022-03-18T16:00:00.000Z","updated":"2022-04-28T07:39:54.000Z","comments":true,"path":"2022/03/19/lookup/markdown-math/","link":"","permalink":"http://example.com/2022/03/19/lookup/markdown-math/","excerpt":"Markdown数学符号补充","text":"对typora-数学符号进行补充 \\overset{def}{=} $\\overset{def}{=}$ \\underset{x\\leftarrow{0,1}^n}{Pr} $ \\underset{x\\leftarrow{0,1}^n}{Pr}$","categories":[{"name":"Lookup","slug":"Lookup","permalink":"http://example.com/categories/Lookup/"}],"tags":[{"name":"markdown","slug":"markdown","permalink":"http://example.com/tags/markdown/"}]},{"title":"Linux常用命令","slug":"lookup/linux-notes","date":"2022-02-18T16:00:00.000Z","updated":"2022-11-03T06:09:18.167Z","comments":true,"path":"2022/02/19/lookup/linux-notes/","link":"","permalink":"http://example.com/2022/02/19/lookup/linux-notes/","excerpt":"Linux常用命令汇总","text":"Debug命令 查找文件位置 1sudo find / -name &lt;file_name&gt; 查看程序依赖的动态链接库 1ldd &lt;file_name&gt; Setup命令 命令行工具 使命令行工具在任意目录下都能直接使用 1sudo ln -s ~/chainmaker/chainmaker-go/tools/cmc/cmc /usr/ 测试命令 查看进程的内存占用 1234# 首先使用top命令找到指定进程的pid（top命令只显示了进程占用内存的百分比，没有具体数值）top# 根据pid打印进程所占内存，每2秒打印一次while true; do pmap -d &lt;pid&gt; | tail -1; sleep 2; done 查看当前目录下所有文件大小 1du -lh --max-depth=1 | sort -n","categories":[{"name":"Linux","slug":"Linux","permalink":"http://example.com/categories/Linux/"},{"name":"Lookup","slug":"Lookup","permalink":"http://example.com/categories/Lookup/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}]},{"title":"rust实践经验","slug":"instruction/rust-notes","date":"2022-01-31T16:00:00.000Z","updated":"2022-09-07T05:50:39.380Z","comments":true,"path":"2022/02/01/instruction/rust-notes/","link":"","permalink":"http://example.com/2022/02/01/instruction/rust-notes/","excerpt":"开发rust程序过程中遇到的问题以及解决方法","text":"开发rust程序过程中遇到的问题以及解决方法 错误处理 对于 Result、Option等类型，如果使用 unwrap、expect等方法，会直接导致panic 对于 Result 类型，如果遇到错误只需要返回 None，那么可以使用如下简单的语法来替代 match : 1let some_var = something_that_returns_result().ok()?; 其中，Result::ok() 函数将 Result 转换为 Option： 对于 Ok(val)，返回 Some(val)； 对于 Err(some_error)，返回 None ? 提取 Option 中的内容，如果为 None，则返回 None slice复制 使用copy_from_slice将一个slice的内容复制到另外一个slice时，要求两个slice的长度相同，因此对于要将[u8]转为[u8; usize]的场景，需要使用以下代码： 1234let v: Vec&lt;u8&gt; = vec![1,2,3];let vs: &amp;[u8] = v.as_slice();let mut vs2: [u8; 32] = [0; 32];vs2[..3].copy_from_slice(vs); 关于所有权 定长的变量存放在栈中，默认实现 Copy 特征，拷贝时直接在栈上复制一个副本，为浅拷贝 不定长或可变的变量存放在堆中，并将其对应的指针压入栈中，拷贝时会转移所有权，若需要原变量也保持所有权，需要进行深拷贝，即将堆中存放的数据也拷贝一份 循环 使用方法 等价使用方式 所有权 for item in collection for item in IntoIterator::into_iter(collection) 转移所有权 for item in &amp;collection for item in collection.iter() 不可变借用 for item in &amp;mut collection for item in collection.iter_mut() 可变借用 Trait 孤儿规则：如果你想要为类型 A 实现特征 T，那么 A 或者 T 至少有一个是在当前作用域中定义的 eg：无法在当前作用域中，为 String 类型实现 Display 特征，因为它们俩都定义在标准库中，其定义所在的位置都不在当前作用域 调用方法需要引入特征： 12345678910111213use std::convert::TryInto;fn main() &#123; let a: i32 = 10; let b: u16 = 100; let b_ = b.try_into() .unwrap(); if a &lt; b_ &#123; println!(&quot;Ten is less than one hundred.&quot;); &#125;&#125; 特征对象： Box&lt;dyn Trait&gt; 或 &amp;dyn Trait Box::leak 需要一个在运行期初始化的值，但是可以全局有效，也就是和整个程序活得一样久 eg. 可以把一个 String 类型，变成一个 'static 生命周期的 &amp;str 类型： 1234567891011fn main() &#123; let s = gen_static_str(); println!(&quot;&#123;&#125;&quot;, s);&#125;fn gen_static_str() -&gt; &amp;&#x27;static str&#123; let mut s = String::new(); s.push_str(&quot;hello, world&quot;); Box::leak(s.into_boxed_str())&#125; Stack overflow 例如定义一个跳表节点 123456struct Node &#123; skips: Vec&lt;Option&lt;*mut Node&gt;&gt;, next: Option&lt;Box&lt;Node&gt;&gt;, key: Vec&lt;u8&gt;, value: Vec&lt;u8&gt;,&#125; 若跳表中节点很多，则在drop头节点时，默认会采用递归的方式来清除，这样会导致爆栈，因此需要自定义迭代方式的drop 123456789impl Drop for Node &#123; fn drop(&amp;mut self) &#123; if let Some(mut next) = self.next.take() &#123; while let Some(n) = next.next.take() &#123; next = n; &#125; &#125; &#125;&#125;","categories":[{"name":"Instruction","slug":"Instruction","permalink":"http://example.com/categories/Instruction/"},{"name":"Rust","slug":"Rust","permalink":"http://example.com/categories/Rust/"}],"tags":[{"name":"rust","slug":"rust","permalink":"http://example.com/tags/rust/"}]},{"title":"go实践经验","slug":"instruction/go-notes","date":"2022-01-31T16:00:00.000Z","updated":"2022-05-02T06:35:08.000Z","comments":true,"path":"2022/02/01/instruction/go-notes/","link":"","permalink":"http://example.com/2022/02/01/instruction/go-notes/","excerpt":"开发go程序过程中遇到的问题以及解决方法","text":"开发go程序过程中遇到的问题以及解决方法 hash 使用 crypto.sha256 可以获得文件哈希： 12345678910111213fileName := &quot;main.go&quot;file, err := os.Open(fileName)if err != nil &#123; log.Fatal(err)&#125;defer file.Close()hash := sha256.New()if _, err = io.Copy(hash, file); err != nil &#123; log.Fatal(err)&#125;sum := hash.Sum(nil)fmt.Printf(&quot;Sum: %x\\n&quot;, sum) 最终得到的哈希值 sum 的类型是 []byte ，若想要得到 string 类型的哈希值不能通过 string(sum) 的方式强制转换，而需要使用以下方法转换： 1hash := hex.EncodeToString(sum) json 使用 json.Marshal 方法可以将 struct 转换为字符串，但其中的特殊html字符会被转义成unicode，例如 &amp; 会被转义为 \\u0026 ，若不想被转义，则需要通过以下方法转换： 123456bf := bytes.NewBuffer([]byte&#123;&#125;)jsonEncoder := json.NewEncoder(bf)jsonEncoder.SetEscapeHTML(false)jsonEncoder.Encode(fdata.Data)fileData := bf.String()fmt.Println(f) slice 拷贝 切片是底层数组的视图，实际指向一段地址 eg. 在将arr放入res，底层是将指向arr切片地址的指针放入res中。若不改变arr大小，仅改变arr中元素的值，会导致之前放入res中的arr产生变化（在递归中会碰到这样的问题） 123456789101112arr := []int&#123;1,2,3&#125;res := [][]int&#123;&#125;res = append(res, arr)// 改变arr中的值，不做扩容arr[2] = 4res = append(res, arr)// arr扩容arr = append(arr, 5)res = append(res, arr)fmt.Println(res)// 输出：[[1 2 4] [1 2 4] [1 2 4 5]] 正确的做法是进行深拷贝： 123456789101112131415161718arr := []int&#123;1,2,3&#125;res := [][]int&#123;&#125;tmp := make([]int, len(arr))copy(tmp, arr)res = append(res, tmp)// 改变arr中的值，不做扩容arr[2] = 4tmp = make([]int, len(arr))copy(tmp, arr)res = append(res, tmp)// arr扩容arr = append(arr, 5)tmp = make([]int, len(arr))copy(tmp, arr)res = append(res, tmp)fmt.Println(res)// 输出：[[1 2 3] [1 2 4] [1 2 4 5]] 垃圾回收 底层的数组会被保存在内存中，直到它不再被引用。但是有时候可能会因为一个slice的小的内存引用而导致底层整个数组处于被使用的状态，这会延迟自动内存回收器对底层数组的回收 例如假设切片里存放的是指针对象，那么下面删除末尾的元素后，被删除的元素依然被切片底层数组引用，从而导致不能及时被自动垃圾回收器回收（这要依赖回收器的实现方式）： 12var a []*int&#123; ... &#125;a = a[:len(a)-1] // 被删除的最后一个元素依然被引用, 可能导致GC操作被阻碍 修复如下： 123var a []*int&#123; ... &#125;a[len(a)-1] = nil // GC回收最后一个元素内存a = a[:len(a)-1] // 从切片删除最后一个元素 另外，若对于一个很大的临时数组，只需要读取其中的一小部分，读取后整个数组不再需要放在var内存中，则应该传值到一个新的数组，而不是直接使用slice引用： 123var bigArr []int&#123; ... &#125;a := append([]int&#123;&#125;, bigArr[1:3]...) map 拷贝 与slice类似，map也是一个指针，若要进行深拷贝，需要对逐个键值对进行拷贝： 1234567891011m := map[int]string&#123;1: &quot;a&quot;, 2: &quot;b&quot;, 3: &quot;c&quot;&#125;mCopy := map[int]string&#123;&#125;for k, v := range m &#123; mCopy[k] = v&#125;m[4] = &quot;d&quot;fmt.Println(m)fmt.Println(mCopy)// 输出：map[1:a 2:b 3:c 4:d]// map[1:a 2:b 3:c] package 同一目录下的同级文件属于一个包，main.go可以直接调用其他文件中的函数，但是在运行的时候需要使用 go run .","categories":[{"name":"Instruction","slug":"Instruction","permalink":"http://example.com/categories/Instruction/"},{"name":"Go","slug":"Go","permalink":"http://example.com/categories/Go/"}],"tags":[{"name":"go","slug":"go","permalink":"http://example.com/tags/go/"}]},{"title":"Chainmaker相关命令","slug":"lookup/chainmaker-commands","date":"2021-12-02T16:00:00.000Z","updated":"2022-04-28T07:37:24.000Z","comments":true,"path":"2021/12/03/lookup/chainmaker-commands/","link":"","permalink":"http://example.com/2021/12/03/lookup/chainmaker-commands/","excerpt":"Chainmaker相关命令","text":"启动、关闭链 启动链 12cd ~/chainmaker/chainmaker-go/scripts./cluster_quick_start.sh normal 各节点的初始状态文件保存在 ~/chainmaker/chainmaker-go/buid/release 中的压缩文件，启动脚本会将其解压，为了保证链的状态不被覆盖，将压缩文件备份： 12mkdir -p ../build/bakmv ../build/release/*.tar.gz ../build/bak 若要重新初始化链，只用将备份的文件重新放回release目录，再启动链： 1234rm -rf ../build/release/*cp ../build/bak/* ../build/release./cluster_quick_start.sh normalrm ../build/release/*.tar.gz 关闭链 1./cluster_quick_stop.sh 查看节点启动使用正常 查看进程是否存在 1ps -ef|grep chainmaker | grep -v grep 看端口是否监听 1netstat -lptn | grep &quot;1230\\|1130&quot; 检查节点是否有ERROR日志 12345cat $HOME/chainmaker/chainmaker-go/build/release/chainmaker-v2.0.0-wx-org1.chainmaker.org/bin/panic.logtail -f $HOME/chainmaker/chainmaker-go/build/release/chainmaker-v2.0.0-wx-org1.chainmaker.org/log/system.logtail -f $HOME/chainmaker/chainmaker-go/build/release/chainmaker-v2.0.0-wx-org1.chainmaker.org/log/system.log|grep &quot;ERROR\\|put block\\|all necessary&quot; 使用Docker镜像进行合约开发 后台启动docker镜像并进入容器内部 1docker run -it --name chainmaker-rust-contract -v $HOME/chainmaker/contract:/home chainmakerofficial/chainmaker-rust-contract:2.1.0 bash 关闭容器后再次进入 123456# 启动容器docker start chainmaker-rust-contract# 进入容器命令行docker exec -it chainmaker-rust-contract bash# 关闭容器docker stop chainmaker-rust-contract 命令行创建wasm合约 12345678910cmc client contract user create \\--contract-name=fact \\--runtime-type=WASMER \\--byte-code-path=./testdata/contract/chainmaker_contract.wasm \\--version=1.0 \\--sdk-conf-path=./testdata/sdk_config.yml \\--admin-key-file-paths=./testdata/crypto-config/wx-org1.chainmaker.org/user/admin1/admin1.tls.key,./testdata/crypto-config/wx-org2.chainmaker.org/user/admin1/admin1.tls.key,./testdata/crypto-config/wx-org3.chainmaker.org/user/admin1/admin1.tls.key \\--admin-crt-file-paths=./testdata/crypto-config/wx-org1.chainmaker.org/user/admin1/admin1.tls.crt,./testdata/crypto-config/wx-org2.chainmaker.org/user/admin1/admin1.tls.crt,./testdata/crypto-config/wx-org3.chainmaker.org/user/admin1/admin1.tls.crt \\--sync-result=true \\--params=&quot;&#123;&#125;&quot; 命令行调用wasm合约 123456cmc client contract user invoke \\--contract-name=fact \\--method=save \\--sdk-conf-path=./testdata/sdk_config.yml \\--params=&quot;&#123;\\&quot;file_name\\&quot;:\\&quot;name007\\&quot;,\\&quot;file_hash\\&quot;:\\&quot;ab3456df5799b87c77e7f88\\&quot;,\\&quot;time\\&quot;:\\&quot;6543234\\&quot;&#125;&quot; \\--sync-result=true","categories":[{"name":"Lookup","slug":"Lookup","permalink":"http://example.com/categories/Lookup/"}],"tags":[{"name":"blockchain","slug":"blockchain","permalink":"http://example.com/tags/blockchain/"}]},{"title":"frp配置","slug":"instruction/frp-setup","date":"2021-11-03T16:00:00.000Z","updated":"2022-12-19T03:40:23.711Z","comments":true,"path":"2021/11/04/instruction/frp-setup/","link":"","permalink":"http://example.com/2021/11/04/instruction/frp-setup/","excerpt":"frp配置","text":"frp安装 下载：https://github.com/fatedier/frp/releases frp配置 服务端 frps.ini 1234567[common]bind_port = 7000token = 12345678# 可在本地通过 ServerIP:7500 查看服务端情况dashboard_user = rootdashboard_pwd = rootdashboard_port = 7500 提供服务的内网机器 frpc.ini 12345678910[common]server_addr = ServerIPserver_port = 7000token = 12345678[secret_ssh]type = stcpsk = 自定义密钥，与下面一致local_ip = 127.0.0.1local_port = 22 注：需要开启22端口，检测方式： 1ssh root@127.0.0.1 访问服务的机器 frpc.ini 123456789101112[common]server_addr = ServerIPserver_port = 7000token = 12345678[secret_ssh_visitor]type = stcprole = visitorserver_name = secret_sshsk = 自定义密钥，与上面一致bind_addr = 127.0.0.1bind_port = 6000 访问内网机器 服务端 Debian (后台运行) 1nohup ./frps -c frps.ini &amp; 内网机器 Ubuntu 1./frpc -c frpc.ini 若要开机自启则需要使用 systemd，参考使用 systemd | frp (gofrp.org) 访问Ubuntu的机器 Windows (写个bat文件方便直接启动) 1frpc.exe -c frpc.ini 在Windows上使用ssh连接 1ssh -oPort=6000 schenk@127.0.0.1 注：连接后需要手动使.bashrc生效 1source ~/.bashrc","categories":[{"name":"Instruction","slug":"Instruction","permalink":"http://example.com/categories/Instruction/"},{"name":"Linux","slug":"Linux","permalink":"http://example.com/categories/Linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}]},{"title":"v2ray配置","slug":"discard/v2ray","date":"2021-10-29T16:00:00.000Z","updated":"2022-04-28T07:09:40.000Z","comments":true,"path":"2021/10/30/discard/v2ray/","link":"","permalink":"http://example.com/2021/10/30/discard/v2ray/","excerpt":"v2ray配置","text":"Debian 9服务端配置 安装v2ray 1234apt install ntp -yapt-get update -y &amp;&amp; apt-get install curl -ybash &lt;(curl -s -L https://git.io/v2ray.sh)v2ray url # generate vmess url 放行端口 iptables 12345iptables -I INPUT -p tcp --dport &lt;port&gt; -j ACCEPTiptables-saveapt-get install iptables-persistentnetfilter-persistent savenetfilter-persistent reload ufw 123ufw statusufw allow &lt;port&gt;ufw reload Windows客户端 https://github.com/2dust/v2rayN/releases/latest Android客户端 https://github.com/2dust/v2rayNG/releases Linux客户端 https://github.com/jiangxufeng/v2rayL","categories":[],"tags":[]},{"title":"SGX移植crate","slug":"instruction/sgx移植","date":"2021-10-24T16:00:00.000Z","updated":"2022-04-28T07:21:52.000Z","comments":true,"path":"2021/10/25/instruction/sgx移植/","link":"","permalink":"http://example.com/2021/10/25/instruction/sgx%E7%A7%BB%E6%A4%8D/","excerpt":"将Rust Crate移植到SGX中","text":"总流程 12345678910111213141516def 移植(self): if self支持 no_std then 不用修改，直接在依赖处配置好 no_std 的 features return # 移植依赖项 (忽略dev-dependencies） for each dep of self.dependencies 移植 dep # 移植自身 (1) wget 库代码 &amp;&amp; tar xzf (2) 编辑 Cargo.toml 修改每个依赖项为移植后的依赖项 (3) 编辑 src&#x2F;lib.rs 添加特定header（见后文） (4) 编辑每个源文件 添加 use std::prelude::v1::*; (5) 仔细review每个使用 fs&#x2F;path&#x2F;net&#x2F;time&#x2F;env 等不可信输入的地方，修正那里的逻辑 (6) 检查每个 platform dependent 的 feature，将其固定为只适用于 linux-x86_64 的逻辑（因为 linux-SGX 就只有这个环境） (7) 测试 &#96;cargo build&#96; 是否通过 return 下载crate 123456https://crates.io/api/v1/crates/&lt;库名&gt;/&lt;版本号&gt;/downloadhttps://crates.io/api/v1/crates/iter-enum/1.0.1/downloadhttps://crates.io/api/v1/crates/pin-project/1.0.8/downloadhttps://crates.io/api/v1/crates/strum_macros/0.21.1/downloadhttps://crates.io/api/v1/crates/thiserror/1.0.30/download 查看依赖 1cargo tree 检查依赖关系 1grep -R &lt;lib&gt; cargo.toml 12345[target.&#x27;cfg(not(target_env = &quot;sgx&quot;))&#x27;.dependencies]sgx_tstd = &#123; rev = &quot;v1.1.3&quot;, git = &quot;https://github.com/apache/teaclave-sgx-sdk.git&quot; &#125;# 引用已移植的cratebyteorder = &#123; git = &quot;https://github.com/mesalock-linux/byteorder-sgx&quot; &#125; lib.rs 123456#![cfg_attr(all(feature = &quot;mesalock_sgx&quot;, not(target_env = &quot;sgx&quot;)), no_std)]#![cfg_attr(all(target_env = &quot;sgx&quot;, target_vendor = &quot;mesalock&quot;), feature(rustc_private))]#[cfg(all(feature = &quot;mesalock_sgx&quot;, not(target_env = &quot;sgx&quot;)))]#[macro_use]extern crate sgx_tstd as std; 每一个.rs文件添加 (包括lib.rs)，若编译时报Warning再对照着删除 1use std::prelude::v1::*; 常见错误 编译时出现： 1234567error[E0432]: unresolved import `core::alloc::AllocRef` --&gt; /home/schenk/.cargo/git/checkouts/teaclave-sgx-sdk-be25c2ad2f03718d/a6a172e/sgx_alloc/src/system.rs:26:17 |26 | AllocError, AllocRef, GlobalAlloc, Layout, | ^^^^^^^^ no `AllocRef` in `alloc`error: aborting due to previous error 说明rustup toolchain选择有问题，使用命令修改toolchain能通过编译: 1rustup override set nightly-2020-10-25-x86_64-unknown-linux-gnu 编译时出现： 12345error: duplicate lang item in crate `std`: `f32_runtime`. | = note: the lang item is first defined in crate `sgx_tstd` (which `helloworldsampleenclave` depends on) = note: first definition in `sgx_tstd` loaded from /home/schenk/sgx/workspace/sgx-test/enclave/target/release/deps/libsgx_tstd-c10171ffd7c558b5.rlib = note: second definition in `std` loaded from /home/schenk/.rustup/toolchains/nightly-2020-10-25-x86_64-unknown-linux-gnu/lib/rustlib/x86_64-unknown-linux-gnu/lib/libstd-3010daceac92f8fa.so, /home/schenk/.rustup/toolchains/nightly-2020-10-25-x86_64-unknown-linux-gnu/lib/rustlib/x86_64-unknown-linux-gnu/lib/libstd-3010daceac92f8fa.rlib 很有可能是因为在这个错误之前出现了其他错误，例如变量未定义等： 123456error[E0425]: cannot find value `sealed_log` in this scope --&gt; src/lib.rs:143:14 |143 | &amp;sealed_log, | ^^^^^^^^^^ not found in this scope 应当先修复其他的错误 notes cfg 12// 条件编译，如果同时满足feature是&quot;mesalock_sgx&quot; 和 target_env不是&quot;sgx&quot;，则编译#[cfg(all(feature = &quot;mesalock_sgx&quot;, not(target_env = &quot;sgx&quot;)))] cfg_attr 12// 如果满足all(feature = &quot;mesalock_sgx&quot;, not(target_env = &quot;sgx&quot;))，则相当于 ![cfg(no_std)]#![cfg_attr(all(feature = &quot;mesalock_sgx&quot;, not(target_env = &quot;sgx&quot;)), no_std)] .toml features 123456# crate本来就没有features的话不用改# 否则在default中加入&quot;mesalock_sgx&quot;，并添加feature mesalock_sgx，在其中加入在crate中引入的&quot;sgx_*&quot;[features]default = [&quot;linkage&quot;, &quot;mesalock_sgx&quot;]linkage = [&quot;sqlite3-src&quot;]mesalock_sgx = [&quot;sgx_tstd&quot;, &quot;sgx_libc&quot;] target.xxx.dependencies：满足xxx条件时的依赖","categories":[{"name":"Instruction","slug":"Instruction","permalink":"http://example.com/categories/Instruction/"},{"name":"Rust","slug":"Rust","permalink":"http://example.com/categories/Rust/"},{"name":"SGX","slug":"SGX","permalink":"http://example.com/categories/SGX/"}],"tags":[{"name":"rust","slug":"rust","permalink":"http://example.com/tags/rust/"},{"name":"sgx","slug":"sgx","permalink":"http://example.com/tags/sgx/"},{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}]},{"title":"Ubuntu连接PEAP网络","slug":"instruction/ubuntu-peap","date":"2021-10-21T16:00:00.000Z","updated":"2022-04-28T07:22:14.000Z","comments":true,"path":"2021/10/22/instruction/ubuntu-peap/","link":"","permalink":"http://example.com/2021/10/22/instruction/ubuntu-peap/","excerpt":"Ubuntu连接PEAP网络,以SJTU校园网为例","text":"创建配置文件： 12cd /etc/NetworkManager/system-connectionssudo gedit SJTU 在SJTU配置文件中添加内容： 1234567891011121314151617181920212223242526[connection]id&#x3D;SJTUuuid&#x3D;9e123fbc-0123-46e3-97b5-f3214e123456 # uniquetype&#x3D;802-11-wireless[802-11-wireless-security]key-mgmt&#x3D;wpa-eapauth-alg&#x3D;open[802-11-wireless]ssid&#x3D;SJTUmode&#x3D;infrastructuremac-address&#x3D;&lt;MAC address&gt;security&#x3D;802-11-wireless-security[802-1x]eap&#x3D;peap;identity&#x3D;&lt;username&gt;phase2-auth&#x3D;mschapv2password&#x3D;&lt;password&gt;[ipv6]method&#x3D;auto[ipv4]method&#x3D;auto 连接SJTU网络：","categories":[{"name":"Instruction","slug":"Instruction","permalink":"http://example.com/categories/Instruction/"},{"name":"Linux","slug":"Linux","permalink":"http://example.com/categories/Linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}]},{"title":"论文阅读-Secure Multiparty Computation from SGX","slug":"paper-reading/paper-secure-mpc","date":"2021-08-15T16:00:00.000Z","updated":"2022-07-20T03:52:52.905Z","comments":true,"path":"2021/08/16/paper-reading/paper-secure-mpc/","link":"","permalink":"http://example.com/2021/08/16/paper-reading/paper-secure-mpc/","excerpt":"论文Secure Multiparty Computation from SGX阅读笔记","text":"1.Introduction 使用可信硬件实现MPC协议需要克服： 用户和远程机器之间缺乏专用通道 在异步通信以及仅有TEE介入的条件下对计算进行身份验证/达成一致 确保“正确”的各方参与计算 处理共存于同一TEE、共享内存空间的代码之间的交互，每段代码可能对应不同的用户 确保TEE内部运行的代码不会向外部泄露敏感信息 1.1 贡献 通用安全多方计算 一个高效的安全多方计算协议（非交互式） 加载进TEE的代码先执行密钥交换，再通过秘密信道执行任意函数 $F$ 标记验证计算LAC 经过验证的输出为计算序列提供完整性保护，输出的完整性可以进行公开验证 为输入添加标签，并将对应于特定标签的输入和输出绑定 对LAC进行正式建模，通过LAC原语将任意程序部署到TEE LAC可用于更多的依赖TEE的安全协议的模块化分析 实现和实验 两个实现： sgx-mpc-mbed ：依赖TLS库，使用RSA进行密钥交换 sgx-mpc-nacl ：依赖NaCl密码学库，使用椭圆曲线密码进行密钥交换和数字签名 3.TEE程序与机器 TEE程序 抽象为编程语言 $L$ ，包含TEE系统调用 TEE中的系统调用结果只能依赖于: 程序加载时定义的初始共享状态 显式传递的输入 新鲜的随机硬币","categories":[{"name":"SGX","slug":"SGX","permalink":"http://example.com/categories/SGX/"},{"name":"Paper Reading","slug":"Paper-Reading","permalink":"http://example.com/categories/Paper-Reading/"}],"tags":[{"name":"sgx","slug":"sgx","permalink":"http://example.com/tags/sgx/"}]},{"title":"论文阅读-TZ4Fabric. Executing Smart Contracts with ARM TrustZone","slug":"paper-reading/paper-TZ4Fabric","date":"2021-06-12T16:00:00.000Z","updated":"2022-04-28T07:43:26.000Z","comments":true,"path":"2021/06/13/paper-reading/paper-TZ4Fabric/","link":"","permalink":"http://example.com/2021/06/13/paper-reading/paper-TZ4Fabric/","excerpt":"论文TZ4Fabric. Executing Smart Contracts with ARM TrustZone阅读笔记","text":"1.引入 Hyperledger Fabric私有链码（FPC）是一个开源项目，它使通道上的节点（区块链网络中节点的子集）在TEE内执行智能合约，特别是在Intel SGX Enclave内。由于物联网设备大多体积小，可能由电池供电，并嵌入低功耗处理器，FPC不容易在这种情况下部署，这极大地阻碍了其在论文的目标部署场景中的适用性。 Fig1描述了论文预想的部署场景：一个异构的、可能分布的节点集合加入了区块链；智能合约必须跨通道执行，只有少数节点受到保护，免受攻击。例如，攻击者可以破坏一个通道，获得对其节点的访问权并收集敏感信息。为了遏制攻击并防止攻击传播到其他通道，某些通道的智能合约可以在TEE内执行。受到TEE保护的节点可以免受恶意攻击，特别是作为物联网设备部署在“野外”的节点更容易受到此类攻击。 本论文提出了结合ARM TZ的Hyperledger Fabric链码执行的原型系统TZ4Fabric。TZ4Fabric体系结构受到FPC的启发，但它隔离了TEE组件。该设计不仅可以利用ARM TZ，还可以TZ4Fabric扩展到未来的TEE。 2.背景 区块链和智能合约 在许可的区块链中(如Ripple和Hyperledger Fabric)，网络的访问是受限制的，实体是已知的。 Hyperledger Fabric (HF)是一个支持智能合约的许可区块链，在HF中，智能合约称为链码。Fig2给出了HF的高层架构和工作流程，在链码函数被调用之前，它必须被安装(存储在文件系统上)并在对等端实例化。 1、2：客户端应用向对等端发送请求（交易提出），来调用链码函数；对等端执行链码函数 3：对等端向客户端发送交易响应，交易响应由对等端签名，并包含执行响应消息以及读集合和写集合，读集合代表对等端在执行期间通过 GetState 从账本中查询到的所有键值，写集合包含对等端通过 PutState 生成的所有键值对更新 4：当客户端收集了由认可策略定义的足够多的交易响应时，将它们发送给排序端，排序端将交易响应放入区块，并将它们分发给所有对等端，这是排序阶段。之后在验证阶段，每个对等端检查是否满足认可策略以及不同交易的读和写是否由冲突，然后就把交易写在账本上，账本包含两个促成部分：一个区块链和一个世界状态，世界状态是一个可插拔的数据库，用于存储和有效检索区块链中的键的当前值 ARM TrustZone 提供硬件组件，用于在ARM处理器上启用TEE。OP-TEE是一个流行的开源运行时，支持ARM TZ。ARM TZ的安全世界和正常世界的切换是通过安全监控呼叫(SMC)进行的。系统资源是严格隔离的：正常世界不能访问安全世界的资源(如内存、外设等)。在安全世界的引导过程中，将建立信任链，并对安全世界的软件映像进行完整性检查——这个过程称为安全引导。 3.威胁模型 考虑一个强大的攻击者，他拥有管理权限，并且可以物理访问所有支持ARM TZ的节点。进一步假设操作系统和用户空间在正常情况下是不可信的。但是假定TEE(包括引导加载程序、固件、OP-TEE和安全监视器)是可信的。 由于ARM TZ本身并不支持远程认证机制，因此攻击者可能会在协议执行之前试图破坏它。链码在正常情况下作为可信应用程序(TA)存储，并使用构建密钥进行签名。ARM TZ在运行时不提供完整性保护。本论文不考虑侧信道攻击。 4.TZ4Fabric架构 支持ARM TZ的设备通常是低功耗嵌入式设备，其中许多都是由电池供电的，它们资源（存储和内存）有限。TZ4Fabric依赖于Go编程语言环境、HF、OP-TEE以及gRPC等包，这些包不仅需要几百兆的持久存储，而且在运行时也需要几百兆的内存，因此论文提出通过代理将大型系统组件(如HF和Docker)与轻量级安全相关组件(如链码)解耦。 在设计中，链码操作及其响应中可以包含敏感信息，必须保护这些信息免受恶意攻击。因此，将链码存放到一个支持TEE的嵌入式设备。将TZ4Fabric分为三大组件：作为链码驻留在对等端上的包装器、代理、链码本身。包装器通过gRPC和代理通信，代理和链码运行在基于ARM的环境中，并使用TrustZone，其中代理在正常世界，链码在安全世界。论文的设计利用OP-TEE框架来进行代理和链码之间的交互。 包装器被安装和实例化为链码，并被用作对等端和账本的接口。它将来自客户端的输入调用转发到安全世界中的链码，处理与账本的通信，并将交易响应发送回对等端。 代理充当中介，在包装器和链码之间转发调用。它负责从正常世界到安全世界的上下文切换。 链码实现了区块链应用程序逻辑，并由客户端通过包装器调用。在执行过程中，链码可以使用代理通过 getState 和 putState 命令访问账本。 论文的设计允许在一个单一的安全世界中实例化和运行多个链码。 论文的原型侧重于在HF中包含ARM TZ，而没有实现一个机制在网络中复制链码。链码在原型中作为OP-TEE中的TAs执行，链码使用与机器上运行的OP-TEE相同的构建系统进行编译，TA使用原始的构建密钥进行签名，并可选地加密。因此，在调用链码之前，必须将每个链码编译到TA并在目标机器上安装，然后，链码可以在目标机器上复制并直接调用，而不必经过生成TA的过程。在原型中，为链码生成了一个TA，并将其部署在所有启用ARM TZ的代理上。","categories":[{"name":"Paper Reading","slug":"Paper-Reading","permalink":"http://example.com/categories/Paper-Reading/"}],"tags":[{"name":"blockchain","slug":"blockchain","permalink":"http://example.com/tags/blockchain/"}]},{"title":"论文阅读-Ekiden. A Platform for Confidentiality-Preserving, Trustworthy, and Performant Smart Contracts","slug":"paper-reading/paper-Ekiden","date":"2021-06-12T16:00:00.000Z","updated":"2022-07-20T03:49:41.282Z","comments":true,"path":"2021/06/13/paper-reading/paper-Ekiden/","link":"","permalink":"http://example.com/2021/06/13/paper-reading/paper-Ekiden/","excerpt":"论文Ekiden. A Platform for Confidentiality-Preserving, Trustworthy, and Performant Smart Contracts阅读笔记","text":"1.引入 现有的智能合约系统因此缺乏保密性和隐私性，它们不能安全地存储或计算敏感数据；区块链共识需求也使得智能合约在计算能力、存储容量和事务吞吐量方面的性能低下。 区块链和TEE有互补特性： 区块链可以保证强可用性和持久性，而TEE不能保证可用性（因为宿主可以自行决定终止TEE），也不能可靠地访问网络或持久性存储 区块链的计算能力非常有限，必须公开其整个状态以供公共验证，而TEE与本地计算相比产生的开销很小，并通过远程认证提供具有机密性的可验证计算 区块链和TEE结合会产生新的安全问题：由于TEE的基本限制是恶意主机可以任意操纵它的调度和I/O，TEE可能在任意时间中止，导致区块链上丢失和冲突的状态。TEE缺少可信时钟，因此很难更新到区块链的最新状态。可能存在的攻击例如针对区块链的完整性攻击危及TEE保护内容的机密性（如，攻击者可以通过提供一个伪造的区块链来绕过TEE强制执行的隐私计算，以退回到执行前并向其请求任意多个查询） Ekiden采用计算与共识分离的架构。Ekiden在链下的TEE中使用计算节点执行私有数据的智能合约计算（避免了链上计算负担），然后验证它们在链上的正确执行，而区块链上的共识节点不需要使用TEE。Ekiden与共识机制无关，只需要一个能够验证来自计算节点的远程认证的区块链。 为了解决TEE的可用性和网络安全限制，Ekiden支持链上检查和合约状态存储。 主要贡献 正式安全建模：使用一个理想的功能$F_{Ekiden}$来表达Ekiden的全部安全需求，在通用可组合性(UC)框架中概述安全性证明，表明Ekiden协议在并发组合下与$F_{Ekiden}$匹配； TEE-区块链结合方案：系统地列举了区块链和TEE融合产生的基本缺陷，并提供了克服这些缺陷的通用技术； 性能：区块链可能是TEE-区块链混合系统的性能瓶颈。论文提供了优化，在不降低安全性的情况下最小化区块链的使用。 2.背景 智能合约 智能合约系统的限制： 对每个节点都完全复制的智能合约进行链上计算很昂贵 传统的智能合约系统不提供隐私保护，用户由假名区别，但是假名只提供很弱的隐私保护 合约状态和用户输入必须是公开的，以便矿工验证正确的计算，缺乏隐私 可信硬件 SGX生成的认证是不可伪造的 单单SGX不能保证可用性（恶意主机可以任意终止Enclave或丢弃消息） SGX容易遭受侧信道攻击 3.TEE-区块链系统的技术挑战 容忍TEE故障 可用性故障 在SGX中，恶意主机可以终止Enclave，即使是诚实主机也可能在电源循环中丢失Enclave。TEE-区块链系统必须能够容忍这样的主机故障，确保崩溃的TEE可以延迟执行。 论文将TEE视为可消耗和可互换的，依赖区块链来解决并发性导致的任何冲突。为了确保任何特定的TEE很容易被替换，TEE是无状态的，并且任何持久状态都由区块链存储。 侧信道 为了对付SGX的侧信道攻击，论文采用的方法是在空间和时间上进行划分，针对强敌手模型设计Ekiden中的关键组件，如密钥管理器，允许攻击者打破一小部分TEE的机密性，并限制其他组件对密钥管理器的访问。另外还采用了主动密钥旋转来限制泄漏密钥的权限。 时钟故障 SGX的时钟不可信，一个TEE-区块链混合协议必须尽量减少对TEE时钟的依赖。 在论文的设计中，不需要TEE拥有当前区块链的状态。具体来说，不需要TEE来区分陈旧状态和当前状态，而依赖于区块链主动拒绝任何陈旧输入状态的更新。 PoW区块链的发布证明 为了利用区块链作为持久存储，TEE必须能够有效地验证一个项目已经存储在区块链中，同时TEE也需要能够验证新块。这就需要一个可信时钟来防止敌手隔离Enclave而提供一个无效的子链。 论文利用了TEE的保密性，这样延迟时钟响应的攻击者就不能阻止Enclave成功验证区块链内容。 TEE中的密钥管理 使用区块链持久化TEE状态的一个基本限制是缺乏保密性。通常可以通过在多个TEE中保存相同的密钥副本来实现密钥存储，虽然这种方法能很好地抵抗状态丢失，但是会造成更大的攻击面，在可用性和暴露风险之间需要权衡。 论文针对强敌手模型设计密钥管理器，允许攻击者打破一小部分TEE的机密性，并限制其他组件对密钥管理器的访问。 执行结果的原子性交付 通常，对于有状态的TEE-区块链协议，TEE的执行产生两个消息： $m_1$：向调用者发送输出结果 $m_2$：向区块链发送状态更新 这两个消息必须原子性交付，要么都交付成功，有一个交付失败则系统不可用：$m_1$ 在调用者收到时交付成功，$m_2$ 在区块链接受时交付成功，被拒绝的状态更新不是交付成功。 若不要求两个消息的原子性交付，可能产生的攻击有： 如果只有 $m_1$ 被交付，可能会产生倒回攻击，由于TEE不能判断输入状态是否为新状态，因此攻击者可以提供旧状态以从旧状态恢复TEE的执行，直到获得想要的结果（公平性）； 如果只有 $m_2$ 被交付，用户可能永久丢失输出，因为一般不可能根据更新后的状态来重新产生相同的输出 4.Ekiden概述 为了支持像信用评分这样的大规模隐私敏感应用程序，智能合约系统满足数据机密性保护以及高性能的同时要保持区块链提供的完整性和可用性。 Ekiden概述 Ekiden实现了用户自定义智能合约的安全执行环境，Ekiden合约是一个确定性的有状态程序。将合约程序的形式定义为 $(outp,st_{new}):=Contract(st_{old},inp)$ ，其中合约的输入是 $st_{old}$（前一个状态）和 $inp$（用户输入），生成输出 $outp$ 和新状态 $st_{new}$。 一旦部署在Ekiden上，智能合约就有了强大的保密性、完整性和可用性保证。在Ekiden中，有三种实体： 客户是智能合约的用户，在Ekiden中，客户可以通过秘密输入创建合同或执行现有的合同。无论哪种情况，客户机都将计算委托给计算节点； 计算节点在合约TEE中执行合约并且生成用于证明状态更新正确性的证明，从而处理客户的请求。一组计算节点组成一个密钥管理委员会，并运行一个分布式协议来管理合约TEE使用的密钥，合约TEE通过密钥管理委员会来创建或恢复密钥； 共识节点构成区块链，合约状态和认证都保存在这个区块链上。共识节点负责使用TEE检查状态更新的有效性。 工作流程 简单起见，假设客户拥有使用的计算节点的优先级列表，客户记为 $P$ ，计算节点记为 $Comp$。 合约创建 创建合约时，$P$ 将合约代码 $contract$ 发送给 $Comp$，$Comp$ 将 $Contract$ 加载到合约TEE中，合约TEE创建一个新鲜的合约id $cid$，从密钥管理委员会获取新鲜的 $(pk{in}_{cid},sk{in}{cid})$ 对和 $k{cid}^{state}$ 并生成加密的初始状态 $Enc(k^{state}{cid},\\vec{0})$ 和一个证明 $\\sigma{TEE}$（用于证明TEE初始化的正确性以及 $pk_{cid}^{in}$ 是对应于合约 $cid$ 的公钥）。 最后，$Comp$ 从认证服务获取 $\\sigma_{TEE}$ 的正确性证明，该证明和 $\\sigma_{TEE}$ 绑定到一个“certified”证明 $\\pi$ 中。$Comp$ 接着发送 $(Contract,pk{in}_{cid},Enc(k{state}_{cid},\\vec{0}),\\pi)$ 到共识节点。 合约创建的完整协议由Fig2的 $Prot_{Ekiden}$ 中的 create 表示。 请求执行 描述Fig1的过程： (1) 为了使用输入 $inp$ 来执行合约 $cid$ ，$P$ 首先从区块链获取与合约 $cid$ 相关联的 $pk_{cid}^{in}$ ，计算 $inp_{ct}=Enc(pk^{in}{cid},inp)$ ，并将消息 $(cid,inp{ct})$ 发送给 $Comp$ 。如 $Prot_{Ekiden}$ 的Line8-11所示。 (2) $Comp$ 从区块链取出合约代码，以及合约 $cid$ 的加密过去状态 $st_{ct}=Enc(k^{state}{cid},st{old})$ ，并将 $st_{ct}$ 和 $inp_{ct}$ 加载到TEE中执行。 如 $Prot_{Ekiden}$ 的Line30-33所示。 (3-4) 合约TEE从密钥管理委员会获取 $k_{cid}^{state}$ 和 $sk^{in}{cid}$ ，并使用它们解密 $st{ct}$ 和 $inp_{ct}$ 。从而生成输出 $outp$ ，一个新的加密状态 $st{'}_{ct}=Enc(k_{cid}{state},st_{new})$ 和一个用于证明计算正确的签名 $\\pi$ 。如 $Prot_{Ekiden}$ 的Line7-13所示。 (5a, 5b) 最后，$Comp$ 和 $P$ 执行一个原子交付协议，将 $outp$ 交付给 $P$ ，并将 $(st^{'}{ct},\\pi)$ 交付给共识节点。共识节点先验证 $\\pi$ 再接受新状态 $st^{'}{ct}$ 并将其存放在区块链上，只有在这之后，$P$ 才能接收到 $outp$ 。 Ekiden将请求执行与共识解耦。在以太坊中，请求执行被网络中的所有节点复制以达成共识，使得整个网络的速度和单个节点一样慢。而在Ekiden中，请求只被K个计算节点执行，K通常比较小，共识节点只需要验证K个正确执行的证明。 论文的实现中，使用签名 $\\pi$ 来作为TEE正确执行的证明。一个计算节点 $Comp$ 通过如下方式获得签名 $\\pi$ 。假设 $Comp$ 执行结果为一个输出 $st^{‘}{ct}$ 和一个证明 $\\sigma{TEE}$（对合约代码和 $st^{’}{ct}$ 的签名），$Comp$ 将 $\\sigma{TEE}$ 发送到IAS，IAS验证 $\\sigma_{TEE}$ 并回复 $\\pi=(b,\\sigma_{TEE},\\sigma_{IAS})$ ，其中 $b\\in{0,1}$ 表明 $\\sigma_{TEE}$ 的有效性，$\\sigma_{IAS}$ 是IAS对 $b$ 和 $\\sigma_{TEE}$ 的签名。然后 $\\pi$ 被提交到共识节点作为 $st^{'}_{ct}$ 正确性的证明。 Ekiden安全目标 正确执行：合约状态转换反映了合约代码在给定状态和输入上的正确执行； 一致性：在任何时候，区块链都存储与每个计算节点一致的单一状态转换序列； 保密：Ekiden保证合约状态和来自诚实客户的输入对所有其他各方保密，另外Ekiden也能抵御一些密钥管理TEE的背叛； 优雅的机密性降级：如果有计算节点违反机密性，Ekiden提供前向保密，并与受影响的TEE进行合理隔离。假设机密性违反发生在 $t$ ，攻击者最多能够获取 $t-\\Delta$ 的历史。 Ekiden不对合约级别的隐私泄露进行防御，如合约中的隐蔽信道、bug或侧信道。 假设和威胁模型 TEE 假设SGX是正确实现和安全制造的，但由于SGX存在侧信道攻击，假设敌手可以危及一小部分TEE的机密性。 区块链 Ekiden对底层共识协议不可知。假设区块链正确执行规定的计算，并且总是可用的。Ekiden依赖共识节点来进行认证，进一步假设区块链提供发布证明，可以证明区块链上包含一些内容。 威胁模型 系统中的各方都必须信任Ekiden和TEE 假设敌手可以控制除了一个计算节点之外的所有操作系统和网络堆栈，在受控节点上，敌手可以任意排序消息和调度进程 敌手可以操控任意数量的客户 客户不需要自己执行合约，也不需要可信硬件 诚实用户信任自己的代码和平台，但不相信其他客户 每个合约都有一个明确的策略来规定如何处理数据和服务请求 Ekiden不能防止合约有意或无意地通过软件漏洞泄露机密 5.Ekiden重要模块 发布证明 为permissionless的区块链提出发布证明协议： 发布证明是一种在验证者 $\\varepsilon$ 、合约TEE和不可信证明提供者 $P$ 之间的交互式证明。总的来说，只给 $P$ 有限的时间在足够困难的子链的块上发布消息，从而敌手很难伪造。 $\\varepsilon$ 存储最近的一个checkpoint块 $CB$，可以通过 $CB$ 计算难度系数 $\\delta(CB)$ ， $\\varepsilon$ 向任何请求客户发出 $CB$ 版本，使客户能够验证 $CB$ 的新鲜度。给定一个有效的最近的 $CB$ ， $\\varepsilon$ 可以通过 $\\delta(CB)$ 来验证新的块。为了方便分析，论文中的难度系数是恒定的。 为了初始化 $m$ 的发布，$\\varepsilon$ 获取时间戳 $t_1$ ， $\\varepsilon$ 可能需要经过一段延时才能收到 $t_1$ 。收到 $t_1$ 之后，$\\varepsilon$ 生成一个随机数 $r$ 并要求 $P$ 发布 $(m,r)$ 。$\\varepsilon$ 收到 $P$ 发送的证明 $\\pi_{(m,r)}$ 之后，获取时间戳 $t_2$ 。令 $n_c$ 为发布 $(m,r)$ 所需要的确认次数，$\\tau$ 为期望的块间隔时间（区块链中的定值），$\\epsilon$ 为一个乘法松弛因子，代表块产生的时间变化。例如，$\\epsilon=1.5$ 表示 $\\pi_{(m,r)}$ 的产生可以比预期在主链上的速度慢1.5倍。$\\varepsilon$ 只有当 $t_2-t_1&lt;n_c\\times\\tau\\times\\epsilon$ 时才接受 $\\pi_{(m,r)}$。 将 $\\epsilon$ 设置为一个大的值可以降低错误拒绝的概率（拒绝诚实用户 $P$ 的证明会导致区块链增长速度减慢），然而大的 $\\epsilon$ 值也会导致错误接受的概率增大。对于 $\\epsilon&gt;1$ ，需要一个足够大的 $n_c$ 来使成功攻击的概率可忽略，然而大的 $n_c$ 意味着诚实用户 $P$ 需要等待很长时间才能获得输出，影响用户体验。 例如，假设攻击者有25%的算力，设置 $n_c=80$ 以及 $\\epsilon=1.6$ 意味着攻击者需要预期2112次哈希才能伪造一个发布证明，而诚实的证明只有2-19的几率被拒绝。攻击者的伪造时间只有 $t_2-t_1$ ，而若 $\\varepsilon$ 经过一段延时才收到 $t_1$ ，则 $t_2-t_1$ 就更短，对攻击者不利。 一旦一条消息在一个TEE中发布，其他TEE可以通过经认证的安全信道获取该消息及其证明，从而节省重复协议的成本。 密钥管理 每个Ekiden合约都和一系列密钥相关联，包括一个用于状态加密的对称密钥和用于加密客户输入的密钥对。 敌手模型 假设敌手可以打破一定比例（$f%$）的TEE的机密性 假设参与主体有抵御女巫攻击的身份（交押金才能参与协议） 假设随时有足够多（$2f%$）的用户在线，从而密钥的可用性得到保证（通过经济奖惩来激励参与） 所需属性 由于解密密钥最终会暴露给合约TEE，而合约TEE本身也